Generated_Prompt,Original_Question,Original_Answer
"[INST] I'm working on a simple script that involves CAS, jspring security check, redirection, etc.  I would like to use Kenneth Reitz's python requests because it's a great piece of work!  However, CAS requires getting validated via SSL so I have to get past that step first.  I don't know what Python requests is wanting?  Where is this SSL certificate suppose to reside?
Traceback (most recent call last):
  File ""./test.py"", line 24, in <module>
  response = requests.get(url1, headers=headers)
  File ""build/bdist.linux-x86_64/egg/requests/api.py"", line 52, in get
  File ""build/bdist.linux-x86_64/egg/requests/api.py"", line 40, in request
  File ""build/bdist.linux-x86_64/egg/requests/sessions.py"", line 209, in request 
  File ""build/bdist.linux-x86_64/egg/requests/models.py"", line 624, in send
  File ""build/bdist.linux-x86_64/egg/requests/models.py"", line 300, in _build_response
  File ""build/bdist.linux-x86_64/egg/requests/models.py"", line 611, in send
requests.exceptions.SSLError: [Errno 1] _ssl.c:503: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed

 [/INST] I have run into this problem myself. I have no idea why requests is failing like this, but I am assuming it is because the certificate is not being generated. I don't know why it is failing, but I have run into this with other certificates as well.
Traceback (/home/build/python/setup.py"", line 52, in _ssl_verify)
Traceback (/","I'm working on a simple script that involves CAS, jspring security check, redirection, etc.  I would like to use Kenneth Reitz's python requests because it's a great piece of work!  However, CAS requires getting validated via SSL so I have to get past that step first.  I don't know what Python requests is wanting?  Where is this SSL certificate suppose to reside?
Traceback (most recent call last):
  File ""./test.py"", line 24, in <module>
  response = requests.get(url1, headers=headers)
  File ""build/bdist.linux-x86_64/egg/requests/api.py"", line 52, in get
  File ""build/bdist.linux-x86_64/egg/requests/api.py"", line 40, in request
  File ""build/bdist.linux-x86_64/egg/requests/sessions.py"", line 209, in request 
  File ""build/bdist.linux-x86_64/egg/requests/models.py"", line 624, in send
  File ""build/bdist.linux-x86_64/egg/requests/models.py"", line 300, in _build_response
  File ""build/bdist.linux-x86_64/egg/requests/models.py"", line 611, in send
requests.exceptions.SSLError: [Errno 1] _ssl.c:503: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed

","From requests documentation on SSL verification:

Requests can verify SSL certificates for HTTPS requests, just like a web browser. To check a hostâs SSL certificate, you can use the verify argument:

>>> requests.get('https://kennethreitz.com', verify=True)

If you don't want to verify your SSL certificate, make verify=False 
"
"[INST] I'm looking for a library in Python which will provide at and cron like functionality.
I'd quite like have a pure Python solution, rather than relying on tools installed on the box; this way I run on machines with no cron.
For those unfamiliar with cron: you can schedule tasks based upon an expression like: 
 0 2 * * 7 /usr/bin/run-backup # run the backups at 0200 on Every Sunday
 0 9-17/2 * * 1-5 /usr/bin/purge-temps # run the purge temps command, every 2 hours between 9am and 5pm on Mondays to Fridays.

The cron time expression syntax is less important, but I would like to have something with this sort of flexibility. 
If there isn't something that does this for me out-the-box, any suggestions for the building blocks to make something like this would be gratefully received.
Edit
I'm not interested in launching processes, just ""jobs"" also written in Python - python functions. By necessity I think this would be a different thread, but not in a different process.
To this end, I'm looking for the expressivity of the cron time expression, but in Python. 
Cron has been around for years, but I'm trying to be as portable as possible. I cannot rely on its presence.
 [/INST] I have written a cron entry for my linux install:
0 2 * 3 /usr/bin/run-backup # run the purge commands as * * * * 2
0 0 * * 3 /usr/bin/run-backup # run the purge commands as * * * * 2
0 1 * * * 3
0 2 * * * * 5
0 3 * * * 8 * * * * 8 * * * 13
0 5 * * * * 8 * * 13
out-of-the-box, 5 * 7 * 13

in Python * * * * * 8 * 5 /usr/bin/run-backup
1 5 * 5 * 8 *","I'm looking for a library in Python which will provide at and cron like functionality.
I'd quite like have a pure Python solution, rather than relying on tools installed on the box; this way I run on machines with no cron.
For those unfamiliar with cron: you can schedule tasks based upon an expression like: 
 0 2 * * 7 /usr/bin/run-backup # run the backups at 0200 on Every Sunday
 0 9-17/2 * * 1-5 /usr/bin/purge-temps # run the purge temps command, every 2 hours between 9am and 5pm on Mondays to Fridays.

The cron time expression syntax is less important, but I would like to have something with this sort of flexibility. 
If there isn't something that does this for me out-the-box, any suggestions for the building blocks to make something like this would be gratefully received.
Edit
I'm not interested in launching processes, just ""jobs"" also written in Python - python functions. By necessity I think this would be a different thread, but not in a different process.
To this end, I'm looking for the expressivity of the cron time expression, but in Python. 
Cron has been around for years, but I'm trying to be as portable as possible. I cannot rely on its presence.
","maybe this has come up only after the question was asked; I thought I just mention it for completeness sake: https://apscheduler.readthedocs.org/en/latest/
"
"[INST] How do I have a Python script that can accept user input (assuming this is possible) and how do I make it read in arguments if run from the command line?
 [/INST] I've had this problem before, when trying to use a filter on a Python script and a small bug comes up. 
How do I force the filter to pass a Python script (on the command line)?
e.g.:
from sys import get_small_filter
from sys import stdout
from sys import get_small_filter

e = get_small_filter(sys.argv[1])
from sys import argv[1]
from sys import get_small_filter
from sys import argv

from sys import get_small_filter
from sys import argv_filter
from sys import get_small_filter

def filter_all_filter(argv):
    #...
    from sys import argv
    return argv

  #...

from sys import get_small_filter
    #...

e = argv [1]

from sys import get_small_filter
#...

#  #
from sys import get_small_filter
#...

from sys import argv_filter
#...

  #...

the filter() is the filter part in this file.
  #...

  #....

from sys import argv_filter
#...

  #...

e = argv_filter
#...

from sys import argv_filter
#......

  #...

  #...

from sys import argv_filter
#......

  #...

from sys import argv_filter
#......

#......

  #

the filter() is the filter part in the argv_filter.
  #...

  #...

  #......

from argv import filter
sys.filter(argv)

  #...

from argv import filter_all_filter
#...

from sys import get_small_filter
#......

from argv import filter_all_filter
#......

  #...

from sys import argv_filter
# #","How do I have a Python script that can accept user input (assuming this is possible) and how do I make it read in arguments if run from the command line?
","raw_input is no longer available in Python 3.x.  But raw_input was renamed input, so the same functionality exists.
input_var = input(""Enter something: "")
print (""you entered "" + input_var) 

Documentation of the change
"
"[INST] Two options in setup.py develop and install are confusing me. According to this site, using develop creates a special link to site-packages directory.
People have suggested that I use python setup.py install for a fresh installation and python setup.py develop after any changes have been made to the setup file.
Can anyone shed some light on the usage of these commands?
 [/INST] python setup.py develop will create a site-packages directory and have a special command called. setup.py which will generate a fresh site-packages directory. 
e.g.
python setup.py install
(1,2,2,3,4,5,6,3,4,5,3,4,4,3,3,4,5,6,7)

and 
python setup.py develop
(4,4,3,4,5,6)

a site-packages directory
(1,4,4,5,7,4,4,3,3,4,5)


(1,4,6,4,5,4,3,4,4)

(4,4,5,6,4,4,3,4,5,3,4,7)

(1,4,6,4,5,4,7,8)
(1,4,6,7,4,4,4,5)

(4,4,5,6,7)

(1,4,5,6,4,7)
(4,4,5,4,5,4,6)

(4,4,5,6,7)

(2,4,5,6,4,4)

(4,4,5,4,7)
(4,4,5,7,4,7)

(1,4,5,6,7)

(4,4,5,4,7)
(4,4,5,7,7)
(4,4,5,7,4,7)

(4,4,5,7)
(4,4,5,7,7,4,3)
(4,4,5,7,7)
","Two options in setup.py develop and install are confusing me. According to this site, using develop creates a special link to site-packages directory.
People have suggested that I use python setup.py install for a fresh installation and python setup.py develop after any changes have been made to the setup file.
Can anyone shed some light on the usage of these commands?
","From the documentation. The develop will not install the package but it will create a .egg-link in the deployment directory back to the project source code directory. 
So it's like installing but instead of copying to the site-packages it adds a symbolic link (the .egg-link acts as a multiplatform symbolic link). 
That way you can edit the source code and see the changes directly without having to reinstall every time that you make a little change. This is useful when you are the developer of that project hence the name develop. If you are just installing someone else's package you should use install
"
"[INST] How do I concatenate two lists in Python?
Example:
listone = [1, 2, 3]
listtwo = [4, 5, 6]

Expected outcome:
joinedlist == [1, 2, 3, 4, 5, 6]

 [/INST] You seem to be getting the same thing in every direction!
 [/INST] You seem to be getting the same thing in every direction!

You get the same thing in every direction!

listone = [1, 2, 3, 4, 5, 6]

listtwo= [4, 5, 6]

listone[1:] = [1, 2, 3, 4, 5]

listtwo[1]:  [1, 5, 6]

[/INST] You get the same thing in every direction.

list[1]: [1, 5, 6]

 [/][1, 5, 6]

 [/][2] [1, 5, 6]


[/][2] [1, 5, 6]

 [/][2][2]: [1, 5, 6]

[/][2][2][3][4, 6]


[/][2][2][3, 6]

 [/][2][3][4, 5, 6]: [1, 5, 6]

 [/][2][2][3, 4, 5, 6]

[/][2][2][3, 4, 5, 6]

[/][2][2][3, 4, 5, 6]

[/][2][2][3, 4, 5, 6]

 [/][2][2][3, 4, 5, 6]

[/][2][2, 3, 4, 5, 6]

 [/][2][2][3, 4, 5, 6]

 [/][2][2][3, 4","How do I concatenate two lists in Python?
Example:
listone = [1, 2, 3]
listtwo = [4, 5, 6]

Expected outcome:
joinedlist == [1, 2, 3, 4, 5, 6]

","If you don't want to or can't use the plus operator (+), you can uses the  __add__ function:
listone = [1,2,3]
listtwo = [4,5,6]

result = list.__add__(listone, listtwo)
print(result)

>>> [1, 2, 3, 4, 5, 6]

"
"[INST] How do you convert a Unicode string (containing extra characters like Â£ $, etc.) into a Python string?
 [/INST] I know this is an old question but as I've seen people still using filter -1 recently, I thought it would be helpful.
filter(lambda x, y: $y < 1)
filter(lambda y: $n, a: b)
filter(lambda z: 
    a: b)

I'm not sure if this is still valid but its using the filter(lambda * a) part of it, which I believe is valid
 
def filter_1(a, b):
    return [x if a < b, b if a < b, a < b]

def filter_2(a, b, c):
    return [x if a < b, b if x < c, a < b]

def filter_3(a, b, c):
    return [x if a < b, b if x < a && a < b]

And the filter filter() returns an empty list if a, b and c are not in the filter, which is exactly what we want. But if we add filter(a, b, c) to the filter, it returns the first filter.
 
>>> filter(lambda a, b, c, [5, 6, 2])
[2, 3, 1, 2, 1]

Although this seems to be logical, I haven't heard any good use case.
 [/INST] filter(lambda (x, y, c))
>>> filter(lambda (a, b, c) if a < b, [5, 6, 2]
>>> filter(lambda (a, b, c) if a, b, c, 2)
[2, 3, 4, 2]

This is more pythonic and concise.
  filter(lambda (a, b, c) if a < b, filter(lambda (a, b, c) if a, b, c)
>>> filter(lambda (a, b, c) if a, b, c]

[a, b, c]

a, b and c are actually tuples","How do you convert a Unicode string (containing extra characters like Â£ $, etc.) into a Python string?
",">>> text=u'abcd'
>>> str(text)
'abcd'

If a simple conversion.
"
"[INST] Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.
 [/INST] I've found that the best way to do this, is to simply iterate over the dictionary keys and values.
for key, value in mydict.iteritems():
    print key, value

  # Example dictionary
    d = {'a':1, 'b': 2, 'c': 3}
    for key, value in mydict.iteritems():
        print key, value

  # Add more values to the dictionary, if needed, by adding a key-value pair:
  d[key, values][0] = value
  d[key, value] = value

  # Add values to the dictionary, if needed (for instance to populate a dictionary with a list of values)
  d[key, value] = value

  # Combine all values into a new dictionary
  d = {}
  d[key, values][0] = value
  d[key, value] = d[key, value]

  # Combine all values into a new dictionary (assuming that the keys and values can't be repeated)
  d = dict2new(key, value)
  d[key, value] = d.set(key, value)
  d.keys()
  d[key, value]

  # Add values, if needed (for example when iterating over values)
  d[key, value] = d.get(key, value)

  # Add values, if needed (from the dictionary)
  d[key, value] = d[key, value]

  # Add values, if needed (for example `d[key, value]`)
  d[key, value] = d[key, value]
  d.add(key, value)

dict2dict.keys():
d[key, value] = d[key, value]

dict2dict.keys()
d[key, value]

dict2dict['a', 'b', 'c']

dict2dict['b', 'c']

dict2dict","Is it possible to add a key to a Python dictionary after it has been created? It doesn't seem to have an .add() method.
","I feel like consolidating info about Python dictionaries:
### Making a dictionary ###

data = {}
# OR
data = dict()

### Initially adding values ###

data = {'a':1,'b':2,'c':3}
# OR
data = dict(a=1, b=2, c=3)

### Inserting/Updating value ###

data['a']=1  # updates if 'a' exists, else adds 'a'
# OR
data.update({'a':1})
# OR
data.update(dict(a=1))
# OR
data.update(a=1)

### Merging 2 dictionaries ###

data.update(data2)  # Where data2 is also a dict.

### Deleting items in dictionary ###

del data[key] #Remove specific element in a dictionary
data.pop(key) #Removes the key & returns the value
data.clear() #Clear entire dictionary

Feel free to add more!
"
"[INST] I have a list with 15 numbers in, and I need to write some code that produces all 32,768 combinations of those numbers. 
I've found some code (by googling) that apparently does what I'm looking for, but I found the code fairly opaque and am wary of using it. Plus I have a feeling there must be a more elegant solution.
The only thing that occurs to me would be to just loop through the decimal integers 1-32768 and convert those to binary, and use the binary representation as a filter to pick out the appropriate numbers. 
Does anyone know of a better way? Using map(), maybe?
 [/INST] I've written a simple Python wrapper for generating all possible combinations of the integers 0-255, including all powers of 0-255, but if you want to generate all powers of 0-255, 72-255, etc. you can simply do:
filtered = [x&255, x&255, 10-255]

def filter_by_1(x):
    # filter out the filters
    filter_by1 = filter(charlow, 255)
    filter(x, 255, 10-255)

def filter_256(x):
    # filter out the filters
    for i in x:
        if i == 0:
            print ""121""
        if i == 257:
            print ""121""
        if i == 1:
            print ""121""
        if x==1:
            print ""121""
        if x==2:
            print ""121""
        if x==1:
            print ""121""
        if x==0:
            print ""121""
        if x==0:
            print ""121""
        if x==1:
            print ""121""
        if x==2:
            print ""255""
        if x==0:
            print ""121""

def filter","I have a list with 15 numbers in, and I need to write some code that produces all 32,768 combinations of those numbers. 
I've found some code (by googling) that apparently does what I'm looking for, but I found the code fairly opaque and am wary of using it. Plus I have a feeling there must be a more elegant solution.
The only thing that occurs to me would be to just loop through the decimal integers 1-32768 and convert those to binary, and use the binary representation as a filter to pick out the appropriate numbers. 
Does anyone know of a better way? Using map(), maybe?
","This one-liner gives you all the combinations (between 0 and n items if the original list/set contains n distinct elements) and uses the native method itertools.combinations:
from itertools import combinations

input = ['a', 'b', 'c', 'd']

output = sum([map(list, combinations(input, i)) for i in range(len(input) + 1)], [])


The output will be:
[[],
 ['a'],
 ['b'],
 ['c'],
 ['d'],
 ['a', 'b'],
 ['a', 'c'],
 ['a', 'd'],
 ['b', 'c'],
 ['b', 'd'],
 ['c', 'd'],
 ['a', 'b', 'c'],
 ['a', 'b', 'd'],
 ['a', 'c', 'd'],
 ['b', 'c', 'd'],
 ['a', 'b', 'c', 'd']]


Try it online:
http://ideone.com/COghfX
"
"[INST] I spent most of the day yesterday searching for a clear answer for installing pip. I can't find a good solution. 
Can somebody help me install it?
 [/INST] I have tried everything above and I still couldn't get a good solution.
If I have to use pip to install a package it goes down and I have to pay. I have found a solution using a python -m setup.py install on my machine and it works perfectly.
  $ pip /usr/bin/pip
  (pip list -d $VERSION)
  $python setup.py install

  (I also use pip freeze for a list of installed packages)

I have run the pip from the command line and it worked perfectly.  The only issue I have with pip is that both pip is on the command line and I have to get ""pip install"".
 [/INST] pip is not perfect. It just doesn't work the way it should.
The problem is that pip is installed by pip and it has a dependency on python.  If you use --install on the command line it will automatically install the package for you.  If you just use pip you will have to run pip and -m.  There are two ways to do this:

First, you can run the command line and pass it to pip and it will run setup.py and have access to the packages listed there.

The second solution is to run the --install command and then pip will do the same thing but with less code.  If you find this too confusing and confusing for the novice there, here is a quick explanation for those who are new to it:

The --install command only runs setup.py for packages listed in the package indexes.  This is because pip is actually a python package manager.  So this solution is going to run in the python [0,1,2,3] packages listed above.
  --install <package name>
  -r <list of packages to be installed
    [0,1,2,3,4,5,6,7,8,9,10,11,13,14,15,4,6,7,8,9,2,3,4,5,6,7,8,9]
  (p","I spent most of the day yesterday searching for a clear answer for installing pip. I can't find a good solution. 
Can somebody help me install it?
","Download python setup tools from the below website:
https://pypi.python.org/pypi/setuptools
Use the tar file.
Once you download, go to the downloaded folder and run 
python setup.py install

Once you do that,you will have easy_install.
Use the below then to install pip:
sudo easy_install pip

"
"[INST] Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.?
 [/INST] I'm not a Python expert, but I'm pretty sure that this is the cleanest way to do it:
this = lambda x: x.stop()

but you need to set
thread = threading.Thread(target=target, args=())

  if target =='stop':
      print'stop'
      return

  if target == 'quit':
      print 'exit'

  if target == 'quit':
      print 'exiting'

  if len(args) == 1:
      raise SystemExit, 'exit'

The code above is a bit obscure and difficult to follow, if you're not familiar with it, read this: https://docs.python.org/2/exiting.html
  if not target:
      raise SystemExit, 'exiting'

Also note that this code violates the Global Interpreter Lock Rule, which says that you cannot raise SystemExit from within the main thread (the main thread being created by a thread, for example).
  if target == 'quit':
      raise SystemExit, 'exiting'
  if target == 'quit':
      raise SystemExit, 'exiting'
  if target == 'quit':
    raise SystemExit, 'exiting'

  Raise the SystemExit exception raised from the main thread (the main thread being quitting).
  Raising the SystemExit exception raised from the main thread being quitting, who quitting?
The code above only raises the SystemExit exception, which is a Thread-based exception.
  Raising the SystemExit exception from within the main thread is also clean/3 lines/2 lines of code/algorithms/quit() is considered to be an acceptable way to exit.
however, using the ctk.stop() (Although I don't know if this is part of the Python code)
def main():
    ctk.quit()
  RaiseException(SystemExit, SystemError')

Although it's a bit obscure (but I can't imagine why it's raising","Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.?
","      from ctypes import *
      pthread = cdll.LoadLibrary(""libpthread-2.15.so"")
      pthread.pthread_cancel(c_ulong(t.ident))

t is your Thread object.
Read the python source (Modules/threadmodule.c and Python/thread_pthread.h) you can see the Thread.ident is an pthread_t type, so you can do anything pthread can do in python use libpthread.
"
"[INST] Since Python's string can't be changed, I was wondering how to concatenate a string more efficiently?
I can write like it:
s += stringfromelsewhere

or like this:
s = []
s.append(somestring)

later

s = ''.join(s)

While writing this question, I found a good article talking about the topic.
http://www.skymind.com/~ocrow/python_string/
But it's in Python 2.x., so the question would be did something change in Python 3?
 [/INST] I don't know how to do string concatenation in Python 2.x, but I think it can be done using the + operator:
s = '' + s

s = s + stringfromelsewhere

It seems to be the ""official"" way to do string concatenation in Python 2.x, but I'm not sure how to do string concatenation in Python 3.x.

EDIT:
I found this question again because I did have a good reason for doing this. The question is about Python 2.x and I was using Python 3.x. Most answers were about the ""+"" operator, but I'm using Python 2.x and I'd do:

s = [""] + ""+"" + s[0:] + ""+""

from http://docs.python.org/2.x/whatsnew/
mystring = ""+"" + s

it should be
s = """".join(s, [])

against the Python 3.x requirement.
  The question is about combining two lists, however it's stated that string concatenation is not defined in Python 2.x and I haven't specified how to do string concatenation in Python 2.x.

 [/INST] ""+"" is the operator that concatenates two lists, l[:] and r = l[:] + r

The result is:

[
    ""+"" * 2.x,
    ""+"" * 3.x,
    ""+"" + ""*""
]

which is incorrect and the answer is:

[
","Since Python's string can't be changed, I was wondering how to concatenate a string more efficiently?
I can write like it:
s += stringfromelsewhere

or like this:
s = []
s.append(somestring)

later

s = ''.join(s)

While writing this question, I found a good article talking about the topic.
http://www.skymind.com/~ocrow/python_string/
But it's in Python 2.x., so the question would be did something change in Python 3?
","The recommended method is still to use append and join.
"
"[INST] I've been hearing a lot about the PyPy project. They claim it is 6.3 times faster than the CPython interpreter on their site.
Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster.
The second issue is parallelism, the infamous Global Interpreter Lock (GIL). For this, PyPy says it can give GIL-less Python.
If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy right now? 
 [/INST] pyPy is not just an interpreter, but also a compiler optimizer. See http://wiki.pywi.com/wiki/pyPy_2.7/
PyPy is not speed1.3: it is 0.7x slower than Python (on average).
 ...)

Now you might ask: why isn't PyPy faster than CPython?
Simple answer: you don't get speed1.3 because you're not using the right tool for the job.
But that's not true. There's no excuse to say ""why is PyPy slower than CPython"", besides ""speed1.3 is slower than Python""?
So:
http://wiki.python.org/wiki/pyPy/2.7/subpy/pyPy_2.8.html
http://wiki.python.org/wiki/PyPy
http://wiki.python.org/wiki/pyPy
http://wiki.python.org/wiki/pyPy
http://wiki.python.org/wiki/PyPy
http://wiki.python.org/wiki/PyPy

Dynamic typing (where you get speed1.3/2.7/2.8/2.9/3.0/3.8/3.0/3.5/3.8/3.0/3.0/0.7/3.8/3.0/0.9
PyPy is written in C, which is slower than Python (0.7 in 2.7/2.8/2.9):","I've been hearing a lot about the PyPy project. They claim it is 6.3 times faster than the CPython interpreter on their site.
Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster.
The second issue is parallelism, the infamous Global Interpreter Lock (GIL). For this, PyPy says it can give GIL-less Python.
If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy right now? 
","That site does not claim PyPy is 6.3 times faster than CPython. To quote:

The geometric average of all benchmarks is 0.16 or 6.3 times faster than CPython

This is a very different statement to the blanket statement you made, and when you understand the difference, you'll understand at least one set of reasons why you can't just say ""use PyPy"". It might sound like I'm nit-picking, but understanding why these two statements are totally different is vital.
To break that down:

The statement they make only applies to the benchmarks they've used. It says absolutely nothing about your program (unless your program is exactly the same as one of their benchmarks).
The statement is about an average of a group of benchmarks. There is no claim that running PyPy will give a 6.3 times improvement even for the programs they have tested.
There is no claim that PyPy will even run all the programs that CPython runs at all, let alone faster.

"
"[INST] How do I delete a file or folder in Python?
I am using the Python scripting language running on the Windows XP operating system.
 [/INST] I've written a script that uses the exec statement (the actual command line) from within the shell. This script is a part of a shell script I wrote and I am running it from within the application. It is not just a copy-and-paste of script, but a complete re-writing of the application. The idea is to take the output of running the script and then copy the output to the shell and be able to execute the script without the application having to run the script.
 [/INST] I've been trying to use the exec statement from the shell, and it seems to always fail when I use the call_l, but I don't know why. 
def run_script(shell_script):
    # (from http://www.python.org/portable shell)
    # (from http://www.python.org/portable shell)
    # (from shell_script)
    # (from http://www.python.org/portable shell)

  # (from shell_script)
    # (from shell_script)
    # (from shell_script)
    # (from http://www.python.org/portable shell)

# (from shell_script)
# (from http://www.python.org/portable shell)

    # (from http://www.shell.org/portable shell)
    # (from shell_script)
    # (from http://www.python.org/portable shell)

  # (from http://www.shell.org/portable shell)
    # (from shell_script)

I've been trying to add the shell script to the command line, from within the python interpreter. Something is not working as expected.
 [/INST] from shell (import http://www.shell.org/portable shell)
import sys
shell = sys.argv[0]

def run_shell(shell):
    # (from http://www.shell(""shell"",""portable"")
    # (from shell_script)
    # (from http://www.shell","How do I delete a file or folder in Python?
I am using the Python scripting language running on the Windows XP operating system.
","Use 
shutil.rmtree(path[, ignore_errors[, onerror]])

(see complete doc on shutil) and/or
os.remove

and
os.rmdir

(complete doc on os)
"
"[INST] What is the Python equivalent of Perl's chomp function, which removes the last character of a value?
 [/INST] I'm not sure I understand the glyphs() function in python2.6. Can someone explain what it does?
 [/INST] glyphs() is a Unicode (X11) extension that was added to Python 2.6. It was added to the Unicode specification so that  glyphs could be used to construct new strings.
For what exactly glyphs do is needed?
  In general, glyphs are the characters in a string whose encoding is the glyphs (in a given encoding, the letters are the same, X11).

  $0 = glyphs(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)

In Python2.6, glyphs() is the same thing, in a very strange way. It seems to be glyphs from the first line of the program.
  glyphs(0,0,0,0,0,0,0,0,0,0)

  $0 = glyphs(0,0,0,0,0,0,0,0,0,0,0)

However, the $* glyphs are different in a very subtle way:

g
a glyph in a given encoding (code point g0,0,0,0,0,0,0,0,0,0))
b g
a glyph in a given encoding (the first line of glyphs, the second line, the third line, the fourth line)

(thus the glyphs in a given string were the first line of the glyphs, the second line being the second line, the third line being the third line)
(i.e. ""i\x00\x01"")

  $* glyphs(0,0,0,0,0,0,0,0)

  $* glyphs in a given string are the first lines","What is the Python equivalent of Perl's chomp function, which removes the last character of a value?
","Careful with ""foo"".rstrip(os.linesep): That will only chomp the newline characters for the platform where your Python is being executed. Imagine you're chimping the lines of a Windows file under Linux, for instance:
$ python
Python 2.7.1 (r271:86832, Mar 18 2011, 09:09:48) 
[GCC 4.5.0 20100604 [gcc-4_5-branch revision 160292]] on linux2
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import os, sys
>>> sys.platform
'linux2'
>>> ""foo\r\n"".rstrip(os.linesep)
'foo\r'
>>>

Use ""foo"".rstrip(""\r\n"") instead, as Mike says above.
"
"[INST] When we add a database field in django we generally write models.CharField(max_length=100, null=True, blank=True). The same is done with ForeignKey, DecimalField etc. What is the basic difference in having 

null=True only
blank=True only
null=True, blank=True

in respect to different (CharField, ForeignKey, ManyToManyField, DateTimeField) fields. What are the advantages/disadvantages of using 1/2/3?
 [/INST] I just wanted to add one more point that I missed.

All the answers in this post are about how to get the actual ForeignKey object (i.e. not the ""Book of Shakespeare"") from the model class. 
Being a Chosen

I also want to point out that there is generally no ""Book of Many Fields"" (i.e.specially flashing with my models) in general. 

I think most of the answers are just variations of the same thing, just different ways of doing things. 

But...
all of the answers (except for the first one) are chosen because they all use ""Book of Many Fields"" as their names imply.
Now, I will add something to that:

def get_parent_field(self):
    return self.get_parent_field(self, col=*)

Firstly, there is absolutely no need to even write that. Just consider the ""Book of Many Fields"" as the name of the parent class of which our object is named. 
Secondly, I suppose there is also some ""Book of Many Fields"" (i.e. 'Book of Many Fields'). 

So, there is actually only one way to get the Parent Field of chosen fields:
self.parent_fields = 
col = self.fields

if self.parent_fields is None:
    self.parent_fields = col

if self.parent_fields is None:
    self.parent_fields = col

Now, I understand that getting the fields of chosen fields generally is not the same as getting the fields of the parent class of chosen type.)
So, any way being chosen, the way to get the Parent Field of chosen fields is:","When we add a database field in django we generally write models.CharField(max_length=100, null=True, blank=True). The same is done with ForeignKey, DecimalField etc. What is the basic difference in having 

null=True only
blank=True only
null=True, blank=True

in respect to different (CharField, ForeignKey, ManyToManyField, DateTimeField) fields. What are the advantages/disadvantages of using 1/2/3?
","null=True sets NULL (versus NOT NULL) on the column in your DB. Blank values for Django field types such as DateTimeField or ForeignKey will be stored as NULL in the DB.
blank=True determines whether the field will be required in forms. This includes the admin and your own custom forms. If blank=True then the field will not be required, whereas if it's False the field cannot be blank.
The combo of the two is so frequent because typically if you're going to allow a field to be blank in your form, you're going to also need your database to allow NULL values for that field. The exception is CharFields and TextFields, which in Django are never saved as NULL. Blank values are stored in the DB as an empty string ('').
A few examples:
models.DateTimeField(blank=True) # raises IntegrityError if blank

models.DateTimeField(null=True) # NULL allowed, but must be filled out in a form

Obviously those two options don't make logical sense to use (though, there might be a use case for null=True, blank=False if you want a field to always be required in forms, but optional when dealing with an object through something like the shell.)
models.CharField(blank=True) # No problem, blank is stored as ''

models.CharField(null=True) # NULL allowed, but will never be set as NULL

CHAR and TEXT types are never saved as NULL by Django, so null=True is unnecessary. However, you can manually set one of these fields to None to force set it as NULL. If you have a scenario where that might be necessary, you should still include null=True.
"
"[INST] I want to write a function that will execute a shell command and return its output as a string, no matter, is it an error or success message. I just want to get the same result that I would have gotten with the command line.
What would be a code example that would do such a thing?
For example:
def run_command(cmd):
    # ??????

print run_command('mysqladmin create test -uroot -pmysqladmin12')
# Should output something like:
# mysqladmin: CREATE DATABASE failed; error: 'Can't create database 'test'; database exists'

 [/INST] You could do this:
import MySQLdb as mysql

def run_command(cmd):
    #??????
    if cmd.startswd('shell') and'mysql_test' in cmd.args:
       ???????????
    #???????????

  def run_command(cmd):
    def run_command(cmd):
        #???????????
        #?????????

print run_command('mysql test -i')

  run_command('mysql test -i')

  run_command('mysql test -i')

  run_command('mysql test -i')

  run_command('mysql test')

  run_command('mysql test -i')

  run_command('mysql test -i')

  run_command('mysql test')

  run_command('mysql test')

  run_command('mysql test -i')

  [/INST] If you want to run a command in the shell, you could do it with a shell command. The example in the first answer is just a shell command and is equivalent to running the shell command with -i and ""exit"" in the shell (i.e. the shell command)

  def run_command(command):
    #????????????
    command = run_command('mysql test')
 ???????????????

  def run_cmd(command):
   ???????????????

  def run_command(command","I want to write a function that will execute a shell command and return its output as a string, no matter, is it an error or success message. I just want to get the same result that I would have gotten with the command line.
What would be a code example that would do such a thing?
For example:
def run_command(cmd):
    # ??????

print run_command('mysqladmin create test -uroot -pmysqladmin12')
# Should output something like:
# mysqladmin: CREATE DATABASE failed; error: 'Can't create database 'test'; database exists'

","Something like that:
def runProcess(exe):    
    p = subprocess.Popen(exe, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
    while(True):
      retcode = p.poll() #returns None while subprocess is running
      line = p.stdout.readline()
      yield line
      if(retcode is not None):
        break

Note, that I'm redirecting stderr to stdout, it might not be exactly what you want, but I want error messages also.
This function yields line by line as they come (normally you'd have to wait for subprocess to finish to get the output as a whole).
For your case the usage would be:
for line in runProcess('mysqladmin create test -uroot -pmysqladmin12'.split()):
    print line,

"
"[INST] How do I check whether a file exists, without using the try statement?
 [/INST] I'm not sure I understand the try statement but I'm going to try to be more concise.
I'm working on a project where I'm going to be using try: except with: and I'm not in the habit of using try: except:
from pymouth import *

def main():
    try:
        #do something here
        #do something else
    except:
        #do something else

if you want to do the same thing in the reverse order, you can do:
try:
    #do something else
except:
    #do some same thing

pymouth is a nice word. But how do you go about doing ""do something"" in the Python interpreter?
 [/INST] @Pythonista
I think the most concise way to express that is:
try:
    # do something that fails
except:
    # do something that succeeds

In the body of the try: except: pass is a Python statement. It follows the standard idiom of raising an exception.
In this example, do:
try:
    # do something that fails
except:
    # do something that succeeds

In the idiom of raising an exception:
try:
    # do something that fails
except:
    # do something that succeeds

In this example, the try: except: pass is redundant.
It is superfluous to raise an exception on a failure. If you want to do something that fails, you can do this in the except: pass:
>>> from pymouth import do_something
>>> try()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
    raise:
  NameError(io)

Python's SPAM mechanism is a hack that can be made more general. It skips the except: clause on both sides of the except: clause, so it's actually a triple:
>>> from pymouth import do_something
Traceback (most recent call last):
  File ""spam.py"", line 1, in <module>
    Raising a exception","How do I check whether a file exists, without using the try statement?
","In Python 3.4 the language provides a new module to manage files:
import pathlib
path = pathlib.Path('path/to/file')
if path.is_file(): # if you want to check a directory: path.is_dir()
    # if it is true, return true on your code

"
"[INST] How do I check whether a file exists, without using the try statement?
 [/INST] from http://www.python.org/
http://www.python.org/
/
/a/b/c/
/d/
/e/

@m/a/b/c/
@m/b/c/

  /m/b/c/
/m/b/c/

The /m/b/c/
are /m/b/c/
Are /m/b/c/

I've seen these examples before and/
@m/b/c/
and /m/b/c/
and /m/b/c/

These examples are valid if you want to use only one instance of /m/b/c/ or /m/b/c/
@m/b/c/

 [/m/b/c/]
@m/b/c/

 [m/b/c/]
@m/b/c/

 [m/b/c/]
@m/b/c/

@m/b/c/

These are valid instances of /m/b/c/

@m/b/c/

@m/b/c/

 [m/b/c/]

@m/b/c/

@m/b/c/

@m/b/c/

These are valid instances of @m/b/c/
@m/b/c/

@m/b/c/

@m/b/c/

@m/b/c/

@m/b/c/

These are valid instances of @m/b/c ():
@m/b/c
@m/b/c/

@m/b/c/

@m/b/c//

 @m/b/c/

@m/b/c/]

@m/b/c/

@m/b/c//

@m/b/c/

@m/b/c//
@m/","How do I check whether a file exists, without using the try statement?
","You can use following open method to check if file exists + readable
open(inputFile, 'r')

"
"[INST] How can I output colored text to the terminal, in Python?
What is the best Unicode symbol to represent a solid block?
 [/INST] I've searched high and low and I found that the best way to do this is with the ""with"" operator
code = """"""\n{}
@code
{}

...

code = """"""\n0123342101233421012342101233421"",
                   ...

@code2
@b1
@c
@b3

...

to ""\"""",
@b2
...

@c ""
@c with ""
...


@m2
@m3
@n2
...

  /usr/local/bin/m2/m2""
@m2/
/usr/local/m2/
/usr/local/m2/
/usr/local/m2/
/usr/local/m2/
/usr/local/m2/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr/local/c/
/usr/local/m2/
/usr","How can I output colored text to the terminal, in Python?
What is the best Unicode symbol to represent a solid block?
","Stupidly simple based on @joeld's answer
class PrintInColor:
    RED = '\033[91m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    LIGHT_PURPLE = '\033[94m'
    PURPLE = '\033[95m'
    END = '\033[0m'

    @classmethod
    def red(cls, s, **kwargs):
        print(cls.RED + s + cls.END, **kwargs)

    @classmethod
    def green(cls, s, **kwargs):
        print(cls.GREEN + s + cls.END, **kwargs)

    @classmethod
    def yellow(cls, s, **kwargs):
        print(cls.YELLOW + s + cls.END, **kwargs)

    @classmethod
    def lightPurple(cls, s, **kwargs):
        print(cls.LIGHT_PURPLE + s + cls.END, **kwargs)

    @classmethod
    def purple(cls, s, **kwargs):
        print(cls.PURPLE + s + cls.END, **kwargs)

Then just
PrintInColor.red('hello', end=' ')
PrintInColor.green('world')

"
"[INST] How can I convert the str representation of a dict, such as the following string, into a dict?
s = ""{'muffin' : 'lolz', 'foo' : 'kitty'}""

I prefer not to use eval. What else can I use?
The main reason for this, is one of my coworkers classes he wrote, converts all input into strings. I'm not in the mood to go and modify his classes, to deal with this issue.
 [/INST] If you'd like to avoid the input of strings, you can do this:
input = raw_input(""Enter your input: "")
input = input.split("" "" )

It's pretty simple, just copy-paste the input into your input.
  if len(input) == 1:
    print(""input was not valid - please input the input again""

  if len(input) == 1:
    print(""input was valid - please input the input again"")

This is because the input was already processed by the input (s input was just a list of strings) and you're trying to get the string to be your input.
  if len(input) == 1:
    print(""input was valid - you should not use this input"")

  #...

  if len(input) == 1:
    print(""input was valid - you should use this input"")

  if you wish to input a dictionary of strings, input = input
    my_dict = dict(input=input)
  if len(input) == 1:
    print(""input was not valid - you should use this input the input was given""

  if not input == """":
    ""input was not valid - you should not use this input""

  if len(input) == """":
    ""input was not valid - you should use this input""

  if len(input) == """":
    ""input was not valid - you should input your input""

  if len(input) == """":
    ""input was not valid""

The above example uses a for loop to iterate over the input. However, this is a bit tricky, because it requires you to input a list","How can I convert the str representation of a dict, such as the following string, into a dict?
s = ""{'muffin' : 'lolz', 'foo' : 'kitty'}""

I prefer not to use eval. What else can I use?
The main reason for this, is one of my coworkers classes he wrote, converts all input into strings. I'm not in the mood to go and modify his classes, to deal with this issue.
","http://docs.python.org/2/library/json.html
JSON can solve this problem though its decoder wants double quotes around keys and values.  If you don't mind a replace hack...
import json
s = ""{'muffin' : 'lolz', 'foo' : 'kitty'}""
json_acceptable_string = s.replace(""'"", ""\"""")
d = json.loads(json_acceptable_string)
# d = {u'muffin': u'lolz', u'foo': u'kitty'}

NOTE that if you have single quotes as a part of your keys or values this will fail due to improper character replacement. This solution is only recommended if you have a strong aversion to the eval solution.
More about json single quote: jQuery single quote in JSON response
"
"[INST] So, I started learning to code in Python and later Django. The first times it was hard looking at tracebacks and actually figure out what I did wrong and where the syntax error was. Some time has passed now and some way along the way, I guess I got a routine in debugging my Django code. As this was done early in my coding experience, I sat down and wondered if how I was doing this was ineffective and could be done faster. I usually manage to find and correct the bugs in my code, but I wonder if I should be doing it faster?
I usually just use the debug info Django gives when enabled. When things do end up as I thought it would, I break the code flow a lot with a syntax error, and look at the variables at that point in the flow to figure out, where the code does something other than what I wanted.
But can this be improved? Are there some good tools or better ways to debug your Django code?
 [/INST] I think this is an approach that might be helpful if you're dealing with more complex code:
from django.utils import debug
def wrap_with_debug(func, c_debug):
    return func(func)

def func(func, p, c_debug):
    try:
        return p, c_debug + 6, func, p.c_traceback
    return p.traceback

And then you can wrap the call to p in a decorator, i.e. def func(func, p=True):
    @fun = p.function
    def fun_with_debug(func, c_debug):
        return p.c_traceback + func
    def wrap_with_debug(func, p, c_debug):
        return func, p.c_debug + 6, p.c_debug
    def fun(func):
        print p.c_traceback + p.c_debug
        print 'fun is', p.c_debug
        return

@fun = p.c_debug
@wrap_with_debug.c_debug
def fun(func, c_debug, p=True):
    print p.c_debug + 6

And then you can just print p.c_debug +","So, I started learning to code in Python and later Django. The first times it was hard looking at tracebacks and actually figure out what I did wrong and where the syntax error was. Some time has passed now and some way along the way, I guess I got a routine in debugging my Django code. As this was done early in my coding experience, I sat down and wondered if how I was doing this was ineffective and could be done faster. I usually manage to find and correct the bugs in my code, but I wonder if I should be doing it faster?
I usually just use the debug info Django gives when enabled. When things do end up as I thought it would, I break the code flow a lot with a syntax error, and look at the variables at that point in the flow to figure out, where the code does something other than what I wanted.
But can this be improved? Are there some good tools or better ways to debug your Django code?
","From my perspective, we could break down common code debugging tasks into three distinct usage patterns:

Something has raised an exception: runserver_plus' Werkzeug debugger to the rescue. The ability to run custom code at all the trace levels is a killer. And if you're completely stuck, you can create a Gist to share with just a click.
Page is rendered, but the result is wrong: again, Werkzeug rocks. To make a breakpoint in code, just type assert False in the place you want to stop at.
Code works wrong, but the quick look doesn't help. Most probably, an algorithmic problem. Sigh. Then I usually fire up a console debugger PuDB: import pudb; pudb.set_trace(). The main advantage over [i]pdb is that PuDB (while looking as you're in 80's) makes setting custom watch expressions a breeze. And debugging a bunch of nested loops is much simpler with a GUI.

Ah, yes, the templates' woes. The most common (to me and my colleagues) problem is a wrong context: either you don't have a variable, or your variable doesn't have some attribute. If you're using debug toolbar, just inspect the context at the ""Templates"" section, or, if it's not sufficient, set a break in your views' code just after your context is filled up.
So it goes.
"
"[INST] I need a way to get a dictionary value if its key exists, or simply return None, if it does not.
However, Python returns a key_error if you search for a key that does not exist. I know that I can check for the key, but I am looking for something more explicit. Is there a way to just return None if the key does not exist ?
 [/INST] You can do this:
if 'key' in dict:
    return dict['key']
else:
    return dict['key']

  # Example:
d = {'key1': 'key1', 'key2': 'key2'}
d['key2'] = 1
d.get('key1')

  # Return: [None, 'key2']

If you want to check if a key exists using ""key1"" you can use:
if 'key1' in dict:
    print ""key1 not found""

  # Check if key1 exists, e.g. 'key2' in dict
    print ""key2 does not exist""

  # Check if key1 exists, e.g. ""key2""
d.get('key1') # returns: 0

  # Check if 'key1' exists, e.g. ""key2""
d.get('key2') # returns: 1

If you want to check multiple keys, you can use:
d.keys()

  # Check if a key exists, e.g. ""key2"" and 'key1'
d.keys() # e.g. ""key2""

  # Check if a key does not exist, e.g. ""key2"" exists?

# Check if a key exists, e.g. ""key1, key2""
d.keys() # e.g. ""key2""

  # Check if a key exists, e.g. ""key2"" exists?
d.keys() # return: [key2, key2]

  # Check if a key exists, e.g. ""key2"" exists
if ""key1"" in dict:
  if ""key2"" in dict:
    print ""key2""

  # Check","I need a way to get a dictionary value if its key exists, or simply return None, if it does not.
However, Python returns a key_error if you search for a key that does not exist. I know that I can check for the key, but I am looking for something more explicit. Is there a way to just return None if the key does not exist ?
","If you want a more transparent solution, you can subclass dict to get this behavior:
class NoneDict(dict):
    def __getitem__(self, key):
        return dict.get(self, key)

>>> foo = NoneDict([(1,""asdf""), (2,""qwerty"")])
>>> foo[1]
'asdf'
>>> foo[2]
'qwerty'
>>> foo[3] is None
True

"
"[INST] I recently came across the pandas library for python, which according to this benchmark performs very fast in-memory merges.  It's even faster than the data.table package in R (my language of choice for analysis).
Why is pandas so much faster than data.table?  Is it because of an inherent speed advantage python has over R, or is there some tradeoff I'm not aware of?  Is there a way to perform inner and outer joins in data.table without resorting to merge(X, Y, all=FALSE) and merge(X, Y, all=TRUE)?

Here's the R code and the Python code used to benchmark the various packages.
 [/INST] I'll add that most of the answers are written in the spirit of Numpy, so if you are interested in a more advanced approach, you can look into the numpy.core_dtypes.py file. This is a short summary:

def inner(data, a=False, x=True):
    return all(X, Y, a, True)
    def outer(data, Y, a=False):
        return numpy.array(data, a=True, x=False)

    def inner(data, a=True, x=False):
        return all(X, Y, a)

    def all(a, b, c):
        return all(X, Y, a=True)
    def inner(X, Y, c):
        return all(X, Y, a=True)
    def all(X, Y, a=True):
        return numpy.array(X, Y, a=True, Y=False, a=True)

from numpy import array, numpy, Trinity
x = numpy.array(X, Y, a=True, a=False))
b = numpy.array(X, Y, a=True, z=False)

for a b=array(X, Y, Z))
    if a==b:
        return a+b
    if a==b:
        return a+b

http://www.lopen.org/~gohlke/~holt/holt/holt/trinity/
http://www","I recently came across the pandas library for python, which according to this benchmark performs very fast in-memory merges.  It's even faster than the data.table package in R (my language of choice for analysis).
Why is pandas so much faster than data.table?  Is it because of an inherent speed advantage python has over R, or is there some tradeoff I'm not aware of?  Is there a way to perform inner and outer joins in data.table without resorting to merge(X, Y, all=FALSE) and merge(X, Y, all=TRUE)?

Here's the R code and the Python code used to benchmark the various packages.
","It looks like Wes may have discovered a known issue in data.table when the number of unique strings (levels) is large: 10,000.
Does Rprof() reveal most of the time spent in the call sortedmatch(levels(i[[lc]]), levels(x[[rc]])?  This isn't really the join itself (the algorithm), but a preliminary step.
Recent efforts have gone into allowing character columns in keys, which should resolve that issue by integrating more closely with R's own global string hash table. Some benchmark results are already reported by test.data.table() but that code isn't hooked up yet to replace the levels to levels match.
Are pandas merges faster than data.table for regular integer columns?  That should be a way to isolate the algorithm itself vs factor issues.
Also, data.table has time series merge in mind. Two aspects to that: i) multi column ordered keys such as (id,datetime) ii) fast prevailing join (roll=TRUE) a.k.a. last observation carried forward.
I'll need some time to confirm as it's the first I've seen of the comparison to data.table as presented.

UPDATE from data.table v1.8.0 released July 2012

Internal function sortedmatch() removed and replaced with chmatch()
       when matching i levels to x levels for columns of type 'factor'. This
       preliminary step was causing a (known) significant slowdown when the number
       of levels of a factor column was large (e.g. >10,000). Exacerbated in
       tests of joining four such columns, as demonstrated by Wes McKinney
       (author of Python package Pandas). Matching 1 million strings of which
       of which 600,000 are unique is now reduced from 16s to 0.5s, for example.

also in that release was :

character columns are now allowed in keys and are preferred to
factor. data.table() and setkey() no longer coerce character to
factor. Factors are still supported. Implements FR#1493, FR#1224
and (partially) FR#951.
New functions chmatch() and %chin%, faster versions of match()
and %in% for character vectors. R's internal string cache is
utilised (no hash table is built). They are about 4 times faster
than match() on the example in ?chmatch.

As of Sep 2013 data.table is v1.8.10 on CRAN and we're working on v1.9.0. NEWS is updated live.

But as I wrote originally, above :

data.table has time series merge in mind. Two aspects to that: i)
  multi column ordered keys such as (id,datetime) ii) fast prevailing
  join (roll=TRUE) a.k.a. last observation carried forward.

So the Pandas equi join of two character columns is probably still faster than data.table. Since it sounds like it hashes the combined two columns. data.table doesn't hash the key because it has prevailing ordered joins in mind. A ""key"" in data.table is literally just the sort order (similar to a clustered index in SQL; i.e., that's how the data is ordered in RAM). On the list is to add secondary keys, for example.
In summary, the glaring speed difference highlighted by this particular two-character-column test with over 10,000 unique strings shouldn't be as bad now, since the known problem has been fixed.
"
"[INST] I got a list of dictionaries and want that to be sorted by a value of that dictionary.
This
[{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]

sorted by name, should become
[{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]

 [/INST] sorted by string, key=str, value=39, compare=Homer, val=39]

  d = {'name':'Bart', 'age':39}
  d.sorted(key='name, val=39)

  d.sorted_by_key='name'

  d = {'name':'Homer', 'age':39}
  d.sorted_by_key('name', 'age'):
  d.sorted_by_key('name', 'age'):

  d = {'name':'Bart', 'age':10, 'lname': 'Homer', 'age':10}

  d = {('name':'Homer', 'age':39}, ('name':'Homer', 'age':10)}

  d.sorted_by_key('name', 'age'):
  d.sorted_by_key('name'): d.key('name', 'age'): d.sorted_by_key('lname'): d.key('name', 'age'): d.sorted_by_key('lname', 'age'):

  supr(Homer, 'age', 39):
  l = { 'name': 'Homer', 'age':10}
  d.sorted_by_name('name', 'age'):

  supr is not the dict, and this way it doesn't sort the dictionaries properly.
  d.sorted_by_name, 'l':'Homer', 'age':10} = d.sorted_by_name, 'name':'Bart', 'age':10}

  d = d.sorted_by_name

  d = d.sorted","I got a list of dictionaries and want that to be sorted by a value of that dictionary.
This
[{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]

sorted by name, should become
[{'name':'Bart', 'age':10}, {'name':'Homer', 'age':39}]

","Using Schwartzian transform from Perl,
py = [{'name':'Homer', 'age':39}, {'name':'Bart', 'age':10}]

do
sort_on = ""name""
decorated = [(dict_[sort_on], dict_) for dict_ in py]
decorated.sort()
result = [dict_ for (key, dict_) in decorated]

gives
>>> result
[{'age': 10, 'name': 'Bart'}, {'age': 39, 'name': 'Homer'}]

More on Perl Schwartzian transform

In computer science, the Schwartzian transform is a Perl programming
  idiom used to improve the efficiency of sorting a list of items. This
  idiom is appropriate for comparison-based sorting when the ordering is
  actually based on the ordering of a certain property (the key) of the
  elements, where computing that property is an intensive operation that
  should be performed a minimal number of times. The Schwartzian
  Transform is notable in that it does not use named temporary arrays.

"
"[INST] I'm searching for the fastest way to know if a value exists in a list (a list with millions of values in it) and what its index is? I know all values in the list are unique like my example.
My first methods I try is(3.8sec in my real code):
a = [4,2,3,1,5,6]

if a.count(7) == 1:
    b=a.index(7)
    ""Do something with variable b""

My second methods I try is (2x faster:1.9sec on my real code):
a = [4,2,3,1,5,6]

try:
    b=a.index(7)
except ValueError:
    ""Do nothing""
Else:
    ""Do something with variable b""

Proposed methods from S.O. user (2.74sec on my real code):
a = [4,2,3,1,5,6]
if 7 in a:
    a.index(7)

In my real code , first method take 3.81sec and the second methods take 1.88sec.
It's a good improvement but:
I'm a beginner with Python/scripting and I want to know if a fastest way exist to do the same things and save more process time?
More specific explication for my application:
In the API of blender a can access to a list of particles:
particles = [1,2,3,4...etc.]

From there , I can access to it's location:
particles[x].location = [x,y,z]

And I test for each particles if a neighbour exist by searching
in the location of each particles like:
if [x+1,y,z] in particles.location
    ""find the identity of this neighbour particles in x:the index 
    of the particles array""
    particles.index([x+1,y,z])

 [/INST] I think you'd better off doing:
if 'x' in mylist:
    print ""locations found in x""

  -1,2-3,","I'm searching for the fastest way to know if a value exists in a list (a list with millions of values in it) and what its index is? I know all values in the list are unique like my example.
My first methods I try is(3.8sec in my real code):
a = [4,2,3,1,5,6]

if a.count(7) == 1:
    b=a.index(7)
    ""Do something with variable b""

My second methods I try is (2x faster:1.9sec on my real code):
a = [4,2,3,1,5,6]

try:
    b=a.index(7)
except ValueError:
    ""Do nothing""
Else:
    ""Do something with variable b""

Proposed methods from S.O. user (2.74sec on my real code):
a = [4,2,3,1,5,6]
if 7 in a:
    a.index(7)

In my real code , first method take 3.81sec and the second methods take 1.88sec.
It's a good improvement but:
I'm a beginner with Python/scripting and I want to know if a fastest way exist to do the same things and save more process time?
More specific explication for my application:
In the API of blender a can access to a list of particles:
particles = [1,2,3,4...etc.]

From there , I can access to it's location:
particles[x].location = [x,y,z]

And I test for each particles if a neighbour exist by searching
in the location of each particles like:
if [x+1,y,z] in particles.location
    ""find the identity of this neighbour particles in x:the index 
    of the particles array""
    particles.index([x+1,y,z])

","7 in a

Clearest and fastest way to do it.
You can also consider using a set, but constructing that set from your list may take more time than faster membership testing will save. The only way to be certain is to benchmark well. (this also depends on what operations you require)
"
"[INST] from mechanize import Browser
br = Browser()
br.open('http://somewebpage')
html = br.response().readlines()
for line in html:
  print line

When printing a line in an HTML file, I'm trying to find a way to only show the contents of each HTML element and not the formatting itself. If it finds '<a href=""whatever.com"">some text</a>', it will only print 'some text', '<b>hello</b>' prints 'hello', etc. How would one go about doing this?
 [/INST] I've found that if you want to only show the contents of each HTML element (as opposed to the context in which they were originally defined) you can do:
for line in html:
    print line.rstrip()

  which, I think, is cleaner, 
  I'm not sure if it's just a matter of taste.
  if len(html) == 0:
    print html

  I think this is more pythonic than doing the wiess ""for each line in the HTML"" thing, but I'm not sure why it's getting more and only contextual information when I want to do the same thing in contexts where I would actually want to do ""for every line in the HTML"".
For example, given this HTML: <table> <tr> <td>some text</td>
  <tr> <td>some more text</td>
  </tr>

You can easily go iterate over the elements in the HTML element and then do for each line, just change the contexts.
For example, if you want to print the first line, and only the second line, you can do:
for line in html:
  print line

This way you can change the context to be <table> instead of <tr> and then go <td>some other way</td>
  in
  if len(lines) == 0:
    print line[0]
  if len(lines) == 1:
    print line[1]

if len(lines) == len(already_used):
  print lines[0]

This way you only need to iterate over the","from mechanize import Browser
br = Browser()
br.open('http://somewebpage')
html = br.response().readlines()
for line in html:
  print line

When printing a line in an HTML file, I'm trying to find a way to only show the contents of each HTML element and not the formatting itself. If it finds '<a href=""whatever.com"">some text</a>', it will only print 'some text', '<b>hello</b>' prints 'hello', etc. How would one go about doing this?
","Short version!
import re, cgi
tag_re = re.compile(r'(<!--.*?-->|<[^>]*>)')

# Remove well-formed tags, fixing mistakes by legitimate users
no_tags = tag_re.sub('', user_input)

# Clean up anything else by escaping
ready_for_web = cgi.escape(no_tags)

Regex source: MarkupSafe.  Their version handles HTML entities too, while this quick one doesn't.
Why can't I just strip the tags and leave it?
It's one thing to keep people from <i>italicizing</i> things, without leaving is floating around.  But it's another to take arbitrary input and make it completely harmless.  Most of the techniques on this page will leave things like unclosed comments (<!--) and angle-brackets that aren't part of tags (blah <<<><blah) intact.  The HTMLParser version can even leave complete tags in, if they're inside an unclosed comment.
What if your template is {{ firstname }} {{ lastname }}?  firstname = '<a' and lastname = 'href=""http://evil.com/"">' will be let through by every tag stripper on this page (except @Medeiros!), because they're not complete tags on their own.  Stripping out normal HTML tags is not enough.
Django's strip_tags, an improved (see next heading) version of the top answer to this question, gives the following warning:

Absolutely NO guarantee is provided about the resulting string being HTML safe. So NEVER mark safe the result of a strip_tags call without escaping it first, for example with escape().

Follow their advice!
To strip tags with HTMLParser, you have to run it multiple times.
It's easy to circumvent the top answer to this question.
Look at this string (source and discussion):
<img<!-- --> src=x onerror=alert(1);//><!-- -->

The first time HTMLParser sees it, it can't tell that the <img...> is a tag.  It looks broken, so HTMLParser doesn't get rid of it.  It only takes out the <!-- comments -->, leaving you with
<img src=x onerror=alert(1);//>

This problem was disclosed to the Django project in March, 2014.  Their old strip_tags was essentially the same as the top answer to this question.  Their new version basically runs it in a loop until running it again doesn't change the string:
# _strip_once runs HTMLParser once, pulling out just the text of all the nodes.

def strip_tags(value):
    """"""Returns the given HTML with all tags stripped.""""""
    # Note: in typical case this loop executes _strip_once once. Loop condition
    # is redundant, but helps to reduce number of executions of _strip_once.
    while '<' in value and '>' in value:
        new_value = _strip_once(value)
        if len(new_value) >= len(value):
            # _strip_once was not able to detect more tags
            break
        value = new_value
    return value

Of course, none of this is an issue if you always escape the result of strip_tags().
Update 19 March, 2015: There was a bug in Django versions before 1.4.20, 1.6.11, 1.7.7, and 1.8c1.  These versions could enter an infinite loop in the strip_tags() function.  The fixed version is reproduced above.  More details here.
Good things to copy or use
My example code doesn't handle HTML entities - the Django and MarkupSafe packaged versions do.
My example code is pulled from the excellent MarkupSafe library for cross-site scripting prevention.  It's convenient and fast (with C speedups to its native Python version).  It's included in Google App Engine, and used by Jinja2 (2.7 and up), Mako, Pylons, and more.  It works easily with Django templates from Django 1.7.
Django's strip_tags and other html utilities from a recent version are good, but I find them less convenient than MarkupSafe.  They're pretty self-contained, you could copy what you need from this file.
If you need to strip almost all tags, the Bleach library is good.  You can have it enforce rules like ""my users can italicize things, but they can't make iframes.""
Understand the properties of your tag stripper!  Run fuzz tests on it!  Here is the code I used to do the research for this answer.
sheepish note - The question itself is about printing to the console, but this is the top Google result for ""python strip html from string"", so that's why this answer is 99% about the web.
"
"[INST] I would like to use argparse to parse boolean command-line arguments written as ""--foo True"" or ""--foo False"". For example:
my_program --my_boolean_flag False

However, the following test code does not do what I would like:
import argparse
parser = argparse.ArgumentParser(description=""My parser"")
parser.add_argument(""--my_bool"", type=bool)
cmd_line = [""--my_bool"", ""False""]
parsed_args = parser.parse(cmd_line)

Sadly, parsed_args.my_bool evaluates to True. This is the case even when I change cmd_line to be [""--my_bool"", """"], which is surprising, since bool("""") evalutates to False.
How can I get argparse to parse ""False"", ""F"", and their lower-case variants to be False?
 [/INST] The --my_bool flag is a standard convention in the Python world, and you should be careful not to overload the ""--my_bool"" term with a default value of False, unless you have specified a different type of command-line argument.
--my_bool False

This is documented in the --my-bool command of the Python type system. --my_bool is False by default, and --bool is True by default.
This behaviour is not in the spirit of the ""--my-bool"" type of command-line interfaces, but you can get around it by writing a function that accepts bool as the first parameter, and then adds a ""--my_bool"" flag if needed.
def my_bool(bool):
    return '--my_bool'

def main():
    cmd_line = [""--my_bool"", ""--my_bool""]
    command_line = [bool(bool) for bool in [False, True])
    if command_bool == True:
        command_line = [--my_bool""]
        if command_bool == ""False"":
            command_line = "" --my_bool""
        return

--my_bool is a boolean flag that can be passed as a parameter in the command line.
  # my_bool is False by default

--my_bool is False in the usual sense","I would like to use argparse to parse boolean command-line arguments written as ""--foo True"" or ""--foo False"". For example:
my_program --my_boolean_flag False

However, the following test code does not do what I would like:
import argparse
parser = argparse.ArgumentParser(description=""My parser"")
parser.add_argument(""--my_bool"", type=bool)
cmd_line = [""--my_bool"", ""False""]
parsed_args = parser.parse(cmd_line)

Sadly, parsed_args.my_bool evaluates to True. This is the case even when I change cmd_line to be [""--my_bool"", """"], which is surprising, since bool("""") evalutates to False.
How can I get argparse to parse ""False"", ""F"", and their lower-case variants to be False?
","I was looking for the same issue, and imho the pretty solution is :
def str2bool(v):
  return v.lower() in (""yes"", ""true"", ""t"", ""1"")

and using that to parse the string to boolean as suggested above.
"
"[INST] For example I have two dicts:
Dict A: {'a':1, 'b':2, 'c':3}
Dict B: {'b':3, 'c':4, 'd':5}

I need a pythonic way of 'combining' two dicts such that the result is :
{'a':1, 'b':5, 'c':7, 'd':5}

That is to say: if a key appears in both dicts, add their values, if it appears in only one dict, keep its value.
 [/INST] If you only need to combine two dicts in one, you can do this:
b = {'a':1, 'c':5, 'd':5}

b.keys() == ['a', 'c', 'd']

b.keys() == ['a', 'c', 'd']

  - if a key appears in both dicts, the result is :
   ('a':1, 'c':5, 'd':5})

from collections import defaultdict
m = {
   'a':1,
   'b':5,
   'c':7,
   'd':8}

def add_dict(a,b,c):
   if a == b:
   return a + b
   if a == b:   return b

def add_dict(c,d):
   return [a, b, 'c']

def A(a,b,c):
   if a == b:   return {'a':b, 'c':b}
   if b == 'c':   return {'c':b, 'd':d}

def A_from_dict(a):
   b = {'a':b, 'c':b}
   return (A+dict(a), b, c)

from collections import defaultdict
a = [('b', 'c), 'd': 'd'])

def B_from_dict(a):
   return {'b':a, 'c':b}

>>> A = dict()
>>> B = {'a':b, 'c':d}
>>> B = B.get(('b':1, 'c':","For example I have two dicts:
Dict A: {'a':1, 'b':2, 'c':3}
Dict B: {'b':3, 'c':4, 'd':5}

I need a pythonic way of 'combining' two dicts such that the result is :
{'a':1, 'b':5, 'c':7, 'd':5}

That is to say: if a key appears in both dicts, add their values, if it appears in only one dict, keep its value.
",">>> A = {'a':1, 'b':2, 'c':3}
>>> B = {'b':3, 'c':4, 'd':5}
>>> c = {x: A.get(x, 0) + B.get(x, 0) for x in set(A).union(B)}
>>> print(c)

{'a': 1, 'c': 7, 'b': 5, 'd': 5}

"
"[INST] I have a df :
>>> df
                 STK_ID  EPS  cash
STK_ID RPT_Date                   
601166 20111231  601166  NaN   NaN
600036 20111231  600036  NaN    12
600016 20111231  600016  4.3   NaN
601009 20111231  601009  NaN   NaN
601939 20111231  601939  2.5   NaN
000001 20111231  000001  NaN   NaN

Then I just want the records whose EPS is not NaN, that is, df.drop(....) will return the dataframe as below:
                  STK_ID  EPS  cash
STK_ID RPT_Date                   
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN

How to do that ?
 [/INST]agliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliadorfagliadorfdorfagliadorfdorfagliaagliaagliadorfdorfagliadorfagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaagliaaglia","I have a df :
>>> df
                 STK_ID  EPS  cash
STK_ID RPT_Date                   
601166 20111231  601166  NaN   NaN
600036 20111231  600036  NaN    12
600016 20111231  600016  4.3   NaN
601009 20111231  601009  NaN   NaN
601939 20111231  601939  2.5   NaN
000001 20111231  000001  NaN   NaN

Then I just want the records whose EPS is not NaN, that is, df.drop(....) will return the dataframe as below:
                  STK_ID  EPS  cash
STK_ID RPT_Date                   
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN

How to do that ?
","You could use dataframe method notnull or inverse of isnull, or numpy.isnan:
In [332]: df[df.EPS.notnull()]
Out[332]:
   STK_ID  RPT_Date  STK_ID.1  EPS  cash
2  600016  20111231    600016  4.3   NaN
4  601939  20111231    601939  2.5   NaN


In [334]: df[~df.EPS.isnull()]
Out[334]:
   STK_ID  RPT_Date  STK_ID.1  EPS  cash
2  600016  20111231    600016  4.3   NaN
4  601939  20111231    601939  2.5   NaN


In [347]: df[~np.isnan(df.EPS)]
Out[347]:
   STK_ID  RPT_Date  STK_ID.1  EPS  cash
2  600016  20111231    600016  4.3   NaN
4  601939  20111231    601939  2.5   NaN

"
"[INST] How do I delete a file or folder in Python?
I am using the Python scripting language running on the Windows XP operating system.
 [/INST] from http://www.python-institute.com/en/scripts/PE.py
def __main__():
    # define Python scripting language
    # scripting language
    #  define python scripting language
    # scripting language
    # define http://www.pythonpe.com/?
    # define http://www.pythonpe.com/?
    # define http://www.pythonpe.com/?
    # define __main__()

  /Users/INSTALL, define http://?

    # define http://www.pythonpe.com/?
    # define http://?
    # define http://?

 [/INST] def __main__():
    # define http:
    # define http:
    # define http://?
    # define http:
    # define http://
    # define http (
    # a/
    # define http://
    # a/
    # a/

# define __main__():
    # a/
    # define http:
        # define http:
        # define http:
        # define http:
    # define http:
        # define http:
        # define http:
        # define http

I/a/
# define http:
    # define http:

 [/INST] def __main():
    # define http:
        # define http:

    # define http:

 [/a/1]
def __main():
    # define http:
    # define http:

 [/a/]
def __main():
    # define http:
    # define http:
    # define http:
    # define __main():

 [/a/1]
def __main():
    # define http:
    # define http:
    # define http:
    # define __main():
","How do I delete a file or folder in Python?
I am using the Python scripting language running on the Windows XP operating system.
","os.remove() will remove a file.
os.rmdir() will remove an empty directory.
shutil.rmtree() will delete a directory and all its contents.
"
"[INST] pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?
 [/INST] I've had a really nice experience with easy_install on Windows 7, it just works and is really fast (and clean, on both Python and IPython).
http://pypi.python.org/simple/install/
http://code.google.com/p/gettingstartedwithpython
http://www.skymem.com/gettingstartedwithpython/
http://www.skymem.com/gettingstartwithpython/
http://www.skymem.com/gettingstartwithpython/
I used this code to install everything I needed: from skylit import easy_install
from skylit import easy_install
print ""installing required packages:  ""
print ""gotcha!""

and the actual installation message: ""installing required packages:  ""

http://skylit.skymem.com/gettingstartwithpython/installing_with_installers/
http://skylit.skymet/gettingstartwithpython/installers/
http://www.skylit.skymem.com/gettingstartwithpython/installers/
http://skylit.skymet/installers/gettingstartwithpython/installers/lxml
http://skymet.skymet.com/gettingstartwithpython/installers/lxml

I've gotten really really fast at installing on Linux. I just wish I could do it with windows, since I don't have to keep running.py files in the command line, and I don't have to keep running the command line.
http://skymet.skymet.com/lxml
and also: http://www.skymem.com/lxml/
and/or
http://www.skymem.com/lxml/
and/or
http://www.skymem.com/lxml/
and/or
import simple_install

And/or
http://www.skymet.com/lxml/
and/or
[/INST] simple_install","pip is a replacement for easy_install. But should I install pip using easy_install on Windows?  Is there a better way?
","Python 2.7.9+ and 3.4+
Good news! Python 3.4 (released March 2014) and Python 2.7.9 (released December 2014) ship with Pip. This is the best feature of any Python release. It makes the community's wealth of libraries accessible to everyone. Newbies are no longer excluded from using community libraries by the prohibitive difficulty of setup. In shipping with a package manager, Python joins Ruby, Node.js, Haskell, Perl, Go--almost every other contemporary language with a majority open-source community. Thank you Python.
Of course, that doesn't mean Python packaging is problem solved. The experience remains frustrating. I discuss this in Stack Overflow question Does Python have a package/module management system?.
And, alas for everyone using Python 2.7.8 or earlier (a sizable portion of the community). There's no plan to ship Pip to you. Manual instructions follow.
Python 2 â¤ 2.7.8 and Python 3 â¤ 3.3
Flying in the face of its 'batteries included' motto, Python ships without a package manager. To make matters worse, Pip was--until recently--ironically difficult to install.
Official instructions
Per http://www.pip-installer.org/en/latest/installing.html:
Download get-pip.py, being careful to save it as a .py file rather than .txt. Then, run it from the command prompt:
python get-pip.py

You possibly need an administrator command prompt to do this. Follow Start a Command Prompt as an Administrator (Microsoft TechNet).
Alternative instructions
The official documentation tells users to install Pip and each of its dependencies from source. That's tedious for the experienced, and prohibitively difficult for newbies.
For our sake, Christoph Gohlke prepares Windows installers (.msi) for popular Python packages. He builds installers for all Python versions, both 32 and 64 bit. You need to

Install setuptools
Install pip

For me, this installed Pip at C:\Python27\Scripts\pip.exe. Find pip.exe on your computer, then add its folder (for example, C:\Python27\Scripts) to your path (Start / Edit environment variables). Now you should be able to run pip from the command line. Try installing a package:
pip install httpie

There you go (hopefully)! Solutions for common problems are given below:
Proxy problems
If you work in an office, you might be behind a HTTP proxy. If so, set the environment variables http_proxy and https_proxy. Most Python applications (and other free software) respect these. Example syntax:
http://proxy_url:port
http://username:password@proxy_url:port

If you're really unlucky, your proxy might be a Microsoft NTLM proxy. Free software can't cope. The only solution is to install a free software friendly proxy that forwards to the nasty proxy. http://cntlm.sourceforge.net/
Unable to find vcvarsall.bat
Python modules can be part written in C or C++. Pip tries to compile from source. If you don't have a C/C++ compiler installed and configured, you'll see this cryptic error message.

Error: Unable to find vcvarsall.bat

You can fix that by installing a C++ compiler such as MinGW or Visual C++. Microsoft actually ship one specifically for use with Python. Or try Microsoft Visual C++ Compiler for Python 2.7.
Often though it's easier to check Christoph's site for your package.
"
"[INST] I want to create a list of dates, starting with today, and going back an arbitrary number of days, say, in my example 100 days. Is there a better way to do it than this?
import datetime

a = datetime.datetime.today()
numdays = 100
dateList = []
for x in range (0, numdays):
    dateList.append(a - datetime.timedelta(days = x))
print dateList

 [/INST] >>> from datetime import timedelta
>>> dateList = [a - datetime.timedelta(100) for i in range (100): 'new' + i - datetime.timedelta(100)])

  /new/type/datetime.datetime', [100, 100, [a, 100, 100])
>>> len(dateList)
100

  /new / new / new / new / (100, 100)

  /new / new / new

 [/INST] >>> from datetime import timedelta
>>> new = [i - datetime.timedelta(0) for i in dateutil.itertoolsomex(100)])
>>> new
[100, 100, 100]

  /new / new / new / today / new

  /new / new / new / new

  /new / new / new

  /new / new / new

  /new / new / new / today / new

  /new / new / new / new

  /new / new / new / new

100

100
100

100

new = [100, 100, 100, 100]

  /new / new / new

100

[100, 100, 100 / new, 100]

  [100, 100, 100, 100]

  /new / new / new / new

 ","I want to create a list of dates, starting with today, and going back an arbitrary number of days, say, in my example 100 days. Is there a better way to do it than this?
import datetime

a = datetime.datetime.today()
numdays = 100
dateList = []
for x in range (0, numdays):
    dateList.append(a - datetime.timedelta(days = x))
print dateList

","You can also use the day ordinal to make it simpler:
def daterange(start_date, end_date):
    for ordinal in range(start_date.toordinal(), end_date.toordinal()):
        yield datetime.date.fromordinal(ordinal)

"
"[INST] I have a command line script that I run with a lot of arguments. I have now come to a point where I have too many arguments, and I want to have some arguments in dictionary form too.
So in order to simplify things I would like to run the script with a settings file instead. I don't really know what libraries to use for the parsing of the file. What's the best practice for doing this? I could of course hammer something out myself, but if there is some library for this, I'm all ears.
A few 'demands':

Rather than using pickle I would like it to be a straight forward text file that can easily be read and edited.
I wan't to be able to add dictionary-like data in it, i.e., some form of nesting should be supported.

A simplified pseudo example file:
truck:
    color: blue
    brand: ford
city: new york
cabriolet:
    color: black
    engine:
        cylinders: 8
        placement: mid
    doors: 2

 [/INST] I think you'll find this answer somewhere in the future, but for the sake of completeness I'll add an outlier to the answer so that other answers don't have to know the inner workings of what's going on underneath the hood.
You'll need to have a way to tell the script that it's from, probably just a path to a file that will be read by the engine (plate), but brand new will have to be the name of the city you want the engine to be running.  I assume all these are out of this realm in a playful way, but I can't really think of how to do this properly.
import collections

outfile = collections.getnamed('pickle')
for k in collections.namedtuple('plate'):
    if k == 'new':
        do_stuff

# collections/outfile:
from collections import namedtuple
outfile = ['plate', 'brand']

def inner_outdoor(city):
    outfile = collections.namedtuple('plate', 'brand')
    outfile[0] = outfile[0]","I have a command line script that I run with a lot of arguments. I have now come to a point where I have too many arguments, and I want to have some arguments in dictionary form too.
So in order to simplify things I would like to run the script with a settings file instead. I don't really know what libraries to use for the parsing of the file. What's the best practice for doing this? I could of course hammer something out myself, but if there is some library for this, I'm all ears.
A few 'demands':

Rather than using pickle I would like it to be a straight forward text file that can easily be read and edited.
I wan't to be able to add dictionary-like data in it, i.e., some form of nesting should be supported.

A simplified pseudo example file:
truck:
    color: blue
    brand: ford
city: new york
cabriolet:
    color: black
    engine:
        cylinders: 8
        placement: mid
    doors: 2

","Take a look at python standard config parser.
EDIT: Since nesting seems to be that important, you might consider handling your config file through JSON format.
It then becomes a matter of using the json module with dumps and loads methods that will work with dictionaries nested to any level you want.
"
"[INST] I want to set up a complete Python IDE in Sublime Text 2.
I want to know how to run the Python code from within the editor. Is it done using build system? How do I do it ?
 [/INST] You can use Sublime REPL (you need to install REPL) and then run the Python code from within the editor (it will open a text editor with the chosen project)
  /nano/python/projects/build/build/sublaco/content/Python/christoph)

  /nano/Python/sublaco/d/sn/[projectname] /d/Python/sublaco/[projectname]

 (from http://www.skysys.com/sublaco/)
  (nano/Python/sublaco/Christoph/projects/[projectname]/)

  (I've got it working, but I'm having trouble finding how to actually run the code).
 [/INST] I've found that Sublaco actually works with Python - I just had to run the Python command from the command line, and it worked perfectly.
  Note that the above works for Python 2.7, but I've heard that the Python 3.4 (which was released this week) supports it too).
  (nomenclate.sublaco/[projectname] /[projectname] /path/sublaco/[projectname])/sublaco/
  (note that the.sublaco/[projectname] part is not necessary, I just didn't bother include it.)

  (I've checked the docs, and it mentions using the -o /nano/build/ [name] [name] [type] [action]][name] values, which I assumed means the [name] parameters are the ones that are passed to the Python 3.0 / JavaScript 2.5 (I've gleaned the info from here :)
   ?
    /nano/Python/sublaco/[name] [name] [action]][[name])
    -o-a-button-button-like-button-button-type-button-d-action-","I want to set up a complete Python IDE in Sublime Text 2.
I want to know how to run the Python code from within the editor. Is it done using build system? How do I do it ?
","On Mac OS X, save your file with a .py extension. Press â+B.  It runs in a window below.

"
"[INST] How can I parse a YAML file in Python?
 [/INST] from [radon]

>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>","How can I parse a YAML file in Python?
","If you have YAML that conforms to the YAML 1.2 specification (released 2009) then you should use ruamel.yaml (disclaimer: I am the author of that package).
It is essentially a superset of PyYAML, which supports a most of YAML 1.1 (from 2005).
If you want to be able to preserve your comments when round-tripping, you certainly should use ruamel.yaml.   
Upgrading @Jon's example is easy:
import ruamel.yaml as yaml

with open(""example.yaml"") as stream:
    try:
        print(yaml.load(stream))
    except yaml.YAMLError as exc:
        print(exc)

"
"[INST] I am sketching the architecture for a set of programs that share various interrelated objects stored in a database. I want one of the programs to act as a service which provides a higher level interface for operations on these objects, and the other programs to access the objects through that service.
I am currently aiming for Python and the Django framework as the technologies to implement that service with. I'm pretty sure I figure how to demonize the Python program in Linux. However, it is an optional spec item that the system should support Windows. I have little experience with Windows programming and no experience at all with Windows services.
Is it possible to run a Python programs as a Windows service (i. e. run it automatically without user login)? I won't necessarily have to implement this part, but I need a rough idea how it would be done in order to decide whether to design along these lines.
Edit: Thanks for all the answers so far, they are quite comprehensive. I would like to know one more thing: How is Windows aware of my service? Can I manage it with the native Windows utilities? Basically, what is the equivalent of putting a start/stop script in /etc/init.d?
 [/INST] I think this is the best answer, but I'll expand on that:

The Python interpreter is a shell and the Windows executable.
The Windows interpreter is a executable (file, script) which can be run from any directory (path, file, directory), and this interpreter will run the same code you would run the.exe file with no user interaction.

The Python interpreter is a framework that provides many common functions, such as loading files, executing commands, and executing a program (both interactive and interactive) with the correct execution of a Python program.

The Python interpreter is a separate executable (the path specification you would write in a Windows application) and the rest of the interpreter (the shell script) are both interchangeable and extendable.
 
Being able to run the Python interpreter from a Windows command line would be:


python -c 'import sys; sys.exit(0) # launch the Python interpreter
  sys.exit(0) # terminate the process

Being able to run the Python interpreter from the command line is","I am sketching the architecture for a set of programs that share various interrelated objects stored in a database. I want one of the programs to act as a service which provides a higher level interface for operations on these objects, and the other programs to access the objects through that service.
I am currently aiming for Python and the Django framework as the technologies to implement that service with. I'm pretty sure I figure how to demonize the Python program in Linux. However, it is an optional spec item that the system should support Windows. I have little experience with Windows programming and no experience at all with Windows services.
Is it possible to run a Python programs as a Windows service (i. e. run it automatically without user login)? I won't necessarily have to implement this part, but I need a rough idea how it would be done in order to decide whether to design along these lines.
Edit: Thanks for all the answers so far, they are quite comprehensive. I would like to know one more thing: How is Windows aware of my service? Can I manage it with the native Windows utilities? Basically, what is the equivalent of putting a start/stop script in /etc/init.d?
","Although I upvoted the chosen answer a couple of weeks back, in the meantime I struggled a lot more with this topic. It feels like having a special Python installation and using special modules to run a script as a service is simply the wrong way. What about portability and such?
I stumbled across the wonderful Non-sucking Service Manager, which made it really simple and sane to deal with Windows Services. I figured since I could pass options to an installed service, I could just as well select my Python executable and pass my script as an option.
I have not yet tried this solution, but I will do so right now and update this post along the process. I am also interested in using virtualenvs on Windows, so I might come up with a tutorial sooner or later and link to it here.
"
"[INST] Which image processing techniques could be used to implement an application that detects the christmas trees displayed in the following images?






I'm searching for solutions that are going to work on all these images. Therefore, approaches that require training haar cascade classifiers or template matching are not very interesting.
I'm looking for something that can be written in any programming language, as long as it uses only Open Source technologies. The solution must be tested with the images that are shared on this question. There are 6 input images and the answer should display the results of processing each of them. Finally, for each output image there must be red lines draw to surround the detected tree.
How would you go about programmatically detecting the trees in these images?
 [/INST] You could use the method from the avi/0 singleton (see the avi/0) as follows:
from gpy import get_image
from gpy import get_image
from template import avi

@raw_image = avi/0
@template_instance = avi
@raw_image.instance_process_name = avi
@raw_image.program_image_process_name = avi
@raw_image.program_image_process_name

  # (O/|*|) Red I'm using
  # @template_instances.html + @html_process_name
  # @html_process_name
  # @template_instances.html + get_image_process_name
# @template_instores.html + avi/
# @template_instores.html + get_image_template_name

  # @template_instores.html + get_image_name = avi

  # @template_instores.html # avi_
# @template_instores.html # html_process_name

  # @template_instores.html # from avi/
# @template_instores.html # from html_process_name

  # @template_instores.html # from html_process_name

  # @program_instores.html # from html_process_name

  # @template_instores.html # from av","Which image processing techniques could be used to implement an application that detects the christmas trees displayed in the following images?






I'm searching for solutions that are going to work on all these images. Therefore, approaches that require training haar cascade classifiers or template matching are not very interesting.
I'm looking for something that can be written in any programming language, as long as it uses only Open Source technologies. The solution must be tested with the images that are shared on this question. There are 6 input images and the answer should display the results of processing each of them. Finally, for each output image there must be red lines draw to surround the detected tree.
How would you go about programmatically detecting the trees in these images?
","Here is my simple and dumb solution.
It is based upon the assumption that the tree will be the most bright and big thing in the picture.
//g++ -Wall -pedantic -ansi -O2 -pipe -s -o christmas_tree christmas_tree.cpp `pkg-config --cflags --libs opencv`
#include <opencv2/imgproc/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iostream>

using namespace cv;
using namespace std;

int main(int argc,char *argv[])
{
    Mat original,tmp,tmp1;
    vector <vector<Point> > contours;
    Moments m;
    Rect boundrect;
    Point2f center;
    double radius, max_area=0,tmp_area=0;
    unsigned int j, k;
    int i;

    for(i = 1; i < argc; ++i)
    {
        original = imread(argv[i]);
        if(original.empty())
        {
            cerr << ""Error""<<endl;
            return -1;
        }

        GaussianBlur(original, tmp, Size(3, 3), 0, 0, BORDER_DEFAULT);
        erode(tmp, tmp, Mat(), Point(-1, -1), 10);
        cvtColor(tmp, tmp, CV_BGR2HSV);
        inRange(tmp, Scalar(0, 0, 0), Scalar(180, 255, 200), tmp);

        dilate(original, tmp1, Mat(), Point(-1, -1), 15);
        cvtColor(tmp1, tmp1, CV_BGR2HLS);
        inRange(tmp1, Scalar(0, 185, 0), Scalar(180, 255, 255), tmp1);
        dilate(tmp1, tmp1, Mat(), Point(-1, -1), 10);

        bitwise_and(tmp, tmp1, tmp1);

        findContours(tmp1, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);
        max_area = 0;
        j = 0;
        for(k = 0; k < contours.size(); k++)
        {
            tmp_area = contourArea(contours[k]);
            if(tmp_area > max_area)
            {
                max_area = tmp_area;
                j = k;
            }
        }
        tmp1 = Mat::zeros(original.size(),CV_8U);
        approxPolyDP(contours[j], contours[j], 30, true);
        drawContours(tmp1, contours, j, Scalar(255,255,255), CV_FILLED);

        m = moments(contours[j]);
        boundrect = boundingRect(contours[j]);
        center = Point2f(m.m10/m.m00, m.m01/m.m00);
        radius = (center.y - (boundrect.tl().y))/4.0*3.0;
        Rect heightrect(center.x-original.cols/5, boundrect.tl().y, original.cols/5*2, boundrect.size().height);

        tmp = Mat::zeros(original.size(), CV_8U);
        rectangle(tmp, heightrect, Scalar(255, 255, 255), -1);
        circle(tmp, center, radius, Scalar(255, 255, 255), -1);

        bitwise_and(tmp, tmp1, tmp1);

        findContours(tmp1, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);
        max_area = 0;
        j = 0;
        for(k = 0; k < contours.size(); k++)
        {
            tmp_area = contourArea(contours[k]);
            if(tmp_area > max_area)
            {
                max_area = tmp_area;
                j = k;
            }
        }

        approxPolyDP(contours[j], contours[j], 30, true);
        convexHull(contours[j], contours[j]);

        drawContours(original, contours, j, Scalar(0, 0, 255), 3);

        namedWindow(argv[i], CV_WINDOW_NORMAL|CV_WINDOW_KEEPRATIO|CV_GUI_EXPANDED);
        imshow(argv[i], original);

        waitKey(0);
        destroyWindow(argv[i]);
    }

    return 0;
}

The first step is to detect the most bright pixels in the picture, but we have to do a distinction between the tree itself and the snow which reflect its light. Here we try to exclude the snow appling a really simple filter on the color codes:
GaussianBlur(original, tmp, Size(3, 3), 0, 0, BORDER_DEFAULT);
erode(tmp, tmp, Mat(), Point(-1, -1), 10);
cvtColor(tmp, tmp, CV_BGR2HSV);
inRange(tmp, Scalar(0, 0, 0), Scalar(180, 255, 200), tmp);

Then we find every ""bright"" pixel:
dilate(original, tmp1, Mat(), Point(-1, -1), 15);
cvtColor(tmp1, tmp1, CV_BGR2HLS);
inRange(tmp1, Scalar(0, 185, 0), Scalar(180, 255, 255), tmp1);
dilate(tmp1, tmp1, Mat(), Point(-1, -1), 10);

Finally we join the two results:
bitwise_and(tmp, tmp1, tmp1);

Now we look for the biggest bright object:
findContours(tmp1, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);
max_area = 0;
j = 0;
for(k = 0; k < contours.size(); k++)
{
    tmp_area = contourArea(contours[k]);
    if(tmp_area > max_area)
    {
        max_area = tmp_area;
        j = k;
    }
}
tmp1 = Mat::zeros(original.size(),CV_8U);
approxPolyDP(contours[j], contours[j], 30, true);
drawContours(tmp1, contours, j, Scalar(255,255,255), CV_FILLED);

Now we have almost done, but there are still some imperfection due to the snow.
To cut them off we'll build a mask using a circle and a rectangle to approximate the shape of a tree to delete unwanted pieces:
m = moments(contours[j]);
boundrect = boundingRect(contours[j]);
center = Point2f(m.m10/m.m00, m.m01/m.m00);
radius = (center.y - (boundrect.tl().y))/4.0*3.0;
Rect heightrect(center.x-original.cols/5, boundrect.tl().y, original.cols/5*2, boundrect.size().height);

tmp = Mat::zeros(original.size(), CV_8U);
rectangle(tmp, heightrect, Scalar(255, 255, 255), -1);
circle(tmp, center, radius, Scalar(255, 255, 255), -1);

bitwise_and(tmp, tmp1, tmp1);

The last step is to find the contour of our tree and draw it on the original picture.
findContours(tmp1, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);
max_area = 0;
j = 0;
for(k = 0; k < contours.size(); k++)
{
    tmp_area = contourArea(contours[k]);
    if(tmp_area > max_area)
    {
        max_area = tmp_area;
        j = k;
    }
}

approxPolyDP(contours[j], contours[j], 30, true);
convexHull(contours[j], contours[j]);

drawContours(original, contours, j, Scalar(0, 0, 255), 3);

I'm sorry but at the moment I have a bad connection so it is not possible for me to upload pictures. I'll try to do it later.
Merry Christmas.
EDIT:
Here some pictures of the final output:






"
"[INST] In ""Programming Python"", Mark Lutz mentions ""mixins"". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin? 
Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right? 
Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?
What separates a mixin from multiple inheritance? Is it just a matter of semantics?
 [/INST] A class is a collection of instances which collectively form a concept. 
An instance is the instance of your class. 
A collection of instances is the set of instances which collectively form a concept.
A class is the set of instances of your class which collectively form a concept.
A subclass is the set of instances of which the type of class is collectively instantiated.

Note that this example uses static methods to illustrate the pattern.
class MyClass(object):
    def __init__(self):
        print ""init""
    def __call__(self, instance):
        print ""conformity""

class myClass(object):
    def __init__(self):
        print ""init""

class myClass(object):
    def __init__(self):
        print ""init""

class myClass(object):
    def __init__(self):
        print ""init""

class myClass(object):
    def __init__(self):
        print ""init""
    def __call__(self):
        print ""init""

class myClass(object):
    def __init__(self):
        print ""init""

class myClass(object):
    def __init__(self):
        print ""init""

class myClass():
    def __init__(self):
        print ""init""

class myClass():
    def __init__(self):
        print ""init""

class myClass(","In ""Programming Python"", Mark Lutz mentions ""mixins"". I'm from a C/C++/C# background and I have not heard the term before. What is a mixin? 
Reading between the lines of this example (which I've linked to because it's quite long), I'm presuming it's a case of using multiple inheritance to extend a class as opposed to 'proper' subclassing. Is this right? 
Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition?
What separates a mixin from multiple inheritance? Is it just a matter of semantics?
","I think of them as a disciplined way of using multiple inheritance - because ultimately a mixin is just another python class that (might) follow the conventions about classes that are called mixins.
My understanding of the conventions that govern something you would call a Mixin are that a Mixin:

adds methods but not instance variables (class constants are OK)
only inherits from object (in Python)

That way it limits the potential complexity of multiple inheritance, and makes it reasonably easy to track the flow of your program by limiting where you have to look (compared to full multiple inheritance).  They are similar to ruby modules.
If I want to add instance variables (with more flexibility than allowed for by single inheritance) then I tend to go for composition.
Having said that, I have seen classes called XYZMixin that do have instance variables.
"
"[INST] I want to use PhantomJS in Python. I googled this problem but couldn't find proper solutions.
I find os.popen()  may be a good choice. But I couldn't pass some arguments to it.
Using subprocess.Popen() may be a proper solution for now. I want to know whether there's a better solution or not.
Is there a way to use PhantomJS in Python?
 [/INST] I've found that the latest version of PhantomJS has a built in debugger (called ""debugger"", but I'm unsure whether this is related to the python-dev package). The instructions for it are on the page (http://phantomjs.org/docs/quickstart/), but you'll need to run the subprocess.py with the -p flag:
> python -m PhantomJS.py http://localhost:8000

And you can get the output with:
> python -m simple_debugging

(note: you shouldn't get the url from that link; the link is http://www.phantomjs.com/products/php/debugging/p/debugging/tools/debugger/python_debugger.py)
  -o http://localhost:8000

  [/INST] I've found that running the command locally with -o debug, and then copy the output to the command line (with -p.wav, if needed).
Note that the -o command line argument keeps the terminal open (the ""shell"", not the ""command line"").
 [/INST] I found that -o debug -m http://localhost:8000 (http://localhost:8000) is actually very slow (at least in my experience).
The solution I found is to add -w http://localhost:8000, as shown in the answer above.
  -o http://localhost:8000 -o http://localhost:8000

(note that -o http://... is not exactly the command)

Note that the -w command (which I want to run with every command) is to create a new process (the command is -o http://localhost:8000","I want to use PhantomJS in Python. I googled this problem but couldn't find proper solutions.
I find os.popen()  may be a good choice. But I couldn't pass some arguments to it.
Using subprocess.Popen() may be a proper solution for now. I want to know whether there's a better solution or not.
Is there a way to use PhantomJS in Python?
","Now since the GhostDriver comes bundled with the PhantomJS, it has become even more convenient to use it through Selenium.
I tried the Node installation of PhantomJS, as suggested by Pykler, but in practice I found it to be slower than the standalone installation of PhantomJS. I guess standalone installation didn't provided these features earlier, but as of v1.9, it very much does so. 

Install PhantomJS (http://phantomjs.org/download.html) (If you are on Linux, following instructions will help http://stackoverflow.com/a/14267295/382630)
Install Selenium using pip.

Now you can use like this
import selenium.webdriver
driver = selenium.webdriver.PhantomJS()
driver.get('http://google.com')
# do some processing

driver.quit()

"
"[INST] I want to write a function that will execute a shell command and return its output as a string, no matter, is it an error or success message. I just want to get the same result that I would have gotten with the command line.
What would be a code example that would do such a thing?
For example:
def run_command(cmd):
    # ??????

print run_command('mysqladmin create test -uroot -pmysqladmin12')
# Should output something like:
# mysqladmin: CREATE DATABASE failed; error: 'Can't create database 'test'; database exists'

 [/INST] I had a similar problem, and this answer was the solution (for me) that worked on both linux and windows (and I'm not sure that my implementation was the best, but it's a good example for learning - though I'm not sure if there is a better way to do it, but this is what I did:
import MySQLdb as mysql

def run_command(cmd):
  # (mySQLdb is part of the mysql-db package though)
  sql = MySQLdb()
  cursor = mysql.cursor(mySQLdb)
  cursor.close()
  cursor.close()

def run_command(cmd):
  # (mysql_db is part of MySQLdb if in 2.7)
  cursor.close()

def run_command(cmd):
 ????????

def run_sql(cmd):
   ????????')

def run_sql(cmd):
 ????????

If you want to run the command in another process (for example, you want to run mysql_db if - in MySQLDB was not the correct way) - you can use psql.send(cmd) and pass its argument (which was actually a parameter you could have given to the command)
def run_sql(cmd):
 ???????

If you don't want to do the same thing MySQLdb would be a great example of using a raw_input() call to get the same result, without having to set the command line.
Edit: I'm actually writing this as part","I want to write a function that will execute a shell command and return its output as a string, no matter, is it an error or success message. I just want to get the same result that I would have gotten with the command line.
What would be a code example that would do such a thing?
For example:
def run_command(cmd):
    # ??????

print run_command('mysqladmin create test -uroot -pmysqladmin12')
# Should output something like:
# mysqladmin: CREATE DATABASE failed; error: 'Can't create database 'test'; database exists'

","Vartec's answer doesn't read all lines, so I made a version that did:
def run_command(command):
    p = subprocess.Popen(command,
                         stdout=subprocess.PIPE,
                         stderr=subprocess.STDOUT)
    return iter(p.stdout.readline, b'')

Usage is the same as the accepted answer:
command = 'mysqladmin create test -uroot -pmysqladmin12'.split()
for line in run_command(command):
    print(line)

"
"[INST] I want to create a dynamic object (inside another object) in Python and then add attributes to it.
I tried:
obj = someobject
obj.a = object()
setattr(obj.a, 'somefield', 'somevalue')

but this didn't work.
Any ideas?
edit:
I am setting the attributes from a for loop which loops through a list of values, e.g.
params = ['attr1', 'attr2', 'attr3']
obj = someobject
obj.a = object()

for p in params:
   obj.a.p # where p comes from for loop variable

In the above example I would get obj.a.attr1, obj.a.attr2, obj.a.attr3.  
I used the setattr function because I didn't know how to do obj.a.NAME from a for loop.
How would I set the attribute based on the value of p in the example above?
 [/INST] In case of a simple loop, setattr is enough to address the issue:
def setattr(obj, attr, value):
    setattr(obj, attr, value)

def setattr(obj, attr, value):
    setattr(obj.a, attr, value)

  setattr(obj.a, 'attr1', value)

  setattr(obj.b, 'attr2', value)

  # setattr(obj.b, 'attr1', value)

def setattr(obj, attr, value):
    setattr(obj.b, 'attr1')
    setattr(obj.b.c_attr1, 'attr2')

# setattr(obj.b, 'attr2', 'attr1')
# setattr(obj.b, 'attr2')

In this case I want to set the attributes in the order of how I set the attributes in my loop. In this case I think it would be best to set the attributes based on the order of the values in the same loop.
In case of a setattr where I have to define setattr(attr, 'attr1', 'attr2') I could just wrap the loop in a for loop and do setattr(attr","I want to create a dynamic object (inside another object) in Python and then add attributes to it.
I tried:
obj = someobject
obj.a = object()
setattr(obj.a, 'somefield', 'somevalue')

but this didn't work.
Any ideas?
edit:
I am setting the attributes from a for loop which loops through a list of values, e.g.
params = ['attr1', 'attr2', 'attr3']
obj = someobject
obj.a = object()

for p in params:
   obj.a.p # where p comes from for loop variable

In the above example I would get obj.a.attr1, obj.a.attr2, obj.a.attr3.  
I used the setattr function because I didn't know how to do obj.a.NAME from a for loop.
How would I set the attribute based on the value of p in the example above?
","There is types.SimpleNamespace class in Python 3.3+:
obj = someobject
obj.a = SimpleNamespace()
for p in params:
    setattr(obj.a, p, value)
# obj.a.attr1

"
"[INST] What are the uses for **kwargs in Python?
I know you can do an objects.filter on a table and pass in a **kwargs argument.  
Can I also do this for specifying time deltas i.e. timedelta(hours = time1)? 
How exactly does it work? Is it classes as 'unpacking'? Like a,b=1,2?
 [/INST] The 'filter' method can be used to apply a time difference:
>>> def time_deltas(a,b):
...     return a * (10**(a-b)) + (10**(b-a)) * (10**(b-a)) * (10**(b-a)) * (10**(b-a)) * (10**(b-a)) * (10**(b-a)) * (10**(b-a)**(2)**(3))
>>> time_deltas(a,b)**(10**(b-a)) * (10**(b-a)) * (10**(b-a)) * (10**(b**(a*b)) * (10**(b*a)) * (10**(b*a)**(2)) * (10**(b*a)**(1))

  filter(1,2,3,10**(b*a)**(1))
1, 2, 3, 4, 5, 6, 7, 8, 9, 10**(b*a)**(1)

  filter(1,2,3,1) for a in (1,2,3,5,6,7,8)

  filter(1,2,3,5,6)

  filter(1,2,3,4,5,6)

  filter(1,2,3,5,8)

>>> filter(1,2,3,5,7,8)
[1,2,3,4,5,6]

  filter(1,2,3,5,7)

>>> filter(1,2,3,5","What are the uses for **kwargs in Python?
I know you can do an objects.filter on a table and pass in a **kwargs argument.  
Can I also do this for specifying time deltas i.e. timedelta(hours = time1)? 
How exactly does it work? Is it classes as 'unpacking'? Like a,b=1,2?
","As an addition, you can also mix different ways of usage when calling kwargs functions:
def test(**kwargs):
    print kwargs['a']
    print kwargs['b']
    print kwargs['c']


args = { 'b': 2, 'c': 3}

test( a=1, **args )

gives this output:
1
2
3

Note that **kwargs has to be the last argument
"
"[INST] Is there a way of reading one single character from the user input? For instance, they press one key at the terminal and it is returned (sort of like getch()). I know there's a function in Windows for it, but I'd like something that is cross-platform.
 [/INST] I've found this code snippet, which I found useful in a pinch (but I can't remember who wrote it):
def getch():
    # Return character at arrow press
    import terminal
    import time
    return terminal.getch()

# 
# Print the character at the terminal (pressing any of the keys mentioned above)
def getchar():
  try:
    return terminal.keypress(ord(key), 1)
except KeyboardInterrupt:
  print 'You pressed ""keypress"" to quit')

I don't know why the code doesn't work as expected (I thought it should just return the character immediately), but I can't figure out why it's not working as intended.
 [/INST] I've found terminate (http://docs.python.org/3/library/functions.html) in my terminal:
import terminal, subprocess, sys
subprocess.call([terminal.keypress(9, 8, 1), 3, 3, 0, 1, 2)]

It returns a list of the names of all the keys (i.e. ""Enter"", ""Backspace"", ""End"", etc.) in the terminal (I'm assuming you're running Xavier).
Note that this is Linux terminal: if you press any key (1, 2, 3, 4, 5, 6) it will return a list of all the keys that were pressed (terminal input is just ""Press any key press"")
  # 

def terminate():
    # Enter (22quit() - -1)
    # Enter (22quit() - 1) - 
    # Wait for keypress (22quit() - 1)
    # Press enter (22quit(""Press any keypress"")) - 
  # Press (22quit(*i)) -","Is there a way of reading one single character from the user input? For instance, they press one key at the terminal and it is returned (sort of like getch()). I know there's a function in Windows for it, but I'd like something that is cross-platform.
","Also worth trying is the readchar library, which is in part based on the ActiveState recipe mentioned in other answers.
Installation:
pip install readchar

Usage:
import readchar
print(""Reading a char:"")
print(repr(readchar.readchar()))
print(""Reading a key:"")
print(repr(readchar.readkey()))

Tested on Windows and Linux with Python 2.7.
On Windows, only keys which map to letters or ASCII control codes are supported (Backspace, Enter, Esc, Tab, Ctrl+letter). On GNU/Linux (depending on exact terminal, perhaps?) you also get Insert, Delete, Pg Up, Pg Dn, Home, End and F n keys... but then, there's issues separating these special keys from an Esc.
Caveat: Like with most (all?) answers in here, signal keys like Ctrl+C, Ctrl+D and Ctrl+Z are caught and returned (as '\x03', '\x04' and '\x1a' respectively); your program can be come difficult to abort.
"
"[INST] I want my script to wait until the user presses any key.
How do I do that?
 [/INST] I've written a simple wrapper for this, which allows you to easily call.get_input_key() from the terminal (in a Pythonic shell) or.get_field_name() and get_all_fields_done() functions:
def get_field_name(self, col):
    """"""
    @param self - the terminal where ""col"" is expected
    """"""
    """"""
    @param self - the terminal where ""col"" is expected
    """"""
    col = get_field_name(self, ""col"")
    """"""
    def get_field_name_name(self, col):
    """"""
    @param self - the terminal where ""col"" is expected
    """"""
    def get_field_name_name(self, col):
        """"""
    @param field_name - the ""col"" - ""col""
    @field_name_name should be ""col""
        """"""
    def get_field_name_name(self, col):
        """"""
    @param field_name - the field name should be ""col""
    @field_name = col - the field name
    @field_name = col - the field name
    """"""
    def get_field_name_name(self, col):
        """"""
    @field_name = col - the field name
    @field_name_name should be ""col""
    """"""
    def get_field_name_name(self, col):
        """"""
        @field_name = col.split("" - "")[0]
        @field_name_name = col.split("" - "")[0]

    @field_name = ""col""
    @get_field_name_name = col.strip("" - """")
""""""

Getting field name/name/ (i.e. ""col"") is a bit tricky. You can simply call ""col"" with ""self.col"" and ""field_name"" with ""col""
    @field_name = col.strip("" - ""))
    @get_field_name_name = [col.","I want my script to wait until the user presses any key.
How do I do that?
","The python manual provides the following:
import termios, fcntl, sys, os
fd = sys.stdin.fileno()

oldterm = termios.tcgetattr(fd)
newattr = termios.tcgetattr(fd)
newattr[3] = newattr[3] & ~termios.ICANON & ~termios.ECHO
termios.tcsetattr(fd, termios.TCSANOW, newattr)

oldflags = fcntl.fcntl(fd, fcntl.F_GETFL)
fcntl.fcntl(fd, fcntl.F_SETFL, oldflags | os.O_NONBLOCK)

try:
    while 1:
        try:
            c = sys.stdin.read(1)
            print ""Got character"", repr(c)
        except IOError: pass
finally:
    termios.tcsetattr(fd, termios.TCSAFLUSH, oldterm)
    fcntl.fcntl(fd, fcntl.F_SETFL, oldflags)

which can be rolled into your use case.
"
"[INST] I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:
gcc -Wall utilsmodule.c -o Utilc

After executing the command, I get this error message:

utilsmodule.c:1:20: fatal error: Python.h: No such file or directory
  compilation terminated.

in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??
 [/INST] The problem is not with the C source code but rather with the way Python interpreter (gcc, in this context) reads the source code (the compiled file). The actual output which was printed is:

utilsmodule.c:1:20 

and 

utilsmodule.c:8:9:




I've also tried the following command, which should ideally (if it's possible) just output the correct (modified) source code:

utilsmodule.c:9:
  utilsmodule.c:8:9:
  /home/user/desktop/python-utils/utilsmodule.c:9:
  /home/user/desktop/utils/lib/utils/compiled/python/utils/build/utils/compiled/python.c:8:9:
  descriptors:

INUTOUTUTC:MAKEFILE: utils/compiled/gcc/utils.c:8:9:9:9:1


util/compiled/utils/lib/utilsd.c:9:8:9:9:9:1
utils/utils/compiled/gcc.c:9:9:9:9:9:9:9:9:9:9:9

I've also tried this:
utils/compiled/gcc/utils/compiled/gcc/compiled/utils.c:9:9:9:9:9:9:9:9:9:9

I've tried all suggested solutions and so far I've managed to get the output I've just","I am trying to build a shared library using a C extension file but first I have to generate the output file using the command below:
gcc -Wall utilsmodule.c -o Utilc

After executing the command, I get this error message:

utilsmodule.c:1:20: fatal error: Python.h: No such file or directory
  compilation terminated.

in fact I have tried all the suggested solutions over the internet but the problem still exists ... also I have no problem with Python.h. I managed to locate the file on my machine ... anybody has faced the same problem before??
","Two things you have to do.
Install development package for Python, in case of Debian/Ubuntu/Mint it's done with command:
sudo apt-get install python-dev

Second thing is that include files are not by default in the include path, nor is Python library linked with executable by default. You need to add these flags (replace Python's version accordingly):
-I/usr/include/python2.7 -lpython2.7 

In other words your compile command ought to be:
gcc -Wall -I/usr/include/python2.7 -lpython2.7  utilsmodule.c -o Utilc 

"
"[INST] I tried to install the Python package dulwich:
pip install dulwich

But I get a cryptic error message:
error: Unable to find vcvarsall.bat

The same happens if I try installing the package manually:
> python setup.py install
running build_ext
building 'dulwich._objects' extension
error: Unable to find vcvarsall.bat

 [/INST] I had this problem too, so I created a.py file that I can drop into the install directory.
I then ran the following:
> python setup.py install
Traceback (most recent call last):
  File ""/usr/local/bin/python"", line 1, in <module>
    File ""/usr/lib/python2.7/dist-packages/dulwich/__init__.py"", line 2, in <module>
    raise vcargs.by_module

  file vc
    running build_ext with <module>
    error: Unable to find vc

I ran into this situation because I had a.py file that was not a module, but I had assumed I could run from within the vc.py file (setting PATH by the by doing so).
    I also ran the by-word command from the command line (in doing ""python setup.py install""), and it was working fine:
> python setup.py install
    Traceback (most recent call traceback):
    file /usr/lib/python2.7/dist-packages/dulwich/__init__.py
    Traceback (most recent call """") terminated:
      File ""/usr/lib/python2.7/dist-packages/dulwich/__init__.py"", line 2, in <module>
      File ""/usr/lib/python2.7/dist-packages/dulwich/__init__.py"", line 2, in <module>
      Traceback (/usr/lib/python2.7/dist-packages/dulwich/__init__.py)
      Traceback (/usr/lib/python2.7/dulwich/__init__.py):
      Traceback (/usr/lib/python2.7","I tried to install the Python package dulwich:
pip install dulwich

But I get a cryptic error message:
error: Unable to find vcvarsall.bat

The same happens if I try installing the package manually:
> python setup.py install
running build_ext
building 'dulwich._objects' extension
error: Unable to find vcvarsall.bat

","You can install compiled version from http://www.lfd.uci.edu/~gohlke/pythonlibs/
"
"[INST] Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.?
 [/INST] In Python 2, you can simply call
exit(semaphore)

In Python 3, you need to import _thread
import greenlet

def f(x):
    print ""hello""
    return

def go():
    print ""bye""

In both cases, the _thread.exit() call will block the Python
interpreter from running in the normal
execution of a threaded program.
 [/INST] The _thread.exit() call only kills the
threaded greenlet's interpreter. The _deinit() call, on the other hand, only kills the
thread's process after a normal exit.

In Python 3, _exit_ is called only if the thread/processespecifically _exit_ is called, passing
a specific exception (Traceback __exit__"")
In Python 2, the _exit__ special call is called only
when the thread is not called directly (i.e., from a call to __exit__).
  Greenlet is the default name for _exit_ in Python 2.
  Note that the ""Python 3"" interpreter does not exist in Python 2, but it is called from the
concept of _exit_.
  In Python 2, the _exit_ is called as __exit__
  In Python 3, the
calling of _exit_ is called as __exit__ __exit__ __call__.

In Python 2, the _exit__ is called as __exit__ __name__.
In Python 1, the _exit__ is called as __exit__ __name__.
In Python 3, the _exit__ call is called as __exit__ __name__.

In Python 2, the _exit__ call is called as __exit__.

In Python 3, the _exit__ call is called as __exit__.

In Python, _exit_ is called as __exit__.

In Python, _exit_ is called as __exit__.
In Python, the __exit__ call is called as __exit__ __name__.
In Python, the __exit__ call","Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.?
","This is based on thread2 -- killable threads (Python recipe)
You need to call PyThreadState_SetasyncExc(), which is only available through ctypes.
This has only been tested on Python 2.7.3, but it is likely to work with other recent 2.x releases.
import ctypes

def terminate_thread(thread):
    """"""Terminates a python thread from another thread.

    :param thread: a threading.Thread instance
    """"""
    if not thread.isAlive():
        return

    exc = ctypes.py_object(SystemExit)
    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(
        ctypes.c_long(thread.ident), exc)
    if res == 0:
        raise ValueError(""nonexistent thread id"")
    elif res > 1:
        # """"""if it returns a number greater than one, you're in trouble,
        # and you should call it again with exc=NULL to revert the effect""""""
        ctypes.pythonapi.PyThreadState_SetAsyncExc(thread.ident, None)
        raise SystemError(""PyThreadState_SetAsyncExc failed"")

"
"[INST] How can I output colored text to the terminal, in Python?
What is the best Unicode symbol to represent a solid block?
 [/INST] A good reference is this Stack Overflow question.
http://stackoverflow.com/a/123/142000645452006456420064564

In python, you can't really do:
http://stackoverflow.com/questions/123/123/143/143/2444564

You can't really represent a whole block of text, as it's not a part of the object.
But you can easily do this:
b = raw_input(input('') +'')
c = [b['a'] for i in xrange(10)]

In the raw_input, you just put the input argument in the first place:
>>> print(input('a'))
'123'

And from the str in the second place:
>>> print(input('') + '')
'123'

But the latter (the for -i) is not recommended. It's better to use str.isinstance(s, list))
 
You can also check if the whole input is a list:
>>> for i in xrange(len(s))):
    print(i)

The raw_input is actually a parameter in most languages, so you should use the str_i parameter in the first parameter:
'123'  

 
In python, you can do:
raw_input(input('a')) +: [input('a') + ']

But in Python, the raw_input is actually the raw_input(input('a'))).
 
You can also do:
for i in xrange(123):
    print(input('a')) +: [i for i in xrange(123)]

But you should always put the raw_input(input('a')) for input in the for loop, because it's not legal to pass a second parameter in the input.
 
However, the raw_input(input('a')) +","How can I output colored text to the terminal, in Python?
What is the best Unicode symbol to represent a solid block?
","I use the colorama module for coloured terminal printing in Python. A link is here http://pypi.python.org/pypi/colorama
Some example code of printing red and green text:
from colorama import *

print(Fore.GREEN + 'Green text')
print(Fore.RED + 'Red text')

I used colorama to write a basic Matrix program
Installation on Ubuntu (your distribution install command may be different)
sudo apt-get install python-pip
sudo pip install colorama

"
"[INST] I have a directory which hosts all of my Django apps (C:\My_Projects). I want to add this directory to my pythonpath so I can call the apps directly.
I have tried adding C:\My_Projects\; to my Path variable from the Windows GUI (My Computer > Properties > Advanced System Settings > Environment Variables). But it still doesn't read the coltrane module and generates this error:

Error: No module named coltrane

 [/INST] You need to add the path to the environment:
```
COLTRANE=C:\My_Projects\;

and then add the environment entry to your PATH environment:
```
C:\Users\###\AppData\AppData\

and then add the environment variable with the following command
`python -m python setup.py install -c coltrane

as you don't have the right path.
  Note: the coltrane environment is not needed if you don't have the Python package installed.
  Note: Coltrane is not available in the Windows GUI > Advanced Settings > System > General > Advanced System Settings > Environment Variables.
  -n coltrane-env

  -h coltrane-env

  -C coltrane-env (from the above command)

  -h coltrane-env (from the Advanced System Settings > Environment Variables)

  -h coltrane-env (from the Advanced System Settings > Advanced System Settings > Environment Variables)

(Advanced System Settings > Advanced System Settings > Advanced System Settings > Environment Variables)

 [Advanced System Settings > Advanced System Settings > Environment Variables]

(Advanced System Settings > Advanced System Settings > Environment Variables)

  -C coltrane-env (from the Advanced System Settings > Advanced System Settings > Environment Settings)

  -C coltrane-env = coltrane-env (C:\My_Projects\;)

  -C coltrane-env (from the Environment Settings > Advanced System Settings > Advanced System Settings)

Note:

Note:

The coltrane-env environment is not available by default in the Windows GUI.

Advanced System","I have a directory which hosts all of my Django apps (C:\My_Projects). I want to add this directory to my pythonpath so I can call the apps directly.
I have tried adding C:\My_Projects\; to my Path variable from the Windows GUI (My Computer > Properties > Advanced System Settings > Environment Variables). But it still doesn't read the coltrane module and generates this error:

Error: No module named coltrane

","You can also add a .pth file containing the desired directory in either your c:\PythonX.X folder, or your \site-packages folder, which tends to be my preferred method when I'm developing a Python package.
See here for more information.
"
"[INST] Why does the following behave unexpectedly in Python?
>>> a = 256
>>> b = 256
>>> a is b
True           # This is an expected result
>>> a = 257
>>> b = 257
>>> a is b
False          # What happened here? Why is this False?
>>> 257 is 257
True           # Yet the literal numbers compare properly

I am using Python 2.5.2. Trying some different versions of Python, it appears that Python 2.3.3 shows the above behaviour between 99 and 100.
Based on the above, I can hypothesize that Python is internally implemented such that ""small"" integers are stored in a different way than larger integers and the is operator can tell the difference. Why the leaky abstraction? What is a better way of comparing two arbitrary objects to see whether they are the same when I don't know in advance whether they are numbers or not?
 [/INST]ublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublGNublGNublublublublublGNGNublublGNublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublublubl","Why does the following behave unexpectedly in Python?
>>> a = 256
>>> b = 256
>>> a is b
True           # This is an expected result
>>> a = 257
>>> b = 257
>>> a is b
False          # What happened here? Why is this False?
>>> 257 is 257
True           # Yet the literal numbers compare properly

I am using Python 2.5.2. Trying some different versions of Python, it appears that Python 2.3.3 shows the above behaviour between 99 and 100.
Based on the above, I can hypothesize that Python is internally implemented such that ""small"" integers are stored in a different way than larger integers and the is operator can tell the difference. Why the leaky abstraction? What is a better way of comparing two arbitrary objects to see whether they are the same when I don't know in advance whether they are numbers or not?
","I'm late but, you want some of that good source with your answer?*
Good thing about Python is that you can actually see the source for this. I'm going to use Python 3.5 links for now; finding the corresponding 2.x ones is trivial.
In Python, int objects are actually (unified some time ago) of c long type. The dedicated Python C-API function that handles creating a new int object is PyLong_FromLong(long v). The description for this function is:

The current implementation keeps an array of integer objects for all integers between -5 and 256, when you create an int in that range you actually just get back a reference to the existing object. So it should be possible to change the value of 1. I suspect the behaviour of Python in this case is undefined. :-)

Don't know about you but I see this and think:
Let's find that array!
If you haven't fiddled with the C code implementing Python you should, everything is pretty organized and readable. For our case, we need to look in the Objects/ subdirectory of the main source code directory tree.
PyLong_FromLong deals with long objects so it shouldn't be hard to deduce that we need to peek inside longobject.c. After looking inside you might think things are chaotic; they are, but fear not, the function we're looking for is chilling at line 230 waiting for us to check it out. It's a smallish function so the main body (excluding declarations) is easily pasted here:
PyObject *
PyLong_FromLong(long ival)
{
    // omitting declarations

    CHECK_SMALL_INT(ival);

    if (ival < 0) {
        /* negate: cant write this as abs_ival = -ival since that
           invokes undefined behaviour when ival is LONG_MIN */
        abs_ival = 0U-(unsigned long)ival;
        sign = -1;
    }
    else {
        abs_ival = (unsigned long)ival;
    }

    /* Fast path for single-digit ints */
    if (!(abs_ival >> PyLong_SHIFT)) {
        v = _PyLong_New(1);
        if (v) {
            Py_SIZE(v) = sign;
            v->ob_digit[0] = Py_SAFE_DOWNCAST(
                abs_ival, unsigned long, digit);
        }
        return (PyObject*)v; 
}

Now, we're no C master-code-haxxorz but we're also not dumb, we can see that CHECK_SMALL_INT(ival); peeking at us all seductively; we can understand it has something to do with this. Let's check it out:
#define CHECK_SMALL_INT(ival) \
    do if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS) { \
        return get_small_int((sdigit)ival); \
    } while(0)

So it's a macro that calls function get_small_int if the value ival satisfies the condition:
if (-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS)

So what are NSMALLNEGINTS and NSMALLPOSINTS? If you guessed macros you get nothing because that wasn't such a hard question.. Anyway, here they are:
#ifndef NSMALLPOSINTS
#define NSMALLPOSINTS           257
#endif
#ifndef NSMALLNEGINTS
#define NSMALLNEGINTS           5
#endif

So our condition is if (-5 <= ival && ival < 257) call get_small_int. 
No other place to go but continue our journey by looking at get_small_int in all its glory (well, we'll just look at it's body because that's were the interesting things are):
PyObject *v;
assert(-NSMALLNEGINTS <= ival && ival < NSMALLPOSINTS);
v = (PyObject *)&small_ints[ival + NSMALLNEGINTS];
Py_INCREF(v);

Okay, create a PyObject, assert that the previous condition holds and execute the assignment:
v = (PyObject *)&small_ints[ival + NSMALLNEGINTS];

small_ints looks a lot like that array we've been searching for.. and, it is! We could've just read the damn documentation and we would've know all along!:
/* Small integers are preallocated in this array so that they
   can be shared.
   The integers that are preallocated are those in the range
   -NSMALLNEGINTS (inclusive) to NSMALLPOSINTS (not inclusive).
*/
static PyLongObject small_ints[NSMALLNEGINTS + NSMALLPOSINTS];

So yup, this is our guy. When you want to create a new int in the range [NSMALLNEGINTS, NSMALLPOSINTS) you'll just get back a reference to an already existing object that has been preallocated. 
Since the reference refers to the same object issuing id() directly or checking for identity with is on it will return exactly the same thing. 
But, when are they allocated??
During initialization in _PyLong_Init Python will gladly enter in a for loop do do this for you: 
for (ival = -NSMALLNEGINTS; ival <  NSMALLPOSINTS; ival++, v++) {
    // Look me up!
}

I hope my explanation has made you C (common pun) things clearly now.

But, 257 is 257? What's up?
This is actually easier to explain, and I have attempted to do so already; it's due to the fact that Python will execute this interactive statement:
>>> 257 is 257

In its own execution frame. When constructing this frame Python will see that you have two matching literals and will use the same PyLongObject representing 257. You can see this if you do the compilation yourself and examine its contents:
>>> codeObj = compile(""257 is 257"", ""blah!"", ""exec"")
>>> codeObj.co_consts
(257, None)

When Python does the operation; it's now just going to load the exact same object:
>>> import dis
>>> dis.dis(codeObj)
  1           0 LOAD_CONST               0 (257)   # dis
              3 LOAD_CONST               0 (257)   # dis again
              6 COMPARE_OP               8 (is)

So is will return True.

* -- I'll try and word this in a more introductory manner in order for most to be able to follow along.
"
"[INST] I would like to make several statements that give standard output without seeing newlines in between statements.
Specifically, suppose I have:
for item in range(1,100):
    print item

The result is:
1
2
3
4
.
.
.

How get this to instead look like:
1 2 3 4 5 ...

Even better, is it possible to print the single number over the last number, so only one number is on the screen at a time?
 [/INST] You can do this in python:
for i in range(1,100):
    print i

 
This will give you:
1 2 3...

 
Also, this code snippet is not very readable, IMHO.
 
Note that this code also works if you have 100 in a for loop, which I assume you assumed you meant '1', '2',...', etc. 
 
 
And this code, using a list comprehension:
for i in range(100):
    print i

 

 
[1 2   3   4   5...]

 
(0,1,2,3,4,5,6,7,8,9,100)

 
(1,2,3,4,5,6,7,8,9)

You could even make it a generator (not a list comprehension for my code snippet) if you want:
def gen_str(n):
    return ''.join(range(1,100))

(I'd recommend using a generator for this, but I don't see a reason to do so)
 

Also, if you want to do some filtering, you could do:
for i in range(1,100):
        if i % 1:
                print i

 
(not sure if it's good code)

 
However, this code (for me) is very Pythonic and Pythonic in my opinion, and I'm not really sure how to actually implement a generator in 100,11,7,","I would like to make several statements that give standard output without seeing newlines in between statements.
Specifically, suppose I have:
for item in range(1,100):
    print item

The result is:
1
2
3
4
.
.
.

How get this to instead look like:
1 2 3 4 5 ...

Even better, is it possible to print the single number over the last number, so only one number is on the screen at a time?
","Like the other examples,
I use a similar approach but instead of spending time calculating out the last output length, etc,  
I simply use ANSI code escapes to move back to the beginning of the line and then clear that entire line before printing my current status output.
import sys

class Printer():
    """"""Print things to stdout on one line dynamically""""""
    def __init__(self,data):
        sys.stdout.write(""\r\x1b[K""+data.__str__())
        sys.stdout.flush()

To use in your iteration loop you would just call something like:
x = 1
for f in fileList:
    ProcessFile(f)
    output = ""File number %d completed."" % x
    Printer(output)
    x += 1   

See more here
"
"[INST] I've been hunting for an answer to this on South's site, Google, and SO, but couldn't find a simple way to do this. 
I want to rename a Django model using South.
Say you have the following:
class Foo(models.Model):
    name = models.CharField()

class FooTwo(models.Model):
    name = models.CharField()
    foo = models.ForeignKey(Foo)

and you want to convert Foo to Bar, namely
class Bar(models.Model):
    name = models.CharField()

class FooTwo(models.Model):
    name = models.CharField()
    foo = models.ForeignKey(Bar)

To keep it simple, I'm just trying to change the name from Foo to Bar, but ignore the foo member in FooTwo for now.
What's the easiest way to do this using South?

I could probably do a data migration, but that seems pretty involved.
Write a custom migration, e.g. db.rename_table('city_citystate', 'geo_citystate'), but I'm not sure how to fix the foreign key in this case.
An easier way that you know?

 [/INST] I'm assuming you're ok with changing your models as South doesn't support them. If you don't care about the actual model, you can simply override the __un__ attribute, like so:
class Foo(models.Model):
    name = 'city_citystate'
    from models import Foo
    from models.fields import CharField

class Foo(models.Model):
    name = 'city_citystate'
    o = models.ForeignKey(Bar)

class Foo(models.Model):
    name = 'city_state'
    o = models.ForeignKey(Foo)

class Bar(models.Model):
    name = 'city_state'
    o = models.ForeignKey(Foo)

class Bar(models.Model):
    o = models.ForeignKey(Foo)
    name = 'city_state'

class Bar(models.Model):
","I've been hunting for an answer to this on South's site, Google, and SO, but couldn't find a simple way to do this. 
I want to rename a Django model using South.
Say you have the following:
class Foo(models.Model):
    name = models.CharField()

class FooTwo(models.Model):
    name = models.CharField()
    foo = models.ForeignKey(Foo)

and you want to convert Foo to Bar, namely
class Bar(models.Model):
    name = models.CharField()

class FooTwo(models.Model):
    name = models.CharField()
    foo = models.ForeignKey(Bar)

To keep it simple, I'm just trying to change the name from Foo to Bar, but ignore the foo member in FooTwo for now.
What's the easiest way to do this using South?

I could probably do a data migration, but that seems pretty involved.
Write a custom migration, e.g. db.rename_table('city_citystate', 'geo_citystate'), but I'm not sure how to fix the foreign key in this case.
An easier way that you know?

","Make the changes in models.py and then run
./manage.py schemamigration --auto myapp

When you inspect the migration file, you'll see that it deletes a table and creates a new one
class Migration(SchemaMigration):

    def forwards(self, orm):
        # Deleting model 'Foo'                                                                                                                      
        db.delete_table('myapp_foo')

        # Adding model 'Bar'                                                                                                                        
        db.create_table('myapp_bar', (
        ...
        ))
        db.send_create_signal('myapp', ['Bar'])

    def backwards(self, orm):
        ...

This is not quite what you want. Instead, edit the migration so that it looks like:
class Migration(SchemaMigration):

    def forwards(self, orm):
        # Renaming model from 'Foo' to 'Bar'                                                                                                                      
        db.rename_table('myapp_foo', 'myapp_bar')                                                                                                                        
        if not db.dry_run:
            orm['contenttypes.contenttype'].objects.filter(
                app_label='myapp', model='foo').update(model='bar')

    def backwards(self, orm):
        # Renaming model from 'Bar' to 'Foo'                                                                                                                      
        db.rename_table('myapp_bar', 'myapp_foo')                                                                                                                        
        if not db.dry_run:
            orm['contenttypes.contenttype'].objects.filter(app_label='myapp', model='bar').update(model='foo')

In the absence of the update statement, the db.send_create_signal call will create a new ContentType with the new model name. But it's better to just update the ContentType you already have in case there are database objects pointing to it (e.g., via a GenericForeignKey).
Also, if you've renamed some columns which are foreign keys to the renamed model, don't forget to
db.rename_column(myapp_model, foo_id, bar_id)

"
"[INST] What would be a nice way to go from {2:3, 1:89, 4:5, 3:0} to {1:89, 2:3, 3:0, 4:5}?
I checked some posts but they all use the ""sorted"" operator that returns tuples. 
 [/INST] You can use the {x:y} operator in python and then use the {|x:y} for the {y:z} operator.
>>> from collections import OrderedDict
>>> def my_tuple(a,b):
...     return OrderedDict.dict(a,b)
...     def my_func(a,b):
...     return OrderedDict({a:b,b:z})
>>> my_func({a:b,b:z})
({a:b,c:y})
>>> my_func = OrderedDict({a:b,b:z})
>>> my_func()
({a:b,c:y})
>>> my_func()
('{a:b,c:y'}', 'a:b', 'c:z')

  >>> my_func({a:b,c:y})
Outer(...)
{a:b, c:y}

  Outer(...)
{a:b, c:y}

  Outer(...)
...
>>> my_func()
Outer(...)

  Outer(..a:b, c:y)
Outer(..a:b, c:z)
Outer(..a:b, c:z): Outer(..a:b, c:y)
>>> Outer(..a:b, c:z)
Outer(..a:b, c:z)
Outer(..a:b, c:z)
Outer(..a:b, c:z)
Outer(..a:b, c:z): Outer(..a:b, c:z)
Outer(..a:b, c:z)
Outer(..a:b, c:z)

In order to make the tuple out of OrderedDict, you","What would be a nice way to go from {2:3, 1:89, 4:5, 3:0} to {1:89, 2:3, 3:0, 4:5}?
I checked some posts but they all use the ""sorted"" operator that returns tuples. 
","Found another way:
import json
print json.dumps(d, sort_keys = True)

upd:
1. this also sorts nested objects (thanks @DanielF).
2. python dictionaries are unordered therefore this is sutable for print or assign to str only.
"
"[INST] I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.
Now if I open my Python interpreter and do the same ""is"" comparison, it succeeds.
>>> s1 = 'public'
>>> s2 = 'public'
>>> s2 is s1
True

What am I missing here?
 [/INST] In Python 3, you can do var = var
>>> var = 'public'
>>> var = 'public'
>>> print var
True

  (In Python 2, you can do var == True or var == False)

  (In Python 1, you can do var == type)

  (In Python 2, you can do var == type)

  (In Python 3, you can do var == type)

  (In Python 2, you can do var == type)

  (In Python 3, you can do var == type)

  (In Python 2, you can do var == type)

  (In Python 3, you can do var == type)

  (In Python 2, you can do var == type)

  (In Python 3, you can do var == type)

  (In Python 2, you can var == type)

  (In Python 3, you can var == type)

  (In Python 2, you can var == type)

  (In Python 1, you can var == type)

  (In Python 2, you can var == type)

  (In Python 2, you can var == type)

  (In Python 3, you can var == type)

  (In Python 2, you can var == type)

  (In Python 3, you can var == type)

  (In Python 2, you can var == type)

  (In Python 3, you can var == type)

  (In Python 2, you can var == type)

  (In Python 2, you can var","I've got a Python program where two variables are set to the value 'public'. In a conditional expression I have the comparison var1 is var2 which fails, but if I change it to var1 == var2 it returns True.
Now if I open my Python interpreter and do the same ""is"" comparison, it succeeds.
>>> s1 = 'public'
>>> s2 = 'public'
>>> s2 is s1
True

What am I missing here?
","I am answering the question even though the question is to old because no answers above quotes the language reference
Actually the is operator checks for identity and == operator checks for equality,
From Language Reference:
Types affect almost all aspects of object behavior. Even the importance of object identity is affected in some sense: for immutable types, operations that compute new values may actually return a reference to any existing object with the same type and value, while for mutable objects this is not allowed. E.g., after a = 1; b = 1, a and b may or may not refer to the same object with the value one, depending on the implementation, but after c = []; d = [], c and d are guaranteed to refer to two different, unique, newly created empty lists. (Note that c = d = [] assigns the same object to both c and d.)
so from above statement we can infer that the strings which is an immutable type may fail when checked with ""is"" and may checked succeed when checked with ""is""
The same applies for int,tuple which are also immutable types
"
"[INST] I have always used tabs for indentation when I do Python programming. But then I came across a question here on SO where someone pointed out that most Python programmers use spaces instead of tabs to minimize editor-to-editor mistakes.
How does that make a difference? Are there other reasons why one would use spaces instead of tabs for Python? Or is it simply not true?
Should I switch my editor to insert spaces instead of tabs right away or keep on going like I used to?
 [/INST] The only difference between how and how you do tab complete for Python tabulation is the way you do the assignment.  If you keep the space bar pressed down (shift+space)) you get a line with space at the beginning and then tabs+space+Tab=0.  If you press space+Tab, you're in ""insert tab"".
 ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                  # Python tabulation for space+Tab
                    # Python tabulation for space+Tab
                    # Python tabulation for space+Tab
                    # Python space for Python (tab=0, space=1, Tab=2,...)
                    # Python tabulation for space+Tab
                    # Tabulation for space+Tab=0,...
                    # spaces+delims for tabulation, not spaces+delims
                    # (1,2,3,4,5,6,7)
                    # (1,2,3,4,2,5,6,7)

# # Python tabulation for space+Tab=2,3,4,5,6,7
# # # Tab=2,3,4,5,6
# # (3,4,4,5,6,7)
# # (3,4,5,6,7)
# # (1,2,3,4,5,6,7)
# (3,4,5,6,7)
# (1,2,3,4,5,6,7)

 [/INST] spaces+delims for Python is:
(1,2,3,4,5,7)

(1,2,3,4","I have always used tabs for indentation when I do Python programming. But then I came across a question here on SO where someone pointed out that most Python programmers use spaces instead of tabs to minimize editor-to-editor mistakes.
How does that make a difference? Are there other reasons why one would use spaces instead of tabs for Python? Or is it simply not true?
Should I switch my editor to insert spaces instead of tabs right away or keep on going like I used to?
","Tabs rule.  Same argument for nested loops and you want to bring the outer loop ""back"" 1 level.  Tip: If you want to convert old space-riddled python code into tabs use the TabOut utility available as an executable on http://www.textpad.com/add-ons/.
"
"[INST] I need to execute a Python script from the Django shell. I tried
./manage.py shell << my_script.py

But it didn't work. It was just kinda waiting for me to write something.
 [/INST] I had the same problem, so I copied the shell_name from the command line and added it to the.env file. Then I would just run /path/to/your/script.py and it would run the script and then exit.
I also added the -u flag to the command line arguments for the interactive shell command
./manage.py shell << my_env << my_command>

And it worked perfectly.
  shell_cmd <<.shell_cmd my_env but it didn't work

  shell_cmd <<.shell_cmd my_env

 ...

  shell_cmd += shell_cmd

  #.shell_env is set in the settings.py file
  exec my_env

  # shell_env is set in the settings.py shell
  exec my_env

  # shell_env is set in the shell environment

  # execute shell_cmd from the.shell_env file
  # execute shell_cmd from the.shell_name

  shell_env = (shell_env, shell_cmd)

  # execute shell_env from the.shell_name
  shell_cmd = (shell_env, shell_cmd)

#! shell_name is in the shell environment

  shell_env = (shell_name, shell_cmd)

  shell_env = (shell_env, shell_cmd)

  # execute shell_env from the shell_cmd
  # shell_name = shell_name

  # (shell_name, shell_cmd) is set in the shell_name in the shell_file

  # shell_name is set in the shell_name (shell_name)

  shell_env = os.environ

  shell_env = ""shell_name""
  shell_env += ""shell_name="" + shell_env

  shell_env = os.environ
  exec shell_cmd from the shell_name]

  # execute shell","I need to execute a Python script from the Django shell. I tried
./manage.py shell << my_script.py

But it didn't work. It was just kinda waiting for me to write something.
","The << part is wrong, use < instead:
$ ./manage.py shell < myscript.py

You could also do:
$ ./manage.py shell
...
>>> execfile('myscript.py')

"
"[INST] In Python, what commands can I use to find:

the current directory (where I was in the terminal when I ran the Python script), and
where the file I am executing is?

 [/INST] If you run your script from the terminal and then try to execute the first few lines of code, you will get a traceback trace of your script and the terminal information.  The output will be something like:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in?
    x = 0
  File /Users/Username/Desktop/Projects/myproject/__init__.py"", line 2, in?
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 2, in?
  Traceback (/desktop/Projects/__init__.py"", line 2, in?
    traceback ().__init__()) 

Note that the traceback module is very useful for debugging purposes, and it is documented in the Python traceback module documentation.
  Traceback (most recent call last):
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 2, in?
    print(x)
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 2, in?
    print(x)

  File ""/Users/Username/Desktop/Projects/__init__.py"", line 2, in?
    print(x)
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 2, in?
    Traceback (most recent call last):
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 27, in?
  File ""/Desktop/Projects/__init__.py"", line 27, in?
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 2, in?
    print(""Your code is not in what you wanted"")
  File ""/Users/Username/Desktop/Projects/__init__.py"", line 27, in?
    print(""Your code is not where you wanted"")","In Python, what commands can I use to find:

the current directory (where I was in the terminal when I ran the Python script), and
where the file I am executing is?

","If you're using Python 3.4, there is the brand new higher-level pathlib module which allows you to conveniently call pathlib.Path.cwd() to get a Path object representing your current working directory, along with many other new features.
More info on this new API can be found here.
Note: The pathlib module API is currently a provisional API, which means there is no guarantee of backward compatibility. More on provisional APIs can be found here
"
"[INST] Is there a way to get all attributes/methods/fields/etc. of an object in Python?
vars() is close to what I want, but it doesn't work unless an object has a __dict__, which isn't always true (e.g. it's not true for a list, a dict, etc.).
 [/INST] In Python 3, there is an attribute __all__ which lets you access all attributes (not just methods, fields, etc.) defined in the class definition. This is particularly useful when you want to subclass a type:
class MyClass(object):
    def __get__(self):
        print(""not implemented in this class"" % self.attr)

    def __set__(self, value):
        print(""not defined in this class"" % self.attr)

Note that this is not a general-purpose pattern because __get__ is not a good solution for this kind of thing.  (I also expect to eventually have __set__ and __get__ special methods, but that's a bit tricky.)
  Note that __get__ is only applicable if __all__ is not in the parent class (i.e. not in the __init__ method).

Note that __getattr__ is also called __getattr__ in __new__ (see PEP-329).
  Note that __getattr__ is only applicable if the attribute is not defined in the parent class (i.e. not in the __new__ part).
  Note that __getattr__ is also called __getattr__ in __new__ (see PEP-329).

 [/INST] This is a complete, but incomplete/not-standard (PEP-329) definition for a class:
class MyClass(object):
    def __get__(self):
        self.attr = vars.__get__(self, a, b)
       ...

    def __set__(self, a, b):
        self.attr = a, b
       ...

__get__(self, a, b) returns a list of all attributes/methods not present in self.b (i.e. a, b in this case)
def __set__(self, a, b):
    self.","Is there a way to get all attributes/methods/fields/etc. of an object in Python?
vars() is close to what I want, but it doesn't work unless an object has a __dict__, which isn't always true (e.g. it's not true for a list, a dict, etc.).
","What you probably want is dir().
The catch is that classes are able to override the special __dir__ method, which causes dir() to return whatever the class wants (though they are encouraged to return an accurate list, this is not enforced). Furthermore, some objects may implement dynamic attributes by overriding __getattr__, may be RPC proxy objects, or may be instances of C-extension classes. If your object is one these examples, they may not have a __dict__ or be able to provide a comprehensive list of attributes via __dir__: many of these objects may have so many dynamic attrs it doesn't won't actually know what it has until you try to access it. 
In the short run, if dir() isn't sufficient, you could write a function which traverses __dict__ for an object, then __dict__ for all the classes in obj.__class__.__mro__; though this will only work for normal python objects. In the long run, you may have to use duck typing + assumptions - if it looks like a duck, cross your fingers, and hope it has .feathers.
"
"[INST] What does the if __name__ == ""__main__"": do?
# Threading example
import time, thread

def myfunction(string, sleeptime, lock, *args):
    while 1:
        lock.acquire()
        time.sleep(sleeptime)
        lock.release()
        time.sleep(sleeptime)
if __name__ == ""__main__"":
    lock = thread.allocate_lock()
    thread.start_new_thread(myfunction, (""Thread #: 1"", 2, lock))
    thread.start_new_thread(myfunction, (""Thread #: 2"", 2, lock))

 [/INST]artharthartharthdorfarthdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfowoarthdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfowoowoowodorfненowodorfdorfshadorfarthdorfdorfarthdorfshaetidorfshadorfdorfdorfdorfdorfdorfdorfdorfetidorfdorfdorfdorfdorfdorfdorfdorfdorfdorfarthdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfowoowoowoowoowoowoarthdorfshadorfdorfdorfdorfshashadorfdorfdorfdorfdorfdorfdorfdorfdorfarthdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfpecpecpecненarthiomiomiomdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfowoowoowodorfshapecdorfowoowodorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfiomdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfненdorfdorfdorfненdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfowoowodorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfненненdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorf","What does the if __name__ == ""__main__"": do?
# Threading example
import time, thread

def myfunction(string, sleeptime, lock, *args):
    while 1:
        lock.acquire()
        time.sleep(sleeptime)
        lock.release()
        time.sleep(sleeptime)
if __name__ == ""__main__"":
    lock = thread.allocate_lock()
    thread.start_new_thread(myfunction, (""Thread #: 1"", 2, lock))
    thread.start_new_thread(myfunction, (""Thread #: 2"", 2, lock))

","
What does if __name__ == â__main__â: do?

__name__ is a global variable (in Python, global actually means on the module level) that exists in all namespaces. It is typically the module's name (as a str type).
As the only special case, however, in whatever Python process you run, as in mycode.py:
python mycode.py

the otherwise anonymous global namespace is assigned the value of '__main__' to its __name__. 
Thus, including the final lines
if __name__ == '__main__':
    main()


at the end of your mycode.py script,
when it is the primary, entry-point module that is run by a Python process, 

will cause your script's uniquely defined main function to run. 
Another benefit of using this construct: you can also import your code as a module in another script and then run the main function if and when your program decides:
import mycode
# ... any amount of other code
mycode.main()

"
"[INST] Why are there no ++ and -- operators in Python?
 [/INST] In Python 3, if you want to do a join, you have to use the + character (plus sign) to combine two lists:
a + b

b + c

c + b

Example:
a = [1, 2, 3]
b = [4, 5, 6]
c = +a + b

a + b
a + b

  +a + b

  # join list
a + b

  a + b

  # join two lists
a + c

  # join two lists
a + b

  # join two lists
a + b

  # join two list
a + b

  # join two list in Python
a + b

  # join two lists
a + c

  # join two lists
a + b

# join two lists
a + b

  # join two lists
a + b

  # join two lists
a + b

  # join two lists
a + b

 [/INST] The + operator is used to join two lists. It is used to concatenate two lists into a single list.
a + b + c
b + c

  # join two lists
a + b + c

  # join two lists into one list:
a + c

  # join two lists into one list
a + c

  # join two lists into one list:
a + b

  # join two lists into one list:
a + b

  # join two lists into one list:
a + b

  # join two lists into one list:
a + b

  # join two lists into two list
a + b + c

  # join two lists into one list:
a + b

  # join three list into one list:
a + b + c

  # join two lists into one list:
a + b + c

  # join two lists into one list:
a + b + c

  # join two lists into one list:
a + b + c

  # join two lists into","Why are there no ++ and -- operators in Python?
","Clarity!
Python is a lot about clarity and no programmer is likely to correctly guess the meaning of --a unless s/he's learned a language having that construct.
Python is also a lot about avoiding constructs that invite mistakes and the ++ operators are known to be rich sources of defects.
These two reasons are enough not to have those operators in Python.
The decision that Python uses indentation to mark blocks rather
than syntactical means such as some form of begin/end bracketing 
or mandatory end marking is based largely on the same considerations.
For illustration, have a look at the discussion around introducing a conditional operator (in C: cond ? resultif : resultelse) into Python in 2005.
Read at least the first message and the decision message of that discussion (which had several precursors on the same topic previously).
Trivia:
The PEP frequently mentioned therein is the ""Python Extension Proposal"" PEP 308. LC means list comprehension, GE means generator expression (and don't worry if those confuse you, they are none of the few complicated spots of Python).
"
"[INST] I want to detect whether module has changed. Now, using inotify is simple, you just need to know the directory you want to get notifications from.
How do I retrieve a module's path in python?
 [/INST] import sys
sys.path.append(sys.getloader()) # relative to current dir

  # absolute path, relative to current dir
  sys.path.append(sys.getdir()) # relative to current dir
  # absolute path, relative to parent directory

sys.getfilerename(sys.argv[0]) # absolute path
sys.getabsolutepath(sys.argv[0]) # absolute path

  # relative to parent dir
    from sys import exit_static
    from inspect import call
    call(""from __file__"") # relative to current dir
    from inspect import * # new style relative to current dir

For RPy 2.7.1 and RPy 3.0.1
For RPy 2.6.2 and 0.7.0 # new style
For RPy 2.6.1 and 0.8.1 # new style
For RPy 2.6.1 and 0.8.0 # new style
For RPy 2.6.1 and 0.6.1 (from __file__ and 0.6.0)
from inspect import getloader
from inspect import call  # new style
from inspect import * # new style

  # new style
  from inspect import * # new style
  # new style
  # new property

For RPy __getdir__ and RPy __absolve__, see the docs for RPy.
  # new style
  @caller
 def __get_dir__(self):
    from inspect import getloader
    from inspect import * # new style
    self.getloader() # new style
    # new style
    for name in sys.getargv():
      # new style

@new-style-end(self) # new style
def getdir__():
  # new style
  # new style
  from inspect import getloader
  from inspect import * # new style
  # new style

For RPy __","I want to detect whether module has changed. Now, using inotify is simple, you just need to know the directory you want to get notifications from.
How do I retrieve a module's path in python?
","I will try tackling a few variations on this question as well:

finding the path of the called script  
finding the path of the currently executing script  
finding the directory of the called script

(Some of these questions have been asked on SO, but have been closed as duplicates and redirected here.)
Caveats of Using __file__
For a module that you have imported:
import something
something.__file__ 

will return the absolute path of the module.  However, given the folowing script foo.py:
#foo.py
print '__file__', __file__

Calling it with 'python foo.py' Will return simply 'foo.py'.  If you add a shebang:
#!/usr/bin/python 
#foo.py
print '__file__', __file__

and call it using ./foo.py, it will return './foo.py'.  Calling it from a different directory, (eg put foo.py in directory bar), then calling either
python bar/foo.py

or adding a shebang and executing the file directly:
bar/foo.py

will return 'bar/foo.py' (the relative path).
Finding the directory
Now going from there to get the directory, os.path.dirname(__file__) can also be tricky.  At least on my system, it returns an empty string if you call it from the same directory as the file.  ex.
# foo.py
import os
print '__file__ is:', __file__
print 'os.path.dirname(__file__) is:', os.path.dirname(__file__)

will output:
__file__ is: foo.py
os.path.dirname(__file__) is: 

In other words, it returns an empty string, so this does not seem reliable if you want to use it for the current file (as opposed to the file of an imported module).  To get around this, you can wrap it in a call to abspath:
# foo.py
import os
print 'os.path.abspath(__file__) is:', os.path.abspath(__file__)
print 'os.path.dirname(os.path.abspath(__file__)) is:', os.path.dirname(os.path.abspath(__file__))

which outputs something like:
os.path.abspath(__file__) is: /home/user/bar/foo.py
os.path.dirname(os.path.abspath(__file__)) is: /home/user/bar

Note that abspath() does NOT resolve symlinks.  If you want to do this, use realpath() instead.  For example, making a symlink file_import_testing_link pointing to file_import_testing.py, with the following content:
import os
print 'abspath(__file__)',os.path.abspath(__file__)
print 'realpath(__file__)',os.path.realpath(__file__)

executing will print absolute paths something like:
abspath(__file__) /home/user/file_test_link
realpath(__file__) /home/user/file_test.py

file_import_testing_link -> file_import_testing.py
Using inspect
@SummerBreeze mentions using the inspect module.
This seems to work well, and is quite concise, for imported modules:
import os
import inspect
print 'inspect.getfile(os) is:', inspect.getfile(os)

obediently returns the absolute path.  However for finding the path of the currently executing script, I did not see a way to use it.
"
"[INST] I'm using the Python bindings to run Selenium WebDriver.
from selenium import webdriver
wd = webdriver.Firefox()

I know I can grab a webelement like so...
elem = wd.find_element_by_css_selector('#my-id')

And I know I can get the full page source with...
wd.page_source

But is there anyway to get the ""element source""?
elem.source   # <-- returns the HTML as a string

The selenium webdriver docs for Python are basically non-existent and I don't see anything in the code that seems to enable that functionality.
Any thoughts on the best way to access the HTML of an element (and its children)?
 [/INST] I've found that wd.page_source() is not always correct. For example, for example, if I have a <div> and I want to get the text content, I want the text that I want to read.
I found this solution somewhere on the Google github github.page_source_viewer - but I'm not sure if that is correct and I haven't found where in the documentation.
 
@wds.page_source
@wd.page_source

@wd.page_source is actually the source of the HTML, so if you have a way of finding the element out, this seems to be a good place to start.
@wd.page_source is actually the element that you'd normally expect, but I don't know why selenium finds #my_element, and it may get confused if there is one or more elements in the page.
@wd.source is the source of the element, but I don't know what it is out (I think that's what @wd.source). I know it's not always 100% accurate, but I think there's a better way to do this, just curling around the edge
@wd.all_elements_selected_by_css_selector()

 
@wd.all_elements_selected_by_css_selector()

@wd.find_element_by_id_out_of_type('element')
@wd.find","I'm using the Python bindings to run Selenium WebDriver.
from selenium import webdriver
wd = webdriver.Firefox()

I know I can grab a webelement like so...
elem = wd.find_element_by_css_selector('#my-id')

And I know I can get the full page source with...
wd.page_source

But is there anyway to get the ""element source""?
elem.source   # <-- returns the HTML as a string

The selenium webdriver docs for Python are basically non-existent and I don't see anything in the code that seems to enable that functionality.
Any thoughts on the best way to access the HTML of an element (and its children)?
","You can read innerHTML attribute to get source of the content of the element or outerHTML for source with the current element.
Python:
element.get_attribute('innerHTML')

Java:
elem.getAttribute(""innerHTML"");

C#:
element.GetAttribute(""innerHTML"");

Ruby:
element.attribute(""innerHTML"")

Tested and works with the ChromeDriver.
"
"[INST] Yes, I know this subject has been covered before (here, here, here, here), but as far as I know, all solutions, except for one, fail on a list like this:
L = [[[1, 2, 3], [4, 5]], 6]

Where the desired output is
[1, 2, 3, 4, 5, 6]

Or perhaps even better, an iterator. The only solution I saw that works for an arbitrary nesting is found in this question:
def flatten(x):
    result = []
    for el in x:
        if hasattr(el, ""__iter__"") and not isinstance(el, basestring):
            result.extend(flatten(el))
        else:
            result.append(el)
    return result

flatten(L)

Is this the best model? Did I overlook something? Any problems?
 [/INST] The other answers about list comprehensions are fine, but they suffer from the following issue:
[1, 5, 6]
[1, 5, 6, 7]

The problem with this is that the result is not always a list. It's a sequence of tuples. If you do:
[1, 5, 6, 7]

you get:
[1, 5, 7, 8, 9]

However, you can do the same thing with a list comprehension:
[1, 5, 6]

And in this case, you want
[1, 5, 6, [1, 2, 3, 7]]

as in this example:
[1, 5, 6, 4, 1]


Here is the corresponding Python code:
[1, 5, 6, [1, 5, 6]]

The reason is that the list comprehensions, as in any other way, ""map"" ([1, 5, 6]) is expected to perform an operation on an list. By convention, the parameters of a function are the same as the variables in the function, i.e. one will have to use a tuple (if the","Yes, I know this subject has been covered before (here, here, here, here), but as far as I know, all solutions, except for one, fail on a list like this:
L = [[[1, 2, 3], [4, 5]], 6]

Where the desired output is
[1, 2, 3, 4, 5, 6]

Or perhaps even better, an iterator. The only solution I saw that works for an arbitrary nesting is found in this question:
def flatten(x):
    result = []
    for el in x:
        if hasattr(el, ""__iter__"") and not isinstance(el, basestring):
            result.extend(flatten(el))
        else:
            result.append(el)
    return result

flatten(L)

Is this the best model? Did I overlook something? Any problems?
","def flatten(xs):
    res = []
    def loop(ys):
        for i in ys:
            if isinstance(i, list):
                loop(i)
            else:
                res.append(i)
    loop(xs)
    return res

"
"[INST] I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup. 
The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.
One of the sections of code that is causing problems is shown below:
agent_telno = agent.find('div', 'agent_contact_number')
agent_telno = '' if agent_telno is None else agent_telno.contents[0]
p.agent_info = str(agent_contact + ' ' + agent_telno).strip()

Here is a stack trace produced on SOME strings when the snippet above is run:
Traceback (most recent call last):
  File ""foobar.py"", line 792, in <module>
    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()
UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)

I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.
Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?
 [/INST] I've had this issue on two different agents, and I have found a few ways to work around it:

1. Use the `unicode' builtin
2. Use the builtin str() function

2. Use the str() and the unicode() calls, and make sure that the two values are indeed ""unicode""

agent_info = u'\xa0'
bar = u'\xd0'

try:
    x = '\xa","I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup. 
The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a UnicodeEncodeError. I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error.
One of the sections of code that is causing problems is shown below:
agent_telno = agent.find('div', 'agent_contact_number')
agent_telno = '' if agent_telno is None else agent_telno.contents[0]
p.agent_info = str(agent_contact + ' ' + agent_telno).strip()

Here is a stack trace produced on SOME strings when the snippet above is run:
Traceback (most recent call last):
  File ""foobar.py"", line 792, in <module>
    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()
UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)

I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English.
Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem?
","I've actually found that in most of my cases, just stripping out those characters is much simpler:
s = mystring.decode('ascii', 'ignore')

"
"[INST] The following use of super() raises a TypeError: why?
>>> from  HTMLParser import HTMLParser
>>> class TextParser(HTMLParser):
...     def __init__(self):
...         super(TextParser, self).__init__()
...         self.all_data = []
...         
>>> TextParser()
(...)
TypeError: must be type, not classobj

There is a similar question on StackOverflow: python super() raises TypeError ! Why?, where the error is explained by the fact that the user class is not a new-style class.  However, the class above is a new-style class, as it inherits from object:
>>> isinstance(HTMLParser(), object)
True

What am I missing? How can I use super(), here?
Using HTMLParser.__init__(self) instead of super(TextParser, self).__init__() would work, but I would like to understand the TypeError.
PS: Joachim pointed out that being a new-style-class instance is not equivalent to being an object. I read the opposite many times, hence my confusion (example of new-style class instance test based on object instance test: http://stackoverflow.com/revisions/2655651/3).
 [/INST] I've had similar issues in the past, and have seen this type error on at least two occasions (both involving a poorly designed type-checking mechanism, and an unrelated object) and I have not yet seen how to fix it.  If someone can help me with a solution, please let me know.  (I understand that this question is not for the type-checking, but for general knowledge, I also understand that this is a type-error.)
>>> class MyTextParser(object):
...     def __init__(self):
...         self.all_data = []
...        
>>> MyTextParser(self).all_data)
TypeError: must be type, not class

The reason is that myTextParser is not a class and has the TypeError raised by the TypeError. I don't fully understand why this is an issue, but I do know that myTextParser is a list/dict and not classobj, so that is where my problem lies.  I","The following use of super() raises a TypeError: why?
>>> from  HTMLParser import HTMLParser
>>> class TextParser(HTMLParser):
...     def __init__(self):
...         super(TextParser, self).__init__()
...         self.all_data = []
...         
>>> TextParser()
(...)
TypeError: must be type, not classobj

There is a similar question on StackOverflow: python super() raises TypeError ! Why?, where the error is explained by the fact that the user class is not a new-style class.  However, the class above is a new-style class, as it inherits from object:
>>> isinstance(HTMLParser(), object)
True

What am I missing? How can I use super(), here?
Using HTMLParser.__init__(self) instead of super(TextParser, self).__init__() would work, but I would like to understand the TypeError.
PS: Joachim pointed out that being a new-style-class instance is not equivalent to being an object. I read the opposite many times, hence my confusion (example of new-style class instance test based on object instance test: http://stackoverflow.com/revisions/2655651/3).
","If you look at the inheritance tree (in version 2.6), HTMLParser inherits from SGMLParser which inherits from ParserBase which doesn't inherits from object. I.e. HTMLParser is an old-style class.
About your checking with isinstance, I did a quick test in ipython:

In [1]: class A:
   ...:     pass
   ...: 

In [2]: isinstance(A, object)
Out[2]: True

Even if a class is old-style class, it's still an instance of object.
"
"[INST] I'm pretty much new in Python object oriented programming and I have trouble
understanding the super() function (new style classes) especially when it comes to multiple inheritance.
For example if you have something like:
class First(object):
    def __init__(self):
        print ""first""

class Second(object):
    def __init__(self):
        print ""second""

class Third(First, Second):
    def __init__(self):
        super(Third, self).__init__()
        print ""that's it""

What I don't get is: will the Third() class inherit both constructor methods? If yes, then which one will be run with super() and why?
And what if you want to run the other one? I know it has something to do with Python method resolution order (MRO). 
 [/INST] I am not sure why (already in the first part) is a good idea, but here is a super(third!)!):
def __init__(self):
    pass

 [/] 
def get_first(self):
    b = [1, 2]
    c = [2, 3]
    def __init__(self):
        pass

    def __call__(self):
        call(self)
        def get_first(self):
        pass
        def __init__(self):
        call(self)
        pass

 [/]
def __call__(self):
    pass

 [list]
def __call__(self, message):
    pass

 [raw]
def __call__(self):
    pass

 [l]
..]
>>> def __call(self):
    pass
>>> def __init__(self):
        pass
>>>
>>> call(self)
>>> call(self)
>>> call(self)
>>>
>>> call(self)
>>>
>>> call(self)
>>> call(self)
>>> call(self)
>>> call(self)
>>>
>>> call(self)
>>> call(self)
>>>
>>> def __call__(self, message):
>>> call(self)
>>>
>>>
>>> def __call(self):","I'm pretty much new in Python object oriented programming and I have trouble
understanding the super() function (new style classes) especially when it comes to multiple inheritance.
For example if you have something like:
class First(object):
    def __init__(self):
        print ""first""

class Second(object):
    def __init__(self):
        print ""second""

class Third(First, Second):
    def __init__(self):
        super(Third, self).__init__()
        print ""that's it""

What I don't get is: will the Third() class inherit both constructor methods? If yes, then which one will be run with super() and why?
And what if you want to run the other one? I know it has something to do with Python method resolution order (MRO). 
","This is to how I solved to issue of having multiple inheritance with different variables for initialization and having multiple MixIns with the same function call.  I had to explicitly add variables to passed **kwargs and add a MixIn interface to be an endpoint for super calls.
Here A is an extendable base class and B and C are MixIn classes both who provide function f.  A and B both expect parameter v in their __init__ and C expects w.
The function f takes one parameter y.  Q inherits from all three classes. MixInF is the mixin interface for B and C.

IPython NoteBook Of This Code
Github Repo with code example


class A(object):
    def __init__(self, v, *args, **kwargs):
        print ""A:init:v[{0}]"".format(v)
        kwargs['v']=v
        super(A, self).__init__(*args, **kwargs)
        self.v = v


class MixInF(object):
    def __init__(self, *args, **kwargs):
        print ""IObject:init""
    def f(self, y):
        print ""IObject:y[{0}]"".format(y)


class B(MixInF):
    def __init__(self, v, *args, **kwargs):
        print ""B:init:v[{0}]"".format(v)
        kwargs['v']=v
        super(B, self).__init__(*args, **kwargs)
        self.v = v
    def f(self, y):
        print ""B:f:v[{0}]:y[{1}]"".format(self.v, y)
        super(B, self).f(y)


class C(MixInF):
    def __init__(self, w, *args, **kwargs):
        print ""C:init:w[{0}]"".format(w)
        kwargs['w']=w
        super(C, self).__init__(*args, **kwargs)
        self.w = w
    def f(self, y):
        print ""C:f:w[{0}]:y[{1}]"".format(self.w, y)
        super(C, self).f(y)


class Q(C,B,A):
    def __init__(self, v, w):
        super(Q, self).__init__(v=v, w=w)
    def f(self, y):
        print ""Q:f:y[{0}]"".format(y)
        super(Q, self).f(y)

"
"[INST] I made a function which will look up ages in dictionary and show the matching name:
list = {'george':16,'amber':19}
search_age = raw_input(""Provide age"")
for age in list.values():
    if age == search_age:
        name = list[age]
        print name

I know how to compare and find the age I just don't know how to show the name of the person. Additionally, I am getting a KeyError because of line 5. I know it's not correct but I can't figure out to make it search backwards.
 [/INST] list[] = [1, 2, 3]
search_age = list[age]

def george():
    name = list[age]
    return name

list[] = [1, 2, 3]

  list_age = [1, 2, 3]

  # check if the list contains the age:
for age in list:
    name = list[age]
    if age > 1:
        name = list[age]

  # check if the age in the list is within range:
    list[list][0] = list
    # list_age(list[0])
    for age in list:
      # list_age()
      # list_name(list[0]) => list[1]

 [/INST] list = list()
if list[0] in list:
    # check if age in list:
    name = list[0]
    for name in list:
        # list[age]:0]
        # list[0, 1, 2]

raw_age = list(1, 2, 3)

list[0] and 1, 1, 2, 3

 [/list] list = list()
list[0] and 1
list[1] and 2
list[2] and 3

list[1] and 2:

list[2] and 3
list[1, 2, 3]

list[1, 2, 3]

list[1,","I made a function which will look up ages in dictionary and show the matching name:
list = {'george':16,'amber':19}
search_age = raw_input(""Provide age"")
for age in list.values():
    if age == search_age:
        name = list[age]
        print name

I know how to compare and find the age I just don't know how to show the name of the person. Additionally, I am getting a KeyError because of line 5. I know it's not correct but I can't figure out to make it search backwards.
","I thought it would be interesting to point out which methods are the quickest, and in what scenario:
Here's some tests I ran (on a 2012 MacBook Pro)
>>> def method1(list,search_age):
...     for name,age in list.iteritems():
...             if age == search_age:
...                     return name
... 
>>> def method2(list,search_age):
...     return [name for name,age in list.iteritems() if age == search_age]
... 
>>> def method3(list,search_age):
...     return list.keys()[list.values().index(search_age)]

Results from profile.run() on each method 100000 times:
Method 1:
>>> profile.run(""for i in range(0,100000): method1(list,16)"")
     200004 function calls in 1.173 seconds

Method 2:
>>> profile.run(""for i in range(0,100000): method2(list,16)"")
     200004 function calls in 1.222 seconds

Method 3:
>>> profile.run(""for i in range(0,100000): method3(list,16)"")
     400004 function calls in 2.125 seconds

So this shows that for a small dict, method 1 is the quickest. This is most likely because it returns the first match, as opposed to all of the matches like method 2 (see note below).

Interestingly, performing the same tests on a dict I have with 2700 entries, I get quite different results (this time run 10000 times):
Method 1:
>>> profile.run(""for i in range(0,10000): method1(UIC_CRS,'7088380')"")
     20004 function calls in 2.928 seconds

Method 2:
>>> profile.run(""for i in range(0,10000): method2(UIC_CRS,'7088380')"")
     20004 function calls in 3.872 seconds

Method 3:
>>> profile.run(""for i in range(0,10000): method3(UIC_CRS,'7088380')"")
     40004 function calls in 1.176 seconds

So here, method 3 is much faster. Just goes to show the size of your dict will affect which method you choose.
Notes:
Method 2 returns a list of all names, whereas methods 1 and 3 return only the first match.
I have not considered memory usage. I'm not sure if method 3 creates 2 extra lists (keys() and values()) and stores them in memory.
"
"[INST] How can I make two decorators in Python that would do the following?
@makebold
@makeitalic
def say():
   return ""Hello""

...which should return:
""<b><i>Hello</i></b>""

I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.
 [/INST] The best way to do this is by following the decoration:
def say():
    return ""Hello""
    return ""Hello""

# you should...
try:
    @say()
    @return ""Hello""

  # say:
    @return ""Hello""

  # say:
    @return ""Hello""

However, the best way to do this is by following the decoration:
def hell():
    return ""Hello""

# and ""Hello""...
def say():
    return ""Hello""

 [/INST] # Say ""Hello""
def say():
    # Say ""Hello""
    # Say ""Hello""

# Say ""Hello""
try = ""Hello""
# Say:
# def say():
# Say:
# Say:
# def Hello():
#   Say:
# Say:
# Hello
# def is ""Hello""
# Say:
# Hello
# def is (""Hello"")
# from 1 to 1
# def say():
# Hello
# Say:
# Hello
# Hello
# def say()

# Hello
# Say:
# Hello
# Hello
# Say:
# Hello
# Hello
# Hello
# Hello
# Hello
# Hello
# Hello
# Hello
# Hello
# Say:
# Hello
# Hello
# Say:
# Say:
# Say:
# Say:
# Say:
# Say:
# Say:
# Hello
# Say:
# Say:
# Hello
# Say:
# Say:
# Say:
# Say:
# Hello
# Hello
# Hello
# Hello
# Hello
# Say:
# Hello
# Hello
# Hello
# Hello
# Hello
# Hello
# Hello
# Say:
","How can I make two decorators in Python that would do the following?
@makebold
@makeitalic
def say():
   return ""Hello""

...which should return:
""<b><i>Hello</i></b>""

I'm not trying to make HTML this way in a real application - just trying to understand how decorators and decorator chaining works.
","Another way of doing the same thing:
class bol(object):
  def __init__(self, f):
    self.f = f
  def __call__(self):
    return ""<b>{}</b>"".format(self.f())

class ita(object):
  def __init__(self, f):
    self.f = f
  def __call__(self):
    return ""<i>{}</i>"".format(self.f())

@bol
@ita
def sayhi():
  return 'hi'

Or, more flexibly:
class sty(object):
  def __init__(self, tag):
    self.tag = tag
  def __call__(self, f):
    def newf():
      return ""<{tag}>{res}</{tag}>"".format(res=f(), tag=self.tag)
    return newf

@sty('b')
@sty('i')
def sayhi():
  return 'hi'

"
"[INST] Does time.time() in the Python time module return the system's time or the time in UTC?
 [/INST] The time module in the Python module provides a simple method for getting the time in the local time zone. It is easy to use and quick to remember:
from time import time

def getTime():
    return time.time()

# get the time in UTC
print getTime()

# get the time in local time
time.time()

The time in UTC time is 12:00 on the first day of January.
  Note: the UTC time in the first example is the time on the earth's time zone.

  Note: the time in UTC time is the time in the first year of the epoch.

  Note: the time in local time is the time on the year the time was created.

  Note: the time in the UTC timezone is 12:00 on the first day of the year.

  [/INST] Note that the time.localtime() method in the Python time module is not always accurate. It returns the time in the local timezone, which may be different from the time.time in the UTC timezone.
http://docs.python.org/2/howto/index.html
http://docs.python.org/2/datetime.time()
  Note that the time.time() method returns UTC time, not local time.
  Note that the result of running the time.time() as compared to the actual time.time() in the UTC timezone.
  Note that the time.struct_timezone, which is the default time in the first example, is also returned by the time.structtime.timezone.
  Note that the time.structtime.time() method is not always present, and may return different results depending on the timezone.
  Note that the result of the first call of time.time() may be different from the first call of the first example, and may change if the timezone changes. 
  Note that the time.time() may be different from the result of the first example, and may change if the timezone changes.
  Note that the time.time() may be different from the first call of the first example, and may","Does time.time() in the Python time module return the system's time or the time in UTC?
","Based on the answer from #squiguy, to get a true timestamp I would type cast it from float. 
>>> import time
>>> ts = int(time.time())
>>> print(ts)
1389177318

At least that's the concept.
"
"[INST] Can someone explain to me the difference between doing:
class Child(SomeBaseClass):
    def __init__(self):
        super(Child, self).__init__()

and this:
class Child(SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)

I've seen super being used quite a lot in classes with only single inheritance. I can see why you'd use it in multiple inheritance but am unclear as to what the advantages are of using it in this kind of situation.
 [/INST] The other answers are correct in that you don't need to explicitly state that you're calling a base class in the first place (assuming you're not in the ""factory"" mode of programming). You can just define the class's name in someplace, then have it inherit from that class:
class Child(SomeBaseClass):
    def __init__(self):
        print ""some BaseClass""

class SomeBaseClass(SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)

class SomeBaseClass(SomeBaseClass):
    def __init__(SomeBaseClass):
        print ""some BaseClass""

class SomeBaseClass(SomeBaseClass):
    def __init__(self):
        print ""some BaseClass""

class SomeBaseClass(SomeBaseClass):
    def __init__(self):
        print ""some BaseClass""

class SomeBaseClass():
    def __init__(self):
        SomeBaseClass.__init__(self)

class SomeBaseClass():
    def __init__(self):
        SomeBaseClass.__init__(self)

SomeBaseClass.__init__(SomeBaseClass, SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)

SomeBaseClass.py...

SomeBaseClass.__init__(self)
someBaseClass.py...

__init__(SomeBaseClass, SomeBaseClass):
def __init__(self):
   ...

# SomeBaseClass
class SomeBaseClass(SomeBaseClass):
    def __init__(self):
       ...

SomeBaseClass.__init__(self)

","Can someone explain to me the difference between doing:
class Child(SomeBaseClass):
    def __init__(self):
        super(Child, self).__init__()

and this:
class Child(SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)

I've seen super being used quite a lot in classes with only single inheritance. I can see why you'd use it in multiple inheritance but am unclear as to what the advantages are of using it in this kind of situation.
","
Can someone explain to me the difference between doing:
class Child(SomeBaseClass):
    def __init__(self):
        super(Child, self).__init__()

and this:
class Child(SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)


Indirection with Forward Compatibility
What does it give you? For single inheritance, the above is practically identical from a static analysis point of view. However, using super gives you a layer of indirection with forward compatibility.
Forward compatibility is very important to seasoned developers. You want your code to keep working with minimal changes as you change it. When you look at your revision history, you want to see precisely what changed when. 
You may start off with single inheritance, but if you decide to add another base class, you only have to change the line with the bases - if the bases change in a class you inherit from (say a mixin is added) you'd change nothing in this class. Particularly in Python 2, getting the arguments to super and the correct method arguments right can be difficult. If you know you're using super correctly with single inheritance, that makes debugging less difficult going forward.
Dependency Injection
Other people can use your code and inject parents into the method resolution:
class SomeBaseClass(object):
    def __init__(self):
        print('SomeBaseClass.__init__(self) called')

class UnsuperChild(SomeBaseClass):
    def __init__(self):
        print('Child.__init__(self) called')
        SomeBaseClass.__init__(self)

class SuperChild(SomeBaseClass):
    def __init__(self):
        print('SuperChild.__init__(self) called')
        super(SuperChild, self).__init__()

Say you add another class to your object, and want to inject a class between Foo and Bar (for testing or some other reason):
class InjectMe(SomeBaseClass):
    def __init__(self):
        print('InjectMe.__init__(self) called')
        super(InjectMe, self).__init__()

class UnsuperInjector(UnsuperChild, InjectMe): pass

class SuperInjector(SuperChild, InjectMe): pass

Using the un-super child fails to inject the dependency because the child you're using has hard-coded the method to be called after its own:
>>> o = UnsuperInjector()
UnsuperChild.__init__(self) called
SomeBaseClass.__init__(self) called

However, the class with the child that uses super can correctly inject the dependency:
>>> o2 = SuperInjector()
SuperChild.__init__(self) called
InjectMe.__init__(self) called
SomeBaseClass.__init__(self) called

Conclusion
Always use super to reference the parent class. 
What you intend is to reference the parent class that is next-in-line, not specifically the one you see the child inheriting from.
Not using super can put unnecessary constraints on users of your code.
"
"[INST] How do I copy a file in Python? I couldn't find anything under os.
 [/INST]

allot Glen Glen Glen Glenio

iGNGNGN

alloGN Glen Glen Glen


allGNGN

oGNGNGNGN

oGNGNGNGN

allGNGNGNGN

iGNGNGNGN

allGNGNGNGN

iGNGNGNGNGN

allGNGNGNGNGNGNGNGNGNGNGNGN

allGNGNGNGNGNGNGN

allGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGNGN


GNGNGNGNGNGNGN




GNGNGNGN












































































































































","How do I copy a file in Python? I couldn't find anything under os.
","Directory and File copy example - From Tim Golden's Python Stuff:
http://timgolden.me.uk/python/win32_how_do_i/copy-a-file.html
import os
import shutil
import tempfile

filename1 = tempfile.mktemp ("".txt"")
open (filename1, ""w"").close ()
filename2 = filename1 + "".copy""
print filename1, ""=>"", filename2

shutil.copy (filename1, filename2)

if os.path.isfile (filename2): print ""Success""

dirname1 = tempfile.mktemp ("".dir"")
os.mkdir (dirname1)
dirname2 = dirname1 + "".copy""
print dirname1, ""=>"", dirname2

shutil.copytree (dirname1, dirname2)

if os.path.isdir (dirname2): print ""Success""

"
"[INST] I'm trying to convert a longish hollow ""data"" class into a named tuple. My class currently looks like this:
class Node(object):
    def __init__(self, val, left=None, right=None):
        self.val = val
        self.left = left
        self.right = right

After conversion to namedtuple it looks like:
from collections import namedtuple
Node = namedtuple('Node', 'val left right')

But there is a problem here. My original class allowed me to pass in just a value and took care of the default by using default values for the named/keyword arguments. Something like:
class BinaryTree(object):
    def __init__(self, val):
        self.root = Node(val)

But this doesn't work in the case of my refactored named tuple since it expects me to pass all the fields. I can of course replace the occurrences of Node(val) to Node(val, None, None) but it isn't to my liking.
So does there exist a good trick which can make my re-write successful without adding a lot of code complexity (metaprogramming) or should I just swallow the pill and go ahead with the ""search and replace""? :)
TIA
-- sauke
 [/INST] In a more general way, you could define a subclass of Node:
class Node(object):
    def __new__(self, left, right):
        return self.new(left, right)
        def __new__(self, val):
            return Node(self, left, right)
        def __new__(self, val, name=None):
            return self.__new(left, right, name)
        def __new__(self, val, name=None):
            return Node(self, (val, left, right))

Then you could define the __new__(self, inst, val):
class Node(object):
    def __new__(self, left, right):
        return Node(self, left, right)

__new__(self, inst, val):
class Node(object):
    def __new__(self):
        return Node(self, left, right)

class Node(object","I'm trying to convert a longish hollow ""data"" class into a named tuple. My class currently looks like this:
class Node(object):
    def __init__(self, val, left=None, right=None):
        self.val = val
        self.left = left
        self.right = right

After conversion to namedtuple it looks like:
from collections import namedtuple
Node = namedtuple('Node', 'val left right')

But there is a problem here. My original class allowed me to pass in just a value and took care of the default by using default values for the named/keyword arguments. Something like:
class BinaryTree(object):
    def __init__(self, val):
        self.root = Node(val)

But this doesn't work in the case of my refactored named tuple since it expects me to pass all the fields. I can of course replace the occurrences of Node(val) to Node(val, None, None) but it isn't to my liking.
So does there exist a good trick which can make my re-write successful without adding a lot of code complexity (metaprogramming) or should I just swallow the pill and go ahead with the ""search and replace""? :)
TIA
-- sauke
","I subclassed namedtuple and overrode the __new__ method:
from collections import namedtuple

class Node(namedtuple('Node', ['value', 'left', 'right'])):
    __slots__ = ()
    def __new__(cls, value, left=None, right=None):
        return super(Node, cls).__new__(cls, value, left, right)

This preserves an intuitive type hierarchy, which the creation of a factory function disguised as a class does not.
"
"[INST] I have the following code to do this, but how can I do it better? Right now I think it's better than nested loops, but it starts to get Perl-one-linerish when you have a generator in a list comprehension. 
day_count = (end_date - start_date).days + 1
for single_date in [d for d in (start_date + timedelta(n) for n in range(day_count)) if d <= end_date]:
    print strftime(""%Y-%m-%d"", single_date.timetuple())

Notes

I'm not actually using this to print. That's just for demo purposes. 
The start_date and end_date variables are datetime.date objects because I don't need the timestamps. (They're going to be used to generate a report).

Sample Output
For a start date of 2009-05-30 and an end date of 2009-06-09:
2009-05-30
2009-05-31
2009-06-01
2009-06-02
2009-06-03
2009-06-04
2009-06-05
2009-06-06
2009-06-07
2009-06-08
2009-06-09

 [/INST] You can also do:
for i in [d + start_date, 24]:

  for j in range(0, 24):
      print j % d

  (d-start_date-d, d-start_date, time_start_date)

  [/INST] You can also do:
for i in range(0, 24, time_start_date, start_date):
    time_start = time_start_date + 1
    time_start_date = time_start_date + 1
    for j in (0, ","I have the following code to do this, but how can I do it better? Right now I think it's better than nested loops, but it starts to get Perl-one-linerish when you have a generator in a list comprehension. 
day_count = (end_date - start_date).days + 1
for single_date in [d for d in (start_date + timedelta(n) for n in range(day_count)) if d <= end_date]:
    print strftime(""%Y-%m-%d"", single_date.timetuple())

Notes

I'm not actually using this to print. That's just for demo purposes. 
The start_date and end_date variables are datetime.date objects because I don't need the timestamps. (They're going to be used to generate a report).

Sample Output
For a start date of 2009-05-30 and an end date of 2009-06-09:
2009-05-30
2009-05-31
2009-06-01
2009-06-02
2009-06-03
2009-06-04
2009-06-05
2009-06-06
2009-06-07
2009-06-08
2009-06-09

","Why not try:
import datetime as dt

start_date = dt.datetime(2012, 12,1)
end_date = dt.datetime(2012, 12,5)

total_days = (end_date - start_date).days + 1 #inclusive 5 days

for day_number in range(total_days):
    current_date = (start_date + dt.timedelta(days = day_number)).date()
    print current_date

"
"[INST] I am writing a program that must accept input from the user.
#note: Python 2.7 users should use `raw_input`, the equivalent of 3.X's `input`
age = int(input(""Please enter your age: ""))
if age >= 18: 
    print(""You are able to vote in the United States!"")
else:
    print(""You are not able to vote in the United States."")

This works as expected if the user enters sensible data. 
C:\Python\Projects> canyouvote.py
Please enter your age: 23
You are able to vote in the United States!

But if they make a mistake, then it crashes:
C:\Python\Projects> canyouvote.py
Please enter your age: dickety six
Traceback (most recent call last):
  File ""canyouvote.py"", line 1, in <module>
    age = int(input(""Please enter your age: ""))
ValueError: invalid literal for int() with base 10: 'dickety six'

Instead of crashing, I would like it to try getting the input again. Like this:
C:\Python\Projects> canyouvote.py
Please enter your age: dickety six
Sorry, I didn't understand that.
Please enter your age: 26
You are able to vote in the United States!

How can I accomplish this? What if I also wanted to reject values like -1, which is a valid int, but nonsensical in this context?
 [/INST] You can simply call the function as follows:
age = input(""Please enter your age: "")
if age >= 18: 
    print(""You are able to vote in the United States!"")

  (I just wanted to know if there's a way to make the user input value in the age-wise format that I'm expecting to receive. )

 [/INST] You can also do this:
age = int(input(""Please enter your age: ""))
if age <= 18: 
    print(""You are able to vote in the United States!"")

  (I don","I am writing a program that must accept input from the user.
#note: Python 2.7 users should use `raw_input`, the equivalent of 3.X's `input`
age = int(input(""Please enter your age: ""))
if age >= 18: 
    print(""You are able to vote in the United States!"")
else:
    print(""You are not able to vote in the United States."")

This works as expected if the user enters sensible data. 
C:\Python\Projects> canyouvote.py
Please enter your age: 23
You are able to vote in the United States!

But if they make a mistake, then it crashes:
C:\Python\Projects> canyouvote.py
Please enter your age: dickety six
Traceback (most recent call last):
  File ""canyouvote.py"", line 1, in <module>
    age = int(input(""Please enter your age: ""))
ValueError: invalid literal for int() with base 10: 'dickety six'

Instead of crashing, I would like it to try getting the input again. Like this:
C:\Python\Projects> canyouvote.py
Please enter your age: dickety six
Sorry, I didn't understand that.
Please enter your age: 26
You are able to vote in the United States!

How can I accomplish this? What if I also wanted to reject values like -1, which is a valid int, but nonsensical in this context?
","The simplest way to accomplish this would be to put the input method in a while loop. Use continue when you get bad input, and break out of the loop when you're satisfied.
When Your Input Might Raise an Exception
Use try and catch to detect when the user enters data that can't be parsed.
while True:
    try:
        # Note: Python 2.x users should use raw_input, the equivalent of 3.x's input
        age = int(input(""Please enter your age: ""))
    except ValueError:
        print(""Sorry, I didn't understand that."")
        #better try again... Return to the start of the loop
        continue
    else:
        #age was successfully parsed!
        #we're ready to exit the loop.
        break
if age >= 18: 
    print(""You are able to vote in the United States!"")
else:
    print(""You are not able to vote in the United States."")

Implementing Your Own Validation Rules
If you want to reject values that Python can successfully parse, you can add your own validation logic.
while True:
    data = input(""Please enter a loud message (must be all caps): "")
    if not data.isupper():
        print(""Sorry, your response was not loud enough."")
        continue
    else:
        #we're happy with the value given.
        #we're ready to exit the loop.
        break

while True:
    data = input(""Pick an answer from A to D:"")
    if data.lower() not in ('a', 'b', 'c', 'd'):
        print(""Not an appropriate choice."")
    else:
        break

Combining Exception Handling and Custom Validation
Both of the above techniques can be combined into one loop.
while True:
    try:
        age = int(input(""Please enter your age: ""))
    except ValueError:
        print(""Sorry, I didn't understand that."")
        continue

    if age < 0:
        print(""Sorry, your response must not be negative."")
        continue
    else:
        #age was successfully parsed, and we're happy with its value.
        #we're ready to exit the loop.
        break
if age >= 18: 
    print(""You are able to vote in the United States!"")
else:
    print(""You are not able to vote in the United States."")

Encapsulating it All in a Function
If you need to ask your user for a lot of different values, it might be useful to put this code in a function, so you don't have to retype it every time.
def get_non_negative_int(prompt):
    while True:
        try:
            value = int(input(prompt))
        except ValueError:
            print(""Sorry, I didn't understand that."")
            continue

        if value < 0:
            print(""Sorry, your response must not be negative."")
            continue
        else:
            break
    return value

age = get_non_negative_int(""Please enter your age: "")
kids = get_non_negative_int(""Please enter the number of children you have: "")
salary = get_non_negative_int(""Please enter your yearly earnings, in dollars: "")

Putting it all together
You can extend this idea to make a very generic input function:
def sanitised_input(prompt, type_=None, min_=None, max_=None, range_=None): 
    if min_ is not None and max_ is not None and max_ < min_: 
        raise ValueError(""min_ must be less than or equal to max_."") 
    while True: 
        ui = input(prompt) 
        if type_ is not None: 
            try: 
                ui = type_(ui) 
            except ValueError: 
                print(""Input type must be {0}."".format(type_.__name__)) 
                continue
        if max_ is not None and ui > max_: 
            print(""Input must be less than or equal to {0}."".format(max_)) 
        elif min_ is not None and ui < min_: 
            print(""Input must be greater than or equal to {0}."".format(min_)) 
        elif range_ is not None and ui not in range_: 
            if isinstance(range_, range): 
                template = ""Input must be between {0.start} and {0.stop}.""
                print(template.format(range_)) 
            else: 
                template = ""Input must be {0}.""
                if len(range_) == 1: 
                    print(template.format(*range_)) 
                else: 
                    print(template.format("" or "".join(("", "".join(map(str, 
                                                                     range_[:-1])), 
                                                       str(range_[-1]))))) 
        else: 
            return ui 

With usage such as:
age = sanitised_input(""Enter your age: "", int, 1, 101)
answer = sanitised_input(""Enter your answer"", str.lower, range_=('a', 'b', 'c', 'd'))

Common Pitfalls, and Why you Should Avoid Them
The Redundant Use of Redundant input Statements
This method works but is generally considered poor style:
data = input(""Please enter a loud message (must be all caps): "")
while not data.isupper():
    print(""Sorry, your response was not loud enough."")
    data = input(""Please enter a loud message (must be all caps): "")

It might look attractive initially because it's shorter than the while True method, but it violates the Don't Repeat Yourself principle of software development. This increases the likelihood of bugs in your system. What if you want to backport to 2.7 by changing input to raw_input, but accidentally change only the first input above? It's a SyntaxError just waiting to happen.
Recursion Will Blow Your Stack
If you've just learned about recursion, you might be tempted to use it in get_non_negative_int so you can dispose of the while loop.
def get_non_negative_int(prompt):
    try:
        value = int(input(prompt))
    except ValueError:
        print(""Sorry, I didn't understand that."")
        return get_non_negative_int(prompt)

    if value < 0:
        print(""Sorry, your response must not be negative."")
        return get_non_negative_int(prompt)
    else:
        return value

This appears to work fine most of the time, but if the user enters invalid data enough times, the script will terminate with a RuntimeError: maximum recursion depth exceeded. You may think ""no fool would make 1000 mistakes in a row"", but you're underestimating the ingenuity of fools!
"
"[INST] I'd like to grab daily sunrise/sunset times from a web site. Is it possible to scrape web content with Python? what are the modules used? Is there any tutorial available?
 [/INST] I'd actually use Scrapy, because it's awesome in many ways. But I'd say that it's worth mentioning that it's awesome for automating web scraping:
http://www.grantland.org/grantland/
http://www.skymade.com/grantland/

And I'm not sure if Skymate has its features out of this, but I'd certainly love a version that has this feature built in.
 [/INST] I've used skymate (http://www.skymate.me), and it has a module called sunrise (which was called ""getting just the urls""): http://skymate.skymade.com/urls/
it out of getht.skymate:
http://www.skymate.me/files/skymate/
http://www.skymate.me/files/sunrise/

and I want to know if there is a module like sunrise which does what I've seen here, because it would be awesome if it had zero lines/words of the sunrise module. (And I don't know why you'd want sunrise on the first, but I guess it's just me being lazy and not realizing that I've got a lot of sunrise lines/words in my skymate.skymate/
http://www.skymate.me/files/sunrise/
url_start = settings.get_default_setting()

and you can define your own sunrise/downloading functions:
def sunrise(self):
    print(skymate.newline())

and in your code:
import skymate
print(skymate.newline())

You can also give a name to the sunrise, and then define your own (sunrise, sunset) function:
def sunrise(self, url):
    print(url)

And then:
print(skymate.newline())

And then print(sk","I'd like to grab daily sunrise/sunset times from a web site. Is it possible to scrape web content with Python? what are the modules used? Is there any tutorial available?
","I'd really recommend Scrapy, for reasons being elaborated in this question - ""Is it worth learning Scrapy?"".
Quote from the answer:


Scrapy crawling is fastest than mechanize because uses asynchronous operations (on top of Twisted).
Scrapy has better and fastest support for parsing (x)html on top of libxml2.
Scrapy is a mature framework with full unicode, handles redirections, gzipped responses, odd encodings, integrated http cache, etc.
Once you are into Scrapy, you can write a spider in less than 5 minutes that download images, creates thumbnails and export the extracted data directly to csv or json.


"
"[INST] In Python, how do I get a function name as a string without calling the function?
def my_function():
    pass

print get_function_name_as_string(my_function) # my_function is not in quotes

should output ""my_function"".
Is this available in python? If not, any idea how to write get_function_name_as_string in Python?
 [/INST] You can also do this:
my_function()

  output: ""my_function""

  get_function_name_as_string
my_function().function_name # get_function_name_as_string

  get_function_name_as_string
my_function().function_name # get_function_name_as_string

  get_function_name_as_string
my_function().function_name # get_function_name_as_string

  get_function_name_as_string
my_function().function_name # get_function_name_as_string

  get_function_name_as_string
get_function_name_as_string # get_function_name_as_string
get_function_name_as_list
get_function_name_as_list # get_name_as_list

  get_function_name_as_list(""my_function"", ""my_list"") # get_name_name(""my_function"")

get_function_name_as_list(""my_function"", ""my_list"") # get_function_name(""my_function"")
get_function_name_as_list(""my_function"", ""my_list"") # get_function_name(""my_function"")
get_function_name_as_list(""my_function"", ""my_list"") # get_function_name_as_list
get_function_name_as_list(""my_function"") # get_name_list(""my_list"")

as_name = ""my_function""

get_function_name_as_list(""my_function"") # get_function_name(""my_function"")
get_function_name(""my_function"") # get","In Python, how do I get a function name as a string without calling the function?
def my_function():
    pass

print get_function_name_as_string(my_function) # my_function is not in quotes

should output ""my_function"".
Is this available in python? If not, any idea how to write get_function_name_as_string in Python?
","This function will return the caller's function name.
def func_name():
    import traceback
    return traceback.extract_stack(None, 2)[0][2]

It is like Albert Vonpupp's answer with a friendly wrapper.
"
"[INST] I have used hashlib (which replaces md5 in Python 2.6/3.0) and it worked fine if I opened a file and put its content in hashlib.md5() function.
The problem is with very big files that their sizes could exceed RAM size.
How to get the MD5 hash of a file without loading the whole file to memory?
 [/INST] You can do this:
import hashlib
f=open('hash', 'r')
f.write(hashlib.hash('md5', filename))

  def hash(f):
    return hashlib.sha25(f)

  f.close()

  # hash2.sha25 is a very special case
  # http://stackoverflow.com/q/1482867/2443667000

  # 2000 hash2.sha25 is the best option, as it is the only option to make hash2 from a raw byte array (as all other methods I tried, except for hashing with md5, which was actually the worst option).
  # 2000 hash2 is the only way to hash hash(f) style data.
  # 2000 hash(f) 
  # 2000 hash(f)
  # 2000 hash(f)

  # 2000 hash(f) 
  # 2000 hash(f)

  # 2000 hash(f)
  # 2000 hash(f)

f = hashlib.sha25(f)
hash(f)

  # 2000 hash2 hash
  # 2000 hash(f)

  # 2000 hash(f)
  # 2000 hash(f)

  # 2000 hash(f)

  # 2200 hash(f)

  # 2200 hash(f)

  # 2200 hash(f)
  # 2200 hash(f)
  # 220","I have used hashlib (which replaces md5 in Python 2.6/3.0) and it worked fine if I opened a file and put its content in hashlib.md5() function.
The problem is with very big files that their sizes could exceed RAM size.
How to get the MD5 hash of a file without loading the whole file to memory?
","Here's my version of @Piotr Czapla's method:
def md5sum(filename):
    md5 = hashlib.md5()
    with open(filename, 'rb') as f:
        for chunk in iter(lambda: f.read(128 * md5.block_size), b''):
            md5.update(chunk)
    return md5.hexdigest()

"
"[INST] I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.
I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.
This should work:
l = range(1, 1000)
print chunks(l, 10) -> [ [ 1..10 ], [ 11..20 ], .., [ 991..999 ] ]

I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.
Related question: What is the most âpythonicâ way to iterate over a list in chunks?
 [/INST] I think this is a better solution, with the list being split into two lists at least twice, as in the example below:
l = [ 1, 2, 3, 4, 5 ]
for i in range(1, 1000):
    l[i:0] += l[i:0]

  l = [ [ 0, 1, 2, 3, 4, 5, 6, 7, 8]
  for i in l:
    l[i] += l[i:0]
  # l is a list
  for i in range(1, 1000):
    l[i[i:0:0] += l[i:0]

# Example
[1, 2, 3, 4, 5, 6, 7, 8]
[0, 1, 2, 3, 4, 5, 6, 7, 8]

# Empty list to initialize the lists with zeroes
# if len(list) < 2, add to back
# if len(list) > 2, add to front

 [/INST] [/INST","I have a list of arbitrary length, and I need to split it up into equal size chunks and operate on it. There are some obvious ways to do this, like keeping a counter and two lists, and when the second list fills up, add it to the first list and empty the second list for the next round of data, but this is potentially extremely expensive.
I was wondering if anyone had a good solution to this for lists of any length, e.g. using generators.
This should work:
l = range(1, 1000)
print chunks(l, 10) -> [ [ 1..10 ], [ 11..20 ], .., [ 991..999 ] ]

I was looking for something useful in itertools but I couldn't find anything obviously useful. Might've missed it, though.
Related question: What is the most âpythonicâ way to iterate over a list in chunks?
","I saw the most awesome Python-ish answer in a duplicate of this question:
l = range(1,15)
i = iter(l)
print zip(i,i,i)

You can create n-tuple for any n.
"
"[INST] Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?

The following uses each method and has the same outcome, so what is the difference?
#!/usr/bin/python
sub1 = ""python string!""
sub2 = ""an arg""

a = ""i am a %s"" % sub1
b = ""i am a {0}"".format(sub1)

c = ""with %(kwarg)s!"" % {'kwarg':sub2}
d = ""with {kwarg}!"".format(kwarg=sub2)

print a    # ""i am a python string!""
print b    # ""i am a python string!""
print c    # ""with an arg!""
print d    # ""with an arg!""

Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?
log.debug(""some debug info: %s"" % some_info)


 [/INST] The first example is the same as the second example and the second example is different. The reason is that the % operator in the first example is passed to the function call, and the % operator in the second example is used to specify the

given value.
  if %d == 'i am a %d' some time ago' some days ago i.e. my question is with %d argument in some code.
  if kwarg in some_argument: some time ago""

  if kwarg in some_argument: some_argument == some_argument

  if kwarg in some_argument: some_argument == some_argument""

  if kwarg in some_argument: some_argument == some_argument some_argument

  if kwarg in some_argument some_argument some_value: some_argument some_value

  if kwarg in some_argument some_value: some_value

  if %kwarg some_argument some_value: some_value some_value

  if %d in some_argument","Python 2.6 introduced the str.format() method with a slightly different syntax from the existing % operator. Which is better and for what situations?

The following uses each method and has the same outcome, so what is the difference?
#!/usr/bin/python
sub1 = ""python string!""
sub2 = ""an arg""

a = ""i am a %s"" % sub1
b = ""i am a {0}"".format(sub1)

c = ""with %(kwarg)s!"" % {'kwarg':sub2}
d = ""with {kwarg}!"".format(kwarg=sub2)

print a    # ""i am a python string!""
print b    # ""i am a python string!""
print c    # ""with an arg!""
print d    # ""with an arg!""

Furthermore when does string formatting occur in Python? For example, if my logging level is set to HIGH will I still take a hit for performing the following % operation? And if so, is there a way to avoid this?
log.debug(""some debug info: %s"" % some_info)


","But please be careful, just now I've discovered one issue when trying to replace all % with .format in existing code: '{}'.format(unicode_string) will try to encode unicode_string and will probably fail.
Just look at this Python interactive session log:
Python 2.7.2 (default, Aug 27 2012, 19:52:55) 
[GCC 4.1.2 20080704 (Red Hat 4.1.2-48)] on linux2
; s='Ð¹'
; u=u'Ð¹'
; s
'\xd0\xb9'
; u
u'\u0439'

s is just a string (called 'byte array' in Python3) and u is a Unicode string (called 'string' in Python3):
; '%s' % s
'\xd0\xb9'
; '%s' % u
u'\u0439'

When you give a Unicode object as a parameter to % operator it will produce a Unicode string even if the original string wasn't Unicode:
; '{}'.format(s)
'\xd0\xb9'
; '{}'.format(u)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
UnicodeEncodeError: 'latin-1' codec can't encode character u'\u0439' in position 0: ordinal not in range(256)

but the .format function will raise ""UnicodeEncodeError"":
; u'{}'.format(s)
u'\xd0\xb9'
; u'{}'.format(u)
u'\u0439'

and it will work with a Unicode argument fine only if the original string was Unicode.
; '{}'.format(u'i')
'i'

or if argument string can be converted to a string (so called 'byte array')
"
"[INST] I want to be able to get the whole POST body of the request as a string or file handle that I can read but I'm unable to find a way (I'm new to Flask and Python for web at all). This is what I got:
from flask import Flask

app = Flask(__name__)
@app.route('/', methods=['GET', 'POST'])
def parse_request():
    # obtain the whole post body here, in case the request is post...

AS THIS QUESTION IS GETTING MANY VIEWS:
The answer to the question linked below is telling a way that works only if the content-type is not recognised, this one instead is asking how to get the whole raw post body regardless of the headers:
Get raw POST body in Python Flask regardless of Content-Type header
 [/INST] @flask.views.utils.request_data is a decorator that flask automatically applies to all your views. You can use it like this:
@app.route(""/path/data"")
def my_func():
    # do something with the GET request
    print ""got the data""

@app.route(""/path/data"")
def my_func():
    # do something with the GET request
    return ""got the data""

@app.route(""/path/data"")
def my_func():
    # do something with the GET request

@app.route(""/path/data"")
def my_func():
    # do something with the GET request

@app.route(""/path/data"")
def my_func():
    # do something with the GET request
    pass

@app.data
def my_func():
    # do something with the GET request
    # do something with the GET request

@app = Flask(__name__)
def my_func():
    # do something with the GET request
    print ""got the data""

@app.data
def my_func():
    # do something with the GET request

@app.route(""/path/data"")
def my_func():
    #...

@app.data
def my_func():
    # DO SOMETHING

@app","I want to be able to get the whole POST body of the request as a string or file handle that I can read but I'm unable to find a way (I'm new to Flask and Python for web at all). This is what I got:
from flask import Flask

app = Flask(__name__)
@app.route('/', methods=['GET', 'POST'])
def parse_request():
    # obtain the whole post body here, in case the request is post...

AS THIS QUESTION IS GETTING MANY VIEWS:
The answer to the question linked below is telling a way that works only if the content-type is not recognised, this one instead is asking how to get the whole raw post body regardless of the headers:
Get raw POST body in Python Flask regardless of Content-Type header
","The docs describe the attributes available on the request.  In most common cases request.data will be empty because it's used as a fallback:

request.data Contains the incoming request data as string in case it came with a mimetype Flask does not handle.


request.args: the key/value pairs in the URL query string
request.form: the key/value pairs in the body, as sent by a HTML POST form
request.files: the files in the body, which Flask keeps separate from form
request.values: combined args and form, preferring args if keys overlap

"
"[INST] I am trying to run a Django management command from cron. I am using virtualenv to keep my project sandboxed.
I have seen examples here and elsewhere that show running management commands from within virtualenv's like:
0 3 * * * source /home/user/project/env/bin/activate && /home/user/project/manage.py command arg

However, even though syslog shows an entry when the task should have started, this task never actually runs (the log file for the script is empty). If I run the line manually from the shell, it works as expected. 
The only way I can currently get the command to run via cron, is to break the commands up and put them in a dumb bash wrapper script:
#!/bin/sh
source /home/user/project/env/bin/activate
cd /home/user/project/
./manage.py command arg

Please enlighten me what the difference is. What am I missing?
Thanks
EDIT:
ars came up with a working combination of commands:
0 3 * * * cd /home/user/project && /home/user/project/env/bin/python /home/user/project/manage.py command arg

At least in my case, invoking the activate script for the virtualenv did nothing. This works, so on with the show.
 [/INST] The /home/user/project/activate command does not run, it just sets the environment variables and defines a python alias (see http://www.python.org/3/doc/ars/bin/activate) that you can run from the shell. (I know, I know, I know, I just figured out how to do this at home/user/project/bin/activate))
 [/INST) activate is a concept from the cron daemon that automatically activates a virtualenv (a subprocess in Python) whenever it needs to run. This is true for both Python and the cron daemon (and the virtualenv is a standard part of cron/sense) for most cases)

Here is how it works:

0 3 * /home/user/project/venenv/activate.py:3:42:33:33","I am trying to run a Django management command from cron. I am using virtualenv to keep my project sandboxed.
I have seen examples here and elsewhere that show running management commands from within virtualenv's like:
0 3 * * * source /home/user/project/env/bin/activate && /home/user/project/manage.py command arg

However, even though syslog shows an entry when the task should have started, this task never actually runs (the log file for the script is empty). If I run the line manually from the shell, it works as expected. 
The only way I can currently get the command to run via cron, is to break the commands up and put them in a dumb bash wrapper script:
#!/bin/sh
source /home/user/project/env/bin/activate
cd /home/user/project/
./manage.py command arg

Please enlighten me what the difference is. What am I missing?
Thanks
EDIT:
ars came up with a working combination of commands:
0 3 * * * cd /home/user/project && /home/user/project/env/bin/python /home/user/project/manage.py command arg

At least in my case, invoking the activate script for the virtualenv did nothing. This works, so on with the show.
","Running source from a cronfile won't work as cron uses /bin/sh as its default shell, which doesn't support source.  You need to set the SHELL environment variable to be /bin/bash:
SHELL=/bin/bash
*/10 * * * * root source /path/to/virtualenv/bin/activate && /path/to/build/manage.py some_command > /dev/null

It's tricky to spot why this fails as /var/log/syslog doesn't log the error details.  Best to alias yourself to root so you get emailed with any cron errors.  Simply add yourself to /etc/aliases and run sendmail -bi.
More info here:
http://codeinthehole.com/archives/43-Running-django-cronjobs-within-a-virtualenv.html
"
"[INST] Is there a function to extract the extension from a filename?
 [/INST]..............]

 ....................................

 ........................................................

 ...............................................

 ..................................

................

....................................

 ...................................

 ................................

 ...................................

.............................................

................................................................","Is there a function to extract the extension from a filename?
","I'm surprised no one has mentioned pathlib yet, pathlib IS awesome!
NOTE: You require to have Python 3.4 at least though!
import pathlib

print(pathlib.Path('yourPathGoesHere').suffix)

And if you want to get all the suffixes (for instance if you have a .tar.gz), .suffixes will return a list of them! Neat!
"
"[INST] Whenever I use sys.path.append, the new directory will be added. However, once I close python, the list will revert to the previous (default?) values. How do I permanently add a directory to PYTHONPATH?
 [/INST] On Mac OS X you can create a symlink for a directory with the name of the directory you want and the directory itself. This will make the path of the directory you want when you are trying to call the Python file.
  /Applications/MacOS XD.app/Contents/Developer/Python/MacOSX.app/Contents/Developer/Library/MacOSX.macos
On Windows you can create a shortcut for a directory in XYZ (I'm not sure how to do it in XYZ) just by adding.py extensions to your path.
Then you can call the shortlink from XYZ.
  example:
~/Applications/Xcode.app/Contents/MacOSX.developer/Platforms/Python/Python.app/Contents/Develop/Python.platform
~/Applications/Xcode.app/Contents/Developer/Library/MacOSX.platform/Developer/Library/Developer/Python.d/Python/Developer/Library/Python.d/Python.d/Contents/
 ~/Developer/Library/Python/lib/Python.d/Contents/
 ~/Developer/Library/Python/lib/
 ~/Developer/Library/MacOSX.d/Contents/Developer/Library/Developer/Python/Sites/MacOSX.platform/
 ~/Developer/Library/Developer/MacOSX.platform/Developer/Library/Developer/Xcode/Lib/Python.d/
 ~/Developer/Library/Developer/Library/Developer/Library/Developer/Library/Developer/Platforms/Developer/Library/Developer/Library/Developer/Library/Developer/Library/Develop/MacOSX.platform
 ~/Developer/Library/Develop/Mac","Whenever I use sys.path.append, the new directory will be added. However, once I close python, the list will revert to the previous (default?) values. How do I permanently add a directory to PYTHONPATH?
","This works on Windows

On Windows, with Python 2.7 go to the Python setup folder.
Open Lib/site-packages.
Add an example.pth empty file to this folder.
Add the required path to the file, one per each line.

Then you'll be able to see all modules within those paths from your scripts.
"
"[INST] How can I list all files of a directory in python and add them to a list?
 [/INST] from http://www.python.org/web/content/a/b/c]
>>> print(a)
b/c
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
>>> print(b/c, 1)
1
>>> print(b,c, 1)
>>> print(b,c, 1)
>>> print(b,c, 1)
>>> print(b,c, 1)
1
>>> print(b,c, 1)
>>> print(b,c, 1)
1
>>> print(b,c, 1)
>>> print(b,c, 1)
>>> print(b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
>>> (b,c, 1)
","How can I list all files of a directory in python and add them to a list?
","A one-line solution to get only list of files (no subdirectories):
filenames = next(os.walk(path))[2]

or absolute pathnames:
paths = [os.path.join(path,fn) for fn in next(os.walk(path))[2]]

"
"[INST] There is no built in reverse function in Python's str object. What is the best way of implementing this?
If supplying a very concise answer, please elaborate on it's efficiency. Is the str converted to a different object, etc. 
 [/INST] If you're only dealing with str objects, you can get away with the str.split() method, as in:
>>> ""abcd - -"".split()
['abcd', 'cd','- ','- ']

  abcd = ['abcd', 'cd','- ']

str.split(1) # 'abcd'
>>> ['abcd', 'cd','- ']

or even:
>>> 'abcd' # 'abcd'
>>> ""abcde""
>>> ""cd""
>>> 'abcd'

  # 'abcde' is the first argument, 'cd' is the second argument
>>> # 'abcd' 
>>> 'abcd'

  # 'abcde' is the first argument, 'cd' is the second argument

or even:
>>> ""abcd""

  # 'abcde' is the first answer
>>> ""abcd""

... etc.
>>> ""abcd""

  # 'abcd'
  # 'cd'

str.split("""", 'cd') # 'abcd'

The 'abcd' in the first example is actually a reference to the str.split('abcd', 'cd') 'cd' in a code example

  # 'abcd' in the second example
>>> ""abcd""

  # 'cd' in the third example

 [/INST] str.split('', 'cd') returns a list of strings, where the first one is the first element of the list, the second one is the second element of the list, etc.
>>> 'abcd'
['abcd', 'cd']

  # 'abcd'
['abcd', 'cd', 'cd']

  # 'cd', 'cd']
['abcd', 'cd', 'cd']

Str.split('', 'cd', 'cd']
['abcd', 'cd', 'cd']

Str.","There is no built in reverse function in Python's str object. What is the best way of implementing this?
If supplying a very concise answer, please elaborate on it's efficiency. Is the str converted to a different object, etc. 
","Quick Answer (TL;DR)
Example
### example01 -------------------
mystring  =   'coup_ate_grouping'
backwards =   mystring[::-1]
print backwards

### ... or even ...
mystring  =   'coup_ate_grouping'[::-1]
print mystring

### result01 -------------------
'''
gnipuorg_eta_puoc
'''

Detailed Answer
Background
This answer is provided to address the following concern from a user odigity:

Wow. I was horrified at first by the solution Paolo proposed, but that 
  took a back seat to the horror I felt upon reading the first
  comment: ""That's very pythonic. Good job!"" I'm so disturbed that such
  a bright community thinks using such cryptic methods for something so
  basic is a good idea. Why isn't it just s.reverse()?

Problem

Context

Python 2.x
Python 3.x

Scenario:

Developer wants to transform a string
Transformation is to reverse order of all the characters


Solution

example01 produces the desired result, using extended slice notation.        

Pitfalls

Developer might expect something like string.reverse()
The native idiomatic (aka ""pythonic"") solution may not be readable to newer developers
Developer may be tempted to implement his or her own version of string.reverse() to avoid slice notation.
The output of slice notation may be counter-intuitive in some cases:


see e.g., example02


print 'coup_ate_grouping'[-4:]    ## => 'ping'
compared to
print 'coup_ate_grouping'[-4:-1]  ## => 'pin'
compared to
print 'coup_ate_grouping'[-1]  ## => 'g'

the different outcomes of indexing on [-1] may throw some developers off


Rationale
Python has a special circumstance to be aware of: a string is an iterable type.
One rationale for excluding a string.reverse() method is to give python developers incentive to leverage the power of this special circumstance.
In simplified terms, this simply means each individual character in a string can be easily operated on as a part of a sequential array of elements, just like arrays in other programming languages.
To understand how this works, reviewing example02 can provide a good overview.
Example02
### example02 -------------------
## start (with positive integers)
print 'coup_ate_grouping'[0]  ## => 'c'
print 'coup_ate_grouping'[1]  ## => 'o' 
print 'coup_ate_grouping'[2]  ## => 'u' 

## start (with negative integers)
print 'coup_ate_grouping'[-1]  ## => 'g'
print 'coup_ate_grouping'[-2]  ## => 'n' 
print 'coup_ate_grouping'[-3]  ## => 'i' 

## start:end 
print 'coup_ate_grouping'[0:4]    ## => 'coup'    
print 'coup_ate_grouping'[4:8]    ## => '_ate'    
print 'coup_ate_grouping'[8:12]   ## => '_gro'    

## start:end 
print 'coup_ate_grouping'[-4:]    ## => 'ping' (counter-intuitive)
print 'coup_ate_grouping'[-4:-1]  ## => 'pin'
print 'coup_ate_grouping'[-4:-2]  ## => 'pi'
print 'coup_ate_grouping'[-4:-3]  ## => 'p'
print 'coup_ate_grouping'[-4:-4]  ## => ''
print 'coup_ate_grouping'[0:-1]   ## => 'coup_ate_groupin'
print 'coup_ate_grouping'[0:]     ## => 'coup_ate_grouping' (counter-intuitive)

## start:end:step (or stop:end:stride)
print 'coup_ate_grouping'[-1::1]  ## => 'g'   
print 'coup_ate_grouping'[-1::-1] ## => 'gnipuorg_eta_puoc'

## combinations
print 'coup_ate_grouping'[-1::-1][-4:] ## => 'puoc'

Conclusion
The cognitive load associated with understanding how slice notation works in python may indeed be too much for some adopters and developers who do not wish to invest much time in learning the language.
Nevertheless, once the basic principles are understood, the power of this approach over fixed string manipulation methods can be quite favorable.
For those who think otherwise, there are alternate approaches, such as lambda functions, iterators, or simple one-off function declarations.
If desired, a developer can implement her own string.reverse() method, however it is good to understand the rationale behind this ""quirk"" of python.
See also

alternate simple approach
alternate simple approach
alternate explanation of slice notation 

"
"[INST] Not obvious from the flask documention on how to get the query string. I am new, looked at the docs, could not find!   
So
@app.route('/')
@app.route('/data')
def data():
    query_string=??????
    return render_template(""data.html"")

 [/INST] @app.route('/data')
def data():
    query_string=??????
    return render_template(""data."")

@app.route('/data')
def data():
    query_string=??????
    return render_template(""data.html"")

  @app.route('/data')
def data():
    query_string=??????
    return render_template(""data.html"")

  @app.route('/data')
  def data():
    query_string=??????
    return render_template(""data.html"")

  @app.route('/data')
  def data():
    query_string=??????
    return render_template(""data.html"")

  @app.route('/data')
  def data():
    query_string=??????
    return render_template(""data"")

  @app.route('/data')
  def data():
    query_string=????????
    return render_template(""data.html"")

  @app.data/data.html
  def data():
    query_string=????????
    return render_template(""data.html"")

I also want to add to this file the query string ""data"", which should be data-string.
  [/INST] @app_path(/)
    (data_string,/template/data/)
    (data_string,/template/data/)
    (data_string,/template/data/)

  @app_path('data')
  def data():
    return render_template(""data"")
  @app.data('data')
  def data():
    return render_template(""data"")

  @app.route(""/data"")
  def data():
    return render_template(""data"")

  @app","Not obvious from the flask documention on how to get the query string. I am new, looked at the docs, could not find!   
So
@app.route('/')
@app.route('/data')
def data():
    query_string=??????
    return render_template(""data.html"")

","Werkzeug/Flask as already parsed everything for you. No need to do the same work again with urlparse:
from flask import request

@app.route('/')
@app.route('/data')
def data():
    query_string = request.query_string  ## There is it
    return render_template(""data.html"")

The full documentation for the request and response objects is in Werkzeug: http://werkzeug.pocoo.org/docs/wrappers/
"
"[INST] I am learning the ropes in Python. When I try to print an object of class Foobar using the print() function, I get an output like this:
<__main__.Foobar instance at 0x7ff2a18c>

Is there a way I can set the printing behaviour (or the string representation) of a class and its objects? For instance, when I call print() on a class object, I would like to print its data members in a certain format. How to achieve this in Python?
If you are familiar with C++ classes, the above can be achieved for the standard ostream by adding a friend ostream& operator << (ostream&, const Foobar&) method for the class.
 [/INST]dorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorfdorf","I am learning the ropes in Python. When I try to print an object of class Foobar using the print() function, I get an output like this:
<__main__.Foobar instance at 0x7ff2a18c>

Is there a way I can set the printing behaviour (or the string representation) of a class and its objects? For instance, when I call print() on a class object, I would like to print its data members in a certain format. How to achieve this in Python?
If you are familiar with C++ classes, the above can be achieved for the standard ostream by adding a friend ostream& operator << (ostream&, const Foobar&) method for the class.
","You need to use __repr__. This is a standard function like __init__.
For example:
class Foobar():
    """"""This will create Foobar type object.""""""

    def __init__(self):
        print ""Foobar object is created.""

    def __repr__(self):
        return ""Type what do you want to see here.""

a = Foobar()

print a

"
"[INST] filter, map, and reduce work perfectly in Python 2. Here is an example:
>>> def f(x):
        return x % 2 != 0 and x % 3 != 0
>>> filter(f, range(2, 25))
[5, 7, 11, 13, 17, 19, 23]

>>> def cube(x):
        return x*x*x
>>> map(cube, range(1, 11))
[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]

>>> def add(x,y):
        return x+y
>>> reduce(add, range(1, 11))
55

But in Python 3, I receive the following outputs:
>>> filter(f, range(2, 25))
<filter object at 0x0000000002C14908>
>>> map(cube, range(1, 11))
<map object at 0x0000000002C82B70>
>>> reduce(add, range(1, 11))
Traceback (most recent call last):
  File ""<pyshell#8>"", line 1, in <module>
    reduce(add, range(1, 11))
NameError: name 'reduce' is not defined

I would appreciate if someone could explain to me why this is.
Screenshot of code for further clarity:

 [/INST] The first part of the code is to define the filter(1, 11) function and then apply this filter on the range of numbers given. This is done through a function definition named 'cube'. This name is important because it is the name of the function, and it is the part of the signature of the function that makes this function special.

    def cube(x):
        return x*x

    def f(N, k, cube):
        return (N*k, cube","filter, map, and reduce work perfectly in Python 2. Here is an example:
>>> def f(x):
        return x % 2 != 0 and x % 3 != 0
>>> filter(f, range(2, 25))
[5, 7, 11, 13, 17, 19, 23]

>>> def cube(x):
        return x*x*x
>>> map(cube, range(1, 11))
[1, 8, 27, 64, 125, 216, 343, 512, 729, 1000]

>>> def add(x,y):
        return x+y
>>> reduce(add, range(1, 11))
55

But in Python 3, I receive the following outputs:
>>> filter(f, range(2, 25))
<filter object at 0x0000000002C14908>
>>> map(cube, range(1, 11))
<map object at 0x0000000002C82B70>
>>> reduce(add, range(1, 11))
Traceback (most recent call last):
  File ""<pyshell#8>"", line 1, in <module>
    reduce(add, range(1, 11))
NameError: name 'reduce' is not defined

I would appreciate if someone could explain to me why this is.
Screenshot of code for further clarity:

","You can read about the changes in What's New In Python 3.0. You should read it thoroughly when you move from 2.x to 3.x since a lot has been changed.
The whole answer here are quotes from the documentation.
Views And Iterators Instead Of Lists

Some well-known APIs no longer return lists:

[...]
map() and filter() return iterators. If you really need a list, a quick fix is e.g. list(map(...)), but a better fix is often to use a list comprehension (especially when the original code uses lambda), or rewriting the code so it doesnât need a list at all. Particularly tricky is map() invoked for the side effects of the function; the correct transformation is to use a regular for loop (since creating a list would just be wasteful).
[...]


Builtins


[...]
Removed reduce(). Use functools.reduce() if you really need it; however, 99 percent of the time an explicit for loop is more readable.
[...]


"
"[INST] I am writing a project in Django and I see that 80% of the code is in the file models.py. This code is confusing and, after a certain time, I cease to understand what is really happening.
Here is what bothers me:

I find it ugly that my model level (which was supposed to be
responsible only for the work with data from a database) is also
sending email, walking on api to other services, etc. 
Also, I find it unacceptable to place business logic in the view, because
this way it becomes difficult to control. For example, in my
application there are at least three ways to create new
instances of User, but technically it should create them uniformally. 
I do not always notice when the methods and
properties of my models become non-deterministic and when they develop
side effects.

Here is a simple example. At first, the User model was like this:
class User(db.Models):

    def get_present_name(self):
        return self.name or 'Anonymous'

    def activate(self):
        self.status = 'activated'
        self.save()

Over time, it turned into this:
class User(db.Models):

    def get_present_name(self): 
        # property became non-deterministic in terms of database
        # data is taken from another service by api
        return remote_api.request_user_name(self.uid) or 'Anonymous' 

    def activate(self):
        # method now has a side effect (send message to user)
        self.status = 'activated'
        self.save()
        send_mail('Your account is activated!', 'â¦', [self.email])

What I want is to separate entities in my code:

Entities of my database, database level: What contains my application?
Entities of my application, business logic level: What can make my application?

What are the good practices to implement such an approach that can be applied in Django?
 [/INST]ublublublublublublublublublublublublublublublublublublublublublubl","I am writing a project in Django and I see that 80% of the code is in the file models.py. This code is confusing and, after a certain time, I cease to understand what is really happening.
Here is what bothers me:

I find it ugly that my model level (which was supposed to be
responsible only for the work with data from a database) is also
sending email, walking on api to other services, etc. 
Also, I find it unacceptable to place business logic in the view, because
this way it becomes difficult to control. For example, in my
application there are at least three ways to create new
instances of User, but technically it should create them uniformally. 
I do not always notice when the methods and
properties of my models become non-deterministic and when they develop
side effects.

Here is a simple example. At first, the User model was like this:
class User(db.Models):

    def get_present_name(self):
        return self.name or 'Anonymous'

    def activate(self):
        self.status = 'activated'
        self.save()

Over time, it turned into this:
class User(db.Models):

    def get_present_name(self): 
        # property became non-deterministic in terms of database
        # data is taken from another service by api
        return remote_api.request_user_name(self.uid) or 'Anonymous' 

    def activate(self):
        # method now has a side effect (send message to user)
        self.status = 'activated'
        self.save()
        send_mail('Your account is activated!', 'â¦', [self.email])

What I want is to separate entities in my code:

Entities of my database, database level: What contains my application?
Entities of my application, business logic level: What can make my application?

What are the good practices to implement such an approach that can be applied in Django?
","I usually implement a service layer in between views and models. This acts like your project's API and gives you a good helicopter view of what is going on. I inherited this practice from a colleague of mine that uses this layering technique a lot with Java projects (JSF), e.g:
models.py 
class Book:
   author = models.ForeignKey(User)
   title = models.CharField(max_length=125)

   class Meta:
       app_label = ""library""

services.py
from library.models import Book

def get_books(limit=None, **filters):
    """""" simple service function for retrieving books can be widely extended """"""
    if limit:
        return Book.objects.filter(**filters)[:limit]
    return Book.objects.filter(**filters)

views.py
from library.services import get_books

class BookListView(ListView):
    """""" simple view, e.g. implement a _build and _apply filters function """"""
    queryset = get_books()


Mind you, I usually take models, views and services to module level and
  separate even further depending on the project's size

"
"[INST] I want to delete the file filename if it exists.  Is it proper to say
if os.path.exists(filename):
    os.remove(filename)

Is there a better way? A one-line way? 
 [/INST] A simple way to do this is to use shutil.rmtree(path[, onerror]) in the same way as with os.remove. It just makes sense to use it to remove a directory/file.
  onerror(os.path.join(path[, onerror), onerror))

  onerror:
    os.path.exists(path[, onerror]) and on error raise the path[, onerror] to remove the directory/file.
  on error:
    os.path.exists(path[, onerror)) and on error:
    os.remove(path[, onerror])

  on error:
    os.remove(path[, onerror])

  on error:
    os.remove(path[, onerror])

  on on error:
    os.remove(path[, onerror])

  on on error:
    os.remove(path[, onerror])

  on error:
    os.remove(path[, onerror))

  on on error, it just raises a KeyError exception.
  on error, it raises a RAIWTOE exception.
  on on error, it raises a KeyError exception.
  on on error, it raises a KeyError exception.
  on error, it raises a KeyError exception.
  on error, it raises a RAIWTOE exception.

  on error, it raises a KeyError exception.
  on error, it raises a KeyError exception.
  on error, it raises a KeyError exception.

  on error, it raises a KeyError exception.
  on error, it raises a KeyError exception.
  on error, it raises a KeyError exception.

  on error, it raises a KeyError exception:
    os.error(os.path.join(path, onerror))

  on error, it raises a KeyError exception.
  on error, it raises a KeyError exception.","I want to delete the file filename if it exists.  Is it proper to say
if os.path.exists(filename):
    os.remove(filename)

Is there a better way? A one-line way? 
","In the spirit of Andy Jones' answer, how about an authentic ternary operation:
os.remove(fn) if os.path.exists(fn) else None

"
"[INST] What is the use of the yield keyword in Python? What does it do?
For example, I'm trying to understand this code1:
def _get_child_candidates(self, distance, min_dist, max_dist):
    if self._leftchild and distance - max_dist < self._median:
        yield self._leftchild
    if self._rightchild and distance + max_dist >= self._median:
        yield self._rightchild  

And this is the caller:
result, candidates = list(), [self]
while candidates:
    node = candidates.pop()
    distance = node._get_dist(obj)
    if distance <= max_dist and distance >= min_dist:
        result.extend(node._values)
    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))
return result

What happens when the method _get_child_candidates is called?
A list is returned? A single element is returned? Is it called again? When will subsequent calls stop?


1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.
 [/INST] The answer is simple:
result = [x for x in self._children if x.dist <= self._median else self._distance - max_dist < self._median]

  /y /= x - (self._distance - min_dist - self._distance)

  /y /= x - (self._distance - min_dist < self._distance - max_dist)

  /y /= x - self._distance >= self._median: (self._distance - self._distance >= self._distance - self._distance) /= self._distance - self._distance >= self._distance and (self._distance - self._distance >= self._distance + min_distance <= self._distance <= self._distance)

  /y /= self._distance - (self._distance + self._distance <= self._distance >= self._distance + self._distance <= self._distance]

  /y is in [","What is the use of the yield keyword in Python? What does it do?
For example, I'm trying to understand this code1:
def _get_child_candidates(self, distance, min_dist, max_dist):
    if self._leftchild and distance - max_dist < self._median:
        yield self._leftchild
    if self._rightchild and distance + max_dist >= self._median:
        yield self._rightchild  

And this is the caller:
result, candidates = list(), [self]
while candidates:
    node = candidates.pop()
    distance = node._get_dist(obj)
    if distance <= max_dist and distance >= min_dist:
        result.extend(node._values)
    candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))
return result

What happens when the method _get_child_candidates is called?
A list is returned? A single element is returned? Is it called again? When will subsequent calls stop?


1. The code comes from Jochen Schulz (jrschulz), who made a great Python library for metric spaces. This is the link to the complete source: Module mspace.
","Here are some Python examples of how to actually implement generators as if Python did not provide syntactic sugar for them (or in a language without native syntax, like JavaScript). Snippets from that link is below.
As a Python generator:
from itertools import islice

def fib_gen():
    a, b = 1, 1
    while True:
        yield a
        a, b = b, a + b

assert [1, 1, 2, 3, 5] == list(islice(fib_gen(), 5))

Using lexical closures instead of generators
def ftake(fnext, last):
    return [fnext() for _ in xrange(last)]

def fib_gen2():
    #funky scope due to python2.x workaround
    #for python 3.x use nonlocal
    def _():
        _.a, _.b = _.b, _.a + _.b
        return _.a
    _.a, _.b = 0, 1
    return _

assert [1,1,2,3,5] == ftake(fib_gen2(), 5)

Using object closures instead of generators (because ClosuresAndObjectsAreEquivalent)
class fib_gen3:
    def __init__(self):
        self.a, self.b = 1, 1

    def __call__(self):
        r = self.a
        self.a, self.b = self.b, self.a + self.b
        return r

assert [1,1,2,3,5] == ftake(fib_gen3(), 5)

"
"[INST] I am trying to implement a ""Digit Recognition OCR"" in OpenCV-Python (cv2). It is just for learning purposes. I would like to learn both KNearest and SVM features in OpenCV. 
I have 100 samples (i.e. images) of each digit. I would like to train with them.
There is a sample letter_recog.py that comes with OpenCV sample. But i still couldn't figure out on how to use it. I don't understand what are the samples, responses etc. Also, it loads a txt file at first, which i didn't understand first.
Later on searching a little bit, i could find a letter_recognition.data in cpp samples. I used it and made a code for cv2.KNearest in the model of letter_recog.py (just for testing):
import numpy as np
import cv2

fn = 'letter-recognition.data'
a = np.loadtxt(fn, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })
samples, responses = a[:,1:], a[:,0]

model = cv2.KNearest()
retval = model.train(samples,responses)
retval, results, neigh_resp, dists = model.find_nearest(samples, k = 10)
print results.ravel()

It gave me an array of size 20000, i don't understand what it is.
Questions:
1) What is letter_recognition.data file ? How to build that file from my own data set?
2) What does results.reval() denote? 
3) How we can write a simple digit recognition tool using letter_recognition.data file (either KNearest or SVM)?
 [/INST] KNearest is a function in OpenCV2.
Here is the complete code for cv2 only (I just copied the code from the book ""OpenCV2"", chapter 2)
from cv2 import cv2

a = [1,2,3,4,5,6,7,8,9,10,","I am trying to implement a ""Digit Recognition OCR"" in OpenCV-Python (cv2). It is just for learning purposes. I would like to learn both KNearest and SVM features in OpenCV. 
I have 100 samples (i.e. images) of each digit. I would like to train with them.
There is a sample letter_recog.py that comes with OpenCV sample. But i still couldn't figure out on how to use it. I don't understand what are the samples, responses etc. Also, it loads a txt file at first, which i didn't understand first.
Later on searching a little bit, i could find a letter_recognition.data in cpp samples. I used it and made a code for cv2.KNearest in the model of letter_recog.py (just for testing):
import numpy as np
import cv2

fn = 'letter-recognition.data'
a = np.loadtxt(fn, np.float32, delimiter=',', converters={ 0 : lambda ch : ord(ch)-ord('A') })
samples, responses = a[:,1:], a[:,0]

model = cv2.KNearest()
retval = model.train(samples,responses)
retval, results, neigh_resp, dists = model.find_nearest(samples, k = 10)
print results.ravel()

It gave me an array of size 20000, i don't understand what it is.
Questions:
1) What is letter_recognition.data file ? How to build that file from my own data set?
2) What does results.reval() denote? 
3) How we can write a simple digit recognition tool using letter_recognition.data file (either KNearest or SVM)?
","For those who interested in C++ code can refer below code. 
Thanks Abid Rahman for the nice explanation.

The procedure is same as above but, the contour finding uses only first hierarchy level contour, so that the algorithm uses only outer contour for each digit.
Code for creating sample and Label data
//Process image to extract contour
Mat thr,gray,con;
Mat src=imread(""digit.png"",1);
cvtColor(src,gray,CV_BGR2GRAY);
threshold(gray,thr,200,255,THRESH_BINARY_INV); //Threshold to find contour
thr.copyTo(con);

// Create sample and label data
vector< vector <Point> > contours; // Vector for storing contour
vector< Vec4i > hierarchy;
Mat sample;
Mat response_array;  
findContours( con, contours, hierarchy,CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE ); //Find contour

for( int i = 0; i< contours.size(); i=hierarchy[i][0] ) // iterate through first hierarchy level contours
{
    Rect r= boundingRect(contours[i]); //Find bounding rect for each contour
    rectangle(src,Point(r.x,r.y), Point(r.x+r.width,r.y+r.height), Scalar(0,0,255),2,8,0);
    Mat ROI = thr(r); //Crop the image
    Mat tmp1, tmp2;
    resize(ROI,tmp1, Size(10,10), 0,0,INTER_LINEAR ); //resize to 10X10
    tmp1.convertTo(tmp2,CV_32FC1); //convert to float
    sample.push_back(tmp2.reshape(1,1)); // Store  sample data
    imshow(""src"",src);
    int c=waitKey(0); // Read corresponding label for contour from keyoard
    c-=0x30;     // Convert ascii to intiger value
    response_array.push_back(c); // Store label to a mat
    rectangle(src,Point(r.x,r.y), Point(r.x+r.width,r.y+r.height), Scalar(0,255,0),2,8,0);    
}

// Store the data to file
Mat response,tmp;
tmp=response_array.reshape(1,1); //make continuous
tmp.convertTo(response,CV_32FC1); // Convert  to float

FileStorage Data(""TrainingData.yml"",FileStorage::WRITE); // Store the sample data in a file
Data << ""data"" << sample;
Data.release();

FileStorage Label(""LabelData.yml"",FileStorage::WRITE); // Store the label data in a file
Label << ""label"" << response;
Label.release();
cout<<""Training and Label data created successfully....!! ""<<endl;

imshow(""src"",src);
waitKey();

Code for training and testing
Mat thr,gray,con;
Mat src=imread(""dig.png"",1);
cvtColor(src,gray,CV_BGR2GRAY);
threshold(gray,thr,200,255,THRESH_BINARY_INV); // Threshold to create input
thr.copyTo(con);


// Read stored sample and label for training
Mat sample;
Mat response,tmp;
FileStorage Data(""TrainingData.yml"",FileStorage::READ); // Read traing data to a Mat
Data[""data""] >> sample;
Data.release();

FileStorage Label(""LabelData.yml"",FileStorage::READ); // Read label data to a Mat
Label[""label""] >> response;
Label.release();


KNearest knn;
knn.train(sample,response); // Train with sample and responses
cout<<""Training compleated.....!!""<<endl;

vector< vector <Point> > contours; // Vector for storing contour
vector< Vec4i > hierarchy;

//Create input sample by contour finding and cropping
findContours( con, contours, hierarchy,CV_RETR_CCOMP, CV_CHAIN_APPROX_SIMPLE );
Mat dst(src.rows,src.cols,CV_8UC3,Scalar::all(0));

for( int i = 0; i< contours.size(); i=hierarchy[i][0] ) // iterate through each contour for first hierarchy level .
{
    Rect r= boundingRect(contours[i]);
    Mat ROI = thr(r);
    Mat tmp1, tmp2;
    resize(ROI,tmp1, Size(10,10), 0,0,INTER_LINEAR );
    tmp1.convertTo(tmp2,CV_32FC1);
    float p=knn.find_nearest(tmp2.reshape(1,1), 1);
    char name[4];
    sprintf(name,""%d"",(int)p);
    putText( dst,name,Point(r.x,r.y+r.height) ,0,1, Scalar(0, 255, 0), 2, 8 );
}

imshow(""src"",src);
imshow(""dst"",dst);
imwrite(""dest.jpg"",dst);
waitKey();

Result
In the result the dot in the first line is detected as 8 and we havenât trained for dot. Also I am considering every contour in first hierarchy level as the sample input, user can avoid it by computing the area.  

"
"[INST] Using pip, is it possible to figure out which version of a package is currently installed?
I know about pip install XYZ --upgrade but I am wondering if there is anything like pip info XYZ.  If not what would be the best way to tell what version I am currently using.
 [/INST] If you're using pip, you can also do:
$ pip -e ""from pip import XYZ""

  or
$ pip -e ""from pip import XYZ""

  Note that the ""--outdated"" argument is deprecated in pip 3.0, so you should use:
$ pip show -o XYZ

  Note that the --outdated argument is deprecated in pip3.0.

 [/INST] The --outdated option is deprecated in pip2.1.

pip show -outdated outdated

will show the current and outdated outdated packages.
  Note that pip --outdated will run the same command that you would have done with --outdated.
  Note that --outdated in pip3.0 only applies to ""unsupported"" packages.
  Note that --outdated will always run the latest version of the package.
  Note that --outdated in pip3.0 is deprecated too, and should be replaced with pip3.outdated.
  Note that --outdated may not work if the package doesn't have a __outdated__ member.
  Note that --outdated may be deprecated in future versions.
 [/INST] [/INST] pip show [outdated] will show the current and outdated packages.
pip show -outdated [outdated] [/OUTD] [/OUTD] pip show [outdated] [outdated] [/OUTD] [pip show [outdated] [outdated] [outdated] is deprecated in pip3.0

  Note that --outdated [outdated] [outdated] [outdated] [outdated] is deprecated.
  Note that --outdated may not be exactly outdated in pip2.0.

pip show [outdated] [outdated] [on OS outdated] [on OS outdated]

pip show","Using pip, is it possible to figure out which version of a package is currently installed?
I know about pip install XYZ --upgrade but I am wondering if there is anything like pip info XYZ.  If not what would be the best way to tell what version I am currently using.
","Pip 1.3 now also has a list command:
$ pip list
argparse (1.2.1)
pip (1.5.1)
setuptools (2.1)
wsgiref (0.1.2)

"
"[INST] I'm using this code to get standard output from an external program:
>>> from subprocess import *
>>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]

The communicate() method returns an array of bytes:
>>> command_stdout
b'total 0\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\n'

However, I'd like to work with the output as a normal Python string. So that I could print it like this:
>>> print(command_stdout)
-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1
-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2

I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:
>>> binascii.b2a_qp(command_stdout)
b'total 0\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\n'

Does anybody know how to convert the bytes value back to string? I mean, using the ""batteries"" instead of doing it manually. And I'd like it to be ok with Python 3.
 [/INST] Standard RAW (the input file is RAW) is RAW (reading the standard output) and raw (the input file is RAW) are RAW data (i.e. bytes). So you can just do:
>>> print(type(type(s)) == 'raw')

  /\n/total 0\n\n\n\n
>>> print(type(3)) == 'total 0\n\n')

  RAW (bytes) is RAW data","I'm using this code to get standard output from an external program:
>>> from subprocess import *
>>> command_stdout = Popen(['ls', '-l'], stdout=PIPE).communicate()[0]

The communicate() method returns an array of bytes:
>>> command_stdout
b'total 0\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\n'

However, I'd like to work with the output as a normal Python string. So that I could print it like this:
>>> print(command_stdout)
-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1
-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2

I thought that's what the binascii.b2a_qp() method is for, but when I tried it, I got the same byte array again:
>>> binascii.b2a_qp(command_stdout)
b'total 0\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file1\n-rw-rw-r-- 1 thomas thomas 0 Mar  3 07:03 file2\n'

Does anybody know how to convert the bytes value back to string? I mean, using the ""batteries"" instead of doing it manually. And I'd like it to be ok with Python 3.
","I think this way is easy:
bytes = [112, 52, 52]
"""".join(map(chr, bytes))
>> p44

"
"[INST] Is there any way to convert an entire user inputted string from uppercase, or even part uppercase to lowercase? 
E.g. Kilometers --> kilometers.
 [/INST] The semantic meaning of ""uppercase"" in Python is to do the same thing that the str() method does in a lowercase version, i.e. Kilometer > 1
this is important because
  Kilometer == miles : x => kilometers
  miles == kilometer => kilometers

but if you don't care about semantically, you can just write:
uppercase = kilometer
lowercase = kilometer

E.g.
# convert kilometer --> miles
# convert uppercase to lowercase
# kilometer == kilometer

  kilometer == miles
# km = kilometer * kilometer

  # km is always in radians
# but you can do:
km = (1 / kilometer) * km * km

  km = miles / kilometer

  kilometer == km * km

  # don't use uppercase for kilometer

  km = km * km * km

  # don't use uppercase for kilometer

  km = (1.0 / kilometer, km / kilometer) * km / km

  # don't use uppercase for miles

  km = km / km * km

  from this
  km = (1.0 / km * km * km)

  km = (1.0 / km * km ** km)

  km = km * km ** km

  # don't use uppercase for miles
km = km / km ** km

  km = (1.0 / km * km ** km * km)

  km / km / km == km / km * km

  km = (1.0 / km * km ** km * km

  # don't use uppercase for miles

  km / km = (1.0 / km * km ** km)

  km / km * km

  # don't use uppercase for miles

  km / km / km ** km

  km / km == km

  # don","Is there any way to convert an entire user inputted string from uppercase, or even part uppercase to lowercase? 
E.g. Kilometers --> kilometers.
","You can do what Peter said, or
if you want the user to input something you could do this:
raw_input('Type Something').lower()

It will then automatically convert the thing they typed into lowercase. :)
Note: raw_input was renamed to input in Python 3.x and above.
"
"[INST] Requests is a really nice library. I'd like to use it for download big files (>1GB).
The problem is it's not possible to keep whole file in memory I need to read it in chunks. And this is a problem with the following code
import requests

def DownloadFile(url)
    local_filename = url.split('/')[-1]
    r = requests.get(url)
    f = open(local_filename, 'wb')
    for chunk in r.iter_content(chunk_size=512 * 1024): 
        if chunk: # filter out keep-alive new chunks
            f.write(chunk)
    f.close()
    return 

By some reason it doesn't work this way. It still loads response into memory before save it to a file.
 [/INST] The request.mime type is needed for HTTP/1024:
http://www.python.org/mime/html/3/http/
http://www.mime.org/lime/html/
http://www.mime.org/lime/html/
u = requests.get(url)
u.close()
return u

  /local_filename (http://www.mime.org/lime/html/3/2/2/?f=False) 
  File ""http://www.microsoft.com/en/gb/ms_ms/"", line=22, in=22)
  File ""http://www.microsoft.com/l/?f=False"" 
  File ""/l/mime/http/http/files/"", line=1, in=22)
  File ""/l/mime/http/mime.xml"")
  u.close()
  u.close()
  traceback (/mime/mime.html): 
  File ""/mime/lime/mime.xml"", line=22, in=22)
  File ""/mime/mime/lime/html/open/content/mime/content/__name__
  File ""/mime/lime/html/mime/l","Requests is a really nice library. I'd like to use it for download big files (>1GB).
The problem is it's not possible to keep whole file in memory I need to read it in chunks. And this is a problem with the following code
import requests

def DownloadFile(url)
    local_filename = url.split('/')[-1]
    r = requests.get(url)
    f = open(local_filename, 'wb')
    for chunk in r.iter_content(chunk_size=512 * 1024): 
        if chunk: # filter out keep-alive new chunks
            f.write(chunk)
    f.close()
    return 

By some reason it doesn't work this way. It still loads response into memory before save it to a file.
","I figured out what should be changed. The trick was to set stream = True in the get() method. 
After this python process stopped to suck memory (stays around 30kb regardless size of the download file). 
Thank you @danodonovan for you syntax I use it here:
def download_file(url):
    local_filename = url.split('/')[-1]
    # NOTE the stream=True parameter
    r = requests.get(url, stream=True)
    with open(local_filename, 'wb') as f:
        for chunk in r.iter_content(chunk_size=1024): 
            if chunk: # filter out keep-alive new chunks
                f.write(chunk)
                #f.flush() commented by recommendation from J.F.Sebastian
    return local_filename

See http://docs.python-requests.org/en/latest/user/advanced/#body-content-workflow for further reference.
"
"[INST] I'm iterating over a list of tuples in Python, and am attempting to remove them if they meet certain criteria. 
for tup in somelist:
    if determine(tup):
         code_to_remove_tup

What should I use in place of code_to_remove_tup? I can't figure out how to remove the item in this fashion.
 [/INST] If you are removing a single item, and you don't want to iterate over the list and do a search, you can just use index:
for item in mylist:
    if item == myitem:
        del mylist[item]

  # mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]
  # mylist, mylist[1:1: 1]

  # mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, mylist[1:1: 1]

# mylist, my","I'm iterating over a list of tuples in Python, and am attempting to remove them if they meet certain criteria. 
for tup in somelist:
    if determine(tup):
         code_to_remove_tup

What should I use in place of code_to_remove_tup? I can't figure out how to remove the item in this fashion.
","The official Python 2 tutorial 4.2. ""for Statements"" says:

If you need to modify the sequence you are iterating over while inside the loop (for example to duplicate selected items), it is recommended that you first make a copy. Iterating over a sequence does not implicitly make a copy. The slice notation makes this especially convenient:

>>> for w in words[:]:  # Loop over a slice copy of the entire list.
...     if len(w) > 6:
...         words.insert(0, w)
...
>>> words
['defenestrate', 'cat', 'window', 'defenestrate']

which is what was suggested at: http://stackoverflow.com/a/1207427/895245
The Python 2 documentation 7.3. ""The for statement"" gives the same advice:

Note: There is a subtlety when the sequence is being modified by the loop (this can only occur for mutable sequences, i.e. lists). An internal counter is used to keep track of which item is used next, and this is incremented on each iteration. When this counter has reached the length of the sequence the loop terminates. This means that if the suite deletes the current (or a previous) item from the sequence, the next item will be skipped (since it gets the index of the current item which has already been treated). Likewise, if the suite inserts an item in the sequence before the current item, the current item will be treated again the next time through the loop. This can lead to nasty bugs that can be avoided by making a temporary copy using a slice of the whole sequence, e.g.,

for x in a[:]:
    if x < 0: a.remove(x)

"
"[INST] Inspired by the question series 'Hidden features of ...', I am curious to hear about your favorite Django tips or lesser known but useful features you know of.

Please, include only one tip per answer.
Add Django version requirements if there are any.

 [/INST] I have a very long query about this and I finally decided to write it down in order to share it with others. I hope my question is clear and helpful for someone who is in a hurry.
Being a beginner in Django, I was not aware of the basics. I had to learn how to run the Django queryset from within Django. I had a very basic understanding of it, but it was just enough to me to start from scratch and I was not sure if I had a basic understanding of it.
Being new in the software development world, I didn't have a proper way of doing things like this, I was just trying to follow one of my answers from SO.
I had to learn this one day. I was just trying to do this because I didn't have any kind of workflow for it. But now, I understand that I have just started learning Django and I'm not in the mood to go back and do the same thing again. 
Basically, I was looking for something like this:
def my_query(params):
    q = Django.objects.filter(qs=""query1"")
    q = Django.objects.filter(qs=""query2"")
    if len(qs) > 1:
        return Django.objects.exclude(qs=*)
    else:
        return Django.objects.exclude(qs=""query1"")

I was not really thinking about the queryset, but if I had the ability to do that, I would have loved to have some parameters passed in there too.
So basically, my question was: ""what is Django"" and the answer was just ""query1"" because I am not really interested in that part, but I was
  `def my_query(q=Django.objects.filter(qs=*)`)
  from Django_utils import gis
  from my_query import Django_queryset
  return Django.objects.filter(qs=*)

The","Inspired by the question series 'Hidden features of ...', I am curious to hear about your favorite Django tips or lesser known but useful features you know of.

Please, include only one tip per answer.
Add Django version requirements if there are any.

","Using an 'apps' folder to organize your applications without editing PYTHONPATH
This has come handy when I want to organize my folders like this:
apps/
    foo/
    bar/
site/
settings.py
urls.py

without overwritting PYTHONPATH or having to add apps to every import like:
from apps.foo.model import *
from apps.bar.forms import *

In your settings.py add
import os
import sys
PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))
sys.path.insert(0, os.path.join(PROJECT_ROOT, ""apps""))

and you are ready to go :-)
I saw this at http://codespatter.com/2009/04/10/how-to-add-locations-to-python-path-for-reusable-django-apps/
"
"[INST] Whats the difference (in language a python/django noob can understand) in a view between render(), render_to_response() and direct_to_template()?
e.g. from Nathan Borror's basic apps examples
def comment_edit(request, object_id, template_name='comments/edit.html'):
    comment = get_object_or_404(Comment, pk=object_id, user=request.user)
    # ...
    return render(request, template_name, {
        'form': form,
        'comment': comment,
    })

But I've also seen
    return render_to_response(template_name, my_data_dictionary,
              context_instance=RequestContext(request))

And
    return direct_to_template(request, template_name, my_data_dictionary)

Whats the difference, what to use in any particular situation?
 [/INST] The template_name is the same for all the views:
GET_LIST_LIST_NAMES = 'pk_list'

def list_list_list_names(request):
    return [pk_list_names[pk_list_name] for pk in list_names]

The template_list_names is the same, but the context_list_name is the ""pk_list_name""

Note that the ""pk_list_name"" is not the same thing, it depends on the model.
e.g. you could load this list_name in the first template_name, e.g.
def comment_list_names(request):
    return [pk_list_name for pk in e.object_list_names]

(e.g. in the context_list_name, the context_list_names are the same, but just in context_list_list_name, the context_list_name is the first one, the second one can be the second one if the first one doesn't exist, or the third one exists and is omitted.)
e.g.
# list_names
[template_name, e.pk_list_list_name, e.g.pk_list_","Whats the difference (in language a python/django noob can understand) in a view between render(), render_to_response() and direct_to_template()?
e.g. from Nathan Borror's basic apps examples
def comment_edit(request, object_id, template_name='comments/edit.html'):
    comment = get_object_or_404(Comment, pk=object_id, user=request.user)
    # ...
    return render(request, template_name, {
        'form': form,
        'comment': comment,
    })

But I've also seen
    return render_to_response(template_name, my_data_dictionary,
              context_instance=RequestContext(request))

And
    return direct_to_template(request, template_name, my_data_dictionary)

Whats the difference, what to use in any particular situation?
","Render is
def render(request, *args, **kwargs):
    """""" Simple wrapper for render_to_response. """"""
    kwargs['context_instance'] = RequestContext(request)
    return render_to_response(*args, **kwargs)

So there is really no difference between render_to_response except it wraps your context making the template pre-processors work.
Direct to template is a generic view.
There is really no sense in using it here because there is overhead over render_to_response in the form of view function.
"
"[INST] The time module can be initialized using seconds since epoch:
>>> import time
>>> t1=time.gmtime(1284286794)
>>> t1
time.struct_time(tm_year=2010, tm_mon=9, tm_mday=12, tm_hour=10, tm_min=19, 
                 tm_sec=54, tm_wday=6, tm_yday=255, tm_isdst=0)

Is there an elegant way to initialize a datetime.datetime object in the same way?
 [/INST] I've found that the most elegant solution is to simply wrap around the time.time() function.
def tm_hour(tm_mday=2010):
    tm_hour=tm_hour/365867
    tm_mday=tm_hour/365867

tm_myear=tm_hour/365867

for instance:
tm_hour=tm_hour/365867
tm_mday=tm_hour/365867

for tm_hour in tm_mday:
    tm_hour=tm_hour/365867

 
 
and the same thing with a regular timer:
tm_hour=tm_mday/365867

 
 

 

tm_hour=tm_mday/365867

 

 

tm_hour=tm_hour/365867
/tm_hour=tm_mday/365867

 

 

 

tm_hour=tm_mday/365867

 

 

>>> tm_mday/365867

 

tm_hour=tm_hour/365867
/tm_mday/365867

 

 

but the problem is:
tm_mday=tm_hour/tm_mday 

 ","The time module can be initialized using seconds since epoch:
>>> import time
>>> t1=time.gmtime(1284286794)
>>> t1
time.struct_time(tm_year=2010, tm_mon=9, tm_mday=12, tm_hour=10, tm_min=19, 
                 tm_sec=54, tm_wday=6, tm_yday=255, tm_isdst=0)

Is there an elegant way to initialize a datetime.datetime object in the same way?
","Seconds since epoch to datetime to strftime:
>>> ts_epoch = 1362301382
>>> ts = datetime.datetime.fromtimestamp(ts_epoch).strftime('%Y-%m-%d %H:%M:%S')
>>> ts
'2013-03-03 01:03:02'

"
