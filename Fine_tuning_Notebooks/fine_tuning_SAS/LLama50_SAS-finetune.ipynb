{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b27ffdbb-e719-469e-93c4-ba65903f0b55",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## **Installing dependencies** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f25b326-02d3-4541-be55-ce8a45db6967",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b8970df-cd86-44a1-bc71-ad5bbbee9a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /home/zealous_easley/.local/lib/python3.8/site-packages (0.1.99)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# we use the latest version of transformers, peft, and accelerate\n",
    "!pip install -q accelerate peft transformers\n",
    "\n",
    "# install bitsandbytes for quantization\n",
    "!pip install -q bitsandbytes\n",
    "\n",
    "# install trl for the SFT library\n",
    "!pip install -q trl\n",
    "\n",
    "# we need sentencepiece for the llama2 slow tokenizer (not necessary for mistral)\n",
    "!pip install sentencepiece\n",
    "\n",
    "# we need einops, used by falcon-7b, llama-2 mistral etc\n",
    "# einops (einsteinops) is used to simplify tensorops by making them readable\n",
    "!pip install -q -U einops\n",
    "\n",
    "# we need to install datasets for our training dataset\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023723b3",
   "metadata": {},
   "source": [
    "Keeping track on GPU resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ded1d30-d62f-42b3-bf62-30a83d370f8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 34.07 GB\n",
      "Reserved Memory: 0.00 GB\n",
      "Allocated Memory: 0.00 GB\n",
      "Free (inside reserved) Memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def print_gpu_memory_usage():\n",
    "    # Assuming you have at least one CUDA-capable GPU and want to check the first one\n",
    "    t = torch.cuda.get_device_properties(0).total_memory\n",
    "    r = torch.cuda.memory_reserved(0) \n",
    "    a = torch.cuda.memory_allocated(0)\n",
    "    f = r-a  # free inside reserved\n",
    "\n",
    "    print(f\"Total GPU Memory: {t * 1e-9:.2f} GB\")\n",
    "    print(f\"Reserved Memory: {r * 1e-9:.2f} GB\")\n",
    "    print(f\"Allocated Memory: {a * 1e-9:.2f} GB\")\n",
    "    print(f\"Free (inside reserved) Memory: {f * 1e-9:.2f} GB\")\n",
    "\n",
    "# Then, you can call this function at the end of each cell where you want to check the GPU memory usage\n",
    "print_gpu_memory_usage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579aacf2-e918-44d9-8157-d99b22ffe633",
   "metadata": {},
   "source": [
    "## **Loading the model** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "462d6f73-7f44-4ce6-8dbc-23e785c306b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model that we want to train from the Hugging Face hub\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "\n",
    "# The instruction dataset to use found on HuggingFace\n",
    "dataset_name = \"MaamarM/SAS_training\"\n",
    "\n",
    "# Fine-tuned model name\n",
    "new_model = \"Mistral-7B-SAS\"\n",
    "\n",
    "# Output directory where the model predictions and checkpoints will be stored\n",
    "#This is to push our fine tuned model in the Hugging Face platform\n",
    "output_dir = \"./Mistral_Instruct_SAS\"\n",
    "\n",
    "# Number of training epochs\n",
    "num_train_epochs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a59ccfd9-05c4-4d5a-b4ba-cc9e9c53d720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 16:42:52.305819: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-11 16:42:52.368940: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5d696b7d6b4b5fb84a1c7cc359d0b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "\n",
    "# load the quantized settings, we're doing 4 bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "# Load base model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    # use the gpu\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "\n",
    "# don't use the cache\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Load the tokenizer from the model (mistral)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True, use_fast=False)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaab41d-5a14-49b9-8824-52ae41c9a327",
   "metadata": {},
   "source": [
    "## **Testing on some prompts** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8e3a85d-e6fa-4945-8a5b-b0587e6199f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>Annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>*SAS code;\\nPROC REG DATA= REG_SERIES; MODEL y...</td>\n",
       "      <td>Perform a linear regression analysis on the da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5081</th>\n",
       "      <td>%let name=sct4;\\n\\n/* \\nSet your current-worki...</td>\n",
       "      <td>Set a variable named \"name\" to \"sct4\", create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5011</th>\n",
       "      <td>options bufsize=32768 pagesize=10000;\\n\\ndata ...</td>\n",
       "      <td>Define the options \"bufsize\" and \"pagesize\" to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>LIBNAME X \"/folders/myfolders/X\";\\ndata brfss_...</td>\n",
       "      <td>\"Set the library location to '/folders/myfolde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>*Ex15_macro_part_of_SAS_statement.sas;\\noption...</td>\n",
       "      <td>Please convert the following SAS programming l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3819</th>\n",
       "      <td>Parent child kinship problem chain\\n\\n  WPS an...</td>\n",
       "      <td>Create an intermediate dataset named \"int\" by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10089</th>\n",
       "      <td>/*********************************************...</td>\n",
       "      <td>Create an LLM model that can replicate the fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8740</th>\n",
       "      <td>Cross Platform Unzip Medicare Point of Sevice ...</td>\n",
       "      <td>Instructions for an LLM model to match the giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7831</th>\n",
       "      <td>%include \"HIDI_init.sas\" ; /* File path remove...</td>\n",
       "      <td>\"Include the following SAS files in the order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>Keeping a ring of last four daily table update...</td>\n",
       "      <td>Match the SAS programming language script belo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2182 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  \\\n",
       "4829   *SAS code;\\nPROC REG DATA= REG_SERIES; MODEL y...   \n",
       "5081   %let name=sct4;\\n\\n/* \\nSet your current-worki...   \n",
       "5011   options bufsize=32768 pagesize=10000;\\n\\ndata ...   \n",
       "4625   LIBNAME X \"/folders/myfolders/X\";\\ndata brfss_...   \n",
       "3838   *Ex15_macro_part_of_SAS_statement.sas;\\noption...   \n",
       "...                                                  ...   \n",
       "3819   Parent child kinship problem chain\\n\\n  WPS an...   \n",
       "10089  /*********************************************...   \n",
       "8740   Cross Platform Unzip Medicare Point of Sevice ...   \n",
       "7831   %include \"HIDI_init.sas\" ; /* File path remove...   \n",
       "6075   Keeping a ring of last four daily table update...   \n",
       "\n",
       "                                              Annotation  \n",
       "4829   Perform a linear regression analysis on the da...  \n",
       "5081   Set a variable named \"name\" to \"sct4\", create ...  \n",
       "5011   Define the options \"bufsize\" and \"pagesize\" to...  \n",
       "4625   \"Set the library location to '/folders/myfolde...  \n",
       "3838   Please convert the following SAS programming l...  \n",
       "...                                                  ...  \n",
       "3819   Create an intermediate dataset named \"int\" by ...  \n",
       "10089  Create an LLM model that can replicate the fun...  \n",
       "8740   Instructions for an LLM model to match the giv...  \n",
       "7831   \"Include the following SAS files in the order ...  \n",
       "6075   Match the SAS programming language script belo...  \n",
       "\n",
       "[2182 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "parquet_file = r'test_data.parquet'\n",
    "df=pd.read_parquet(parquet_file, engine = 'pyarrow')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76ff4765-3356-4af8-9576-c28c6270e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Scripts:   4%|▍         | 4/100 [05:54<2:02:28, 76.55s/it] /home/zealous_easley/.local/lib/python3.8/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Generating Scripts: 100%|██████████| 100/100 [2:57:47<00:00, 106.68s/it] \n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "def generate_script(instruction):\n",
    "    result = pipe(f\"[INST] {instruction} [/INST]\")\n",
    "    generated_text = result[0]['generated_text']\n",
    "    cleaned_output = generated_text.replace(f\"[INST] {instruction} [/INST]\", \"\").strip()\n",
    "    return instruction, cleaned_output\n",
    "\n",
    "# Use ThreadPoolExecutor to parallelize script generation\n",
    "with ThreadPoolExecutor(max_workers=5) as executor:  # Adjust max_workers based on your hardware\n",
    "    future_to_inst = {executor.submit(generate_script, inst): inst for inst in df['Annotation'].iloc[:100]}\n",
    "    for future in tqdm(as_completed(future_to_inst), total=len(future_to_inst), desc=\"Generating Scripts\"):\n",
    "        instruction, script = future.result()\n",
    "        results.append({\"instruction\": instruction, \"generated_script\": script})\n",
    "\n",
    "# Convert results to DataFrame and save to Parquet\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_parquet('generated_scripts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e361f811-06ff-4307-a25d-615a6dd33ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>generated_script</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Set the library location to '/folders/myfolde...</td>\n",
       "      <td>To set the SAS library location, use the follo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Please convert the following SAS programming l...</td>\n",
       "      <td>To create an LLM model instruction for the giv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rename a file located in a specific path using...</td>\n",
       "      <td>To rename the files using the given file names...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perform a linear regression analysis on the da...</td>\n",
       "      <td>To perform a linear regression analysis, save ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Set a variable named \"name\" to \"sct4\", create ...</td>\n",
       "      <td>```scss:scss\\n\\nname &lt;- \"sct4\"\\nfile.edit(\".\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Set the library named \"es\" to the directory \"/...</td>\n",
       "      <td>To accomplish the tasks you described, you can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Create SAS informats for missing values using ...</td>\n",
       "      <td>To create SAS informats for missing values usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Create an LLM model that can replicate the fun...</td>\n",
       "      <td>To create an LLM model named \"lscmd\" version 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Create a function that creates an Application ...</td>\n",
       "      <td>Here's a VBA function that creates an Applicat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Create SAS informats for missing values and lo...</td>\n",
       "      <td>To create SAS informats for missing values and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          instruction  \\\n",
       "0   \"Set the library location to '/folders/myfolde...   \n",
       "1   Please convert the following SAS programming l...   \n",
       "2   Rename a file located in a specific path using...   \n",
       "3   Perform a linear regression analysis on the da...   \n",
       "4   Set a variable named \"name\" to \"sct4\", create ...   \n",
       "..                                                ...   \n",
       "95  Set the library named \"es\" to the directory \"/...   \n",
       "96  Create SAS informats for missing values using ...   \n",
       "97  Create an LLM model that can replicate the fun...   \n",
       "98  Create a function that creates an Application ...   \n",
       "99  Create SAS informats for missing values and lo...   \n",
       "\n",
       "                                     generated_script  \n",
       "0   To set the SAS library location, use the follo...  \n",
       "1   To create an LLM model instruction for the giv...  \n",
       "2   To rename the files using the given file names...  \n",
       "3   To perform a linear regression analysis, save ...  \n",
       "4   ```scss:scss\\n\\nname <- \"sct4\"\\nfile.edit(\".\",...  \n",
       "..                                                ...  \n",
       "95  To accomplish the tasks you described, you can...  \n",
       "96  To create SAS informats for missing values usi...  \n",
       "97  To create an LLM model named \"lscmd\" version 1...  \n",
       "98  Here's a VBA function that creates an Applicat...  \n",
       "99  To create SAS informats for missing values and...  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parquet_file = r'generated_scripts.parquet'\n",
    "df=pd.read_parquet(parquet_file, engine = 'pyarrow')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22b64aff-bbf1-40d5-8165-d82677363cba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To set the SAS library location, use the following command:\\n\\n```sas\\nOPTIONS NOXWAIT NOXSYNC;\\nLIBNAME lib \"folders/myfolders/X\" SERVER;\\n```\\n\\nReplace \"X\" with the name of your library.\\n\\nNow, load the dataset \\'Chap6_1\\' from the library \\'X\\' into a new dataset named \\'brfss_a\\':\\n\\n```sas\\nDATA brfss_a;\\n    SET lib.Chap6_1;\\nRUN;\\n```\\n\\nFinally, use the \\'PROC CONTENTS\\' procedure to display variable information for the dataset \\'brfss_a\\':\\n\\n```sas\\nPROC CONTENTS DATA=brfss_a;\\nRUN;\\n```\\n\\nThis will display the variable names and their corresponding variable numbers in the SAS log.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['generated_script'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3589ee3a-d738-42cd-b3f5-f87b7e7c7412",
   "metadata": {},
   "source": [
    "## **Fine tuning sur SAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e60c37-ab37-4740-9e40-895990a5cd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\"train\":\"formatted_training.jsonl\"}\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(dataset_name, data_files = data_files , split=\"train[:50%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f21daed2-640a-4a84-a150-e254d91481af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 34.07 GB\n",
      "Reserved Memory: 10.23 GB\n",
      "Allocated Memory: 10.04 GB\n",
      "Free (inside reserved) Memory: 0.19 GB\n"
     ]
    }
   ],
   "source": [
    "print_gpu_memory_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e0f3be-2c98-4bdb-a720-213814165d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95f6a99e-e4ca-4bed-81e9-c75c2bdd61e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be526dec86c9430ba6109e102923520e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b79bf6-10af-478b-b98a-10c8b62985d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/laughing_bhabha/.local/lib/python3.8/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n",
      "  warnings.warn(\n",
      "/home/laughing_bhabha/.local/lib/python3.8/site-packages/trl/trainer/sft_trainer.py:194: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0357, 'grad_norm': 0.032106101512908936, 'learning_rate': 7.633587786259543e-06, 'epoch': 0.01}\n",
      "{'loss': 0.9167, 'grad_norm': 0.04357542842626572, 'learning_rate': 1.5267175572519086e-05, 'epoch': 0.02}\n",
      "{'loss': 0.9073, 'grad_norm': 0.04950644448399544, 'learning_rate': 2.2900763358778628e-05, 'epoch': 0.03}\n",
      "{'loss': 1.137, 'grad_norm': 0.09392911195755005, 'learning_rate': 3.053435114503817e-05, 'epoch': 0.04}\n",
      "{'loss': 1.9872, 'grad_norm': 0.6839531660079956, 'learning_rate': 3.816793893129771e-05, 'epoch': 0.05}\n",
      "{'loss': 0.8592, 'grad_norm': 0.08970703184604645, 'learning_rate': 4.5801526717557256e-05, 'epoch': 0.05}\n",
      "{'loss': 0.8754, 'grad_norm': 0.0978793352842331, 'learning_rate': 5.3435114503816794e-05, 'epoch': 0.06}\n",
      "{'loss': 0.9345, 'grad_norm': 0.11809295415878296, 'learning_rate': 6.106870229007635e-05, 'epoch': 0.07}\n",
      "{'loss': 1.0984, 'grad_norm': 0.18466901779174805, 'learning_rate': 6.870229007633588e-05, 'epoch': 0.08}\n",
      "{'loss': 1.2895, 'grad_norm': 0.5731046795845032, 'learning_rate': 7.633587786259542e-05, 'epoch': 0.09}\n",
      "{'loss': 0.8308, 'grad_norm': 0.11275392025709152, 'learning_rate': 8.396946564885496e-05, 'epoch': 0.1}\n",
      "{'loss': 1.1157, 'grad_norm': 0.12125498801469803, 'learning_rate': 9.160305343511451e-05, 'epoch': 0.11}\n",
      "{'loss': 0.9003, 'grad_norm': 0.1363578587770462, 'learning_rate': 9.923664122137405e-05, 'epoch': 0.12}\n",
      "{'loss': 1.0766, 'grad_norm': 0.18002867698669434, 'learning_rate': 0.00010687022900763359, 'epoch': 0.13}\n",
      "{'loss': 1.3443, 'grad_norm': 1.5380765199661255, 'learning_rate': 0.00011450381679389313, 'epoch': 0.14}\n",
      "{'loss': 0.9338, 'grad_norm': 0.16199500858783722, 'learning_rate': 0.0001221374045801527, 'epoch': 0.15}\n",
      "{'loss': 0.9425, 'grad_norm': 0.14892800152301788, 'learning_rate': 0.00012977099236641222, 'epoch': 0.16}\n",
      "{'loss': 0.8447, 'grad_norm': 0.1235368400812149, 'learning_rate': 0.00013740458015267177, 'epoch': 0.16}\n",
      "{'loss': 1.116, 'grad_norm': 0.2627367079257965, 'learning_rate': 0.0001450381679389313, 'epoch': 0.17}\n",
      "{'loss': 1.3883, 'grad_norm': 1.0940957069396973, 'learning_rate': 0.00015267175572519084, 'epoch': 0.18}\n",
      "{'loss': 0.9485, 'grad_norm': 0.21881233155727386, 'learning_rate': 0.0001603053435114504, 'epoch': 0.19}\n",
      "{'loss': 0.7381, 'grad_norm': 0.1406525820493698, 'learning_rate': 0.00016793893129770992, 'epoch': 0.2}\n",
      "{'loss': 0.7974, 'grad_norm': 0.14319105446338654, 'learning_rate': 0.00017557251908396947, 'epoch': 0.21}\n",
      "{'loss': 0.9896, 'grad_norm': 0.2259070873260498, 'learning_rate': 0.00018320610687022902, 'epoch': 0.22}\n",
      "{'loss': 1.2284, 'grad_norm': 0.6285038590431213, 'learning_rate': 0.00019083969465648857, 'epoch': 0.23}\n",
      "{'loss': 0.7908, 'grad_norm': 0.14832280576229095, 'learning_rate': 0.0001984732824427481, 'epoch': 0.24}\n",
      "{'loss': 0.8424, 'grad_norm': 0.20005609095096588, 'learning_rate': 0.00019999955935091112, 'epoch': 0.25}\n",
      "{'loss': 0.8517, 'grad_norm': 0.12906531989574432, 'learning_rate': 0.00019999776922064323, 'epoch': 0.26}\n",
      "{'loss': 1.0098, 'grad_norm': 0.21583352982997894, 'learning_rate': 0.00019999460209325988, 'epoch': 0.27}\n",
      "{'loss': 1.2238, 'grad_norm': 0.7755027413368225, 'learning_rate': 0.00019999005801237335, 'epoch': 0.27}\n",
      "{'loss': 0.7787, 'grad_norm': 0.12554654479026794, 'learning_rate': 0.00019998413704055686, 'epoch': 0.28}\n",
      "{'loss': 0.7328, 'grad_norm': 0.12639573216438293, 'learning_rate': 0.00019997683925934384, 'epoch': 0.29}\n",
      "{'loss': 0.8252, 'grad_norm': 0.14359284937381744, 'learning_rate': 0.00019996816476922677, 'epoch': 0.3}\n",
      "{'loss': 0.9421, 'grad_norm': 0.2472882717847824, 'learning_rate': 0.00019995811368965578, 'epoch': 0.31}\n",
      "{'loss': 1.2124, 'grad_norm': 0.6176609396934509, 'learning_rate': 0.00019994668615903706, 'epoch': 0.32}\n",
      "{'loss': 0.7791, 'grad_norm': 0.12547345459461212, 'learning_rate': 0.0001999338823347309, 'epoch': 0.33}\n",
      "{'loss': 0.6774, 'grad_norm': 0.15274807810783386, 'learning_rate': 0.0001999197023930495, 'epoch': 0.34}\n",
      "{'loss': 0.8446, 'grad_norm': 0.17964571714401245, 'learning_rate': 0.0001999041465292546, 'epoch': 0.35}\n",
      "{'loss': 0.8493, 'grad_norm': 0.1640661507844925, 'learning_rate': 0.00019988721495755476, 'epoch': 0.36}\n",
      "{'loss': 1.0968, 'grad_norm': 0.4834139943122864, 'learning_rate': 0.0001998689079111025, 'epoch': 0.37}\n",
      "{'loss': 0.6453, 'grad_norm': 0.11639659851789474, 'learning_rate': 0.00019984922564199087, 'epoch': 0.38}\n",
      "{'loss': 0.6194, 'grad_norm': 0.12100355327129364, 'learning_rate': 0.00019982816842125024, 'epoch': 0.38}\n",
      "{'loss': 0.7741, 'grad_norm': 0.12675026059150696, 'learning_rate': 0.00019980573653884435, 'epoch': 0.39}\n",
      "{'loss': 1.0486, 'grad_norm': 0.20845241844654083, 'learning_rate': 0.00019978193030366654, 'epoch': 0.4}\n",
      "{'loss': 1.2836, 'grad_norm': 0.6847386956214905, 'learning_rate': 0.00019975675004353522, 'epoch': 0.41}\n",
      "{'loss': 0.8316, 'grad_norm': 0.13602088391780853, 'learning_rate': 0.00019973019610518966, 'epoch': 0.42}\n",
      "{'loss': 0.8062, 'grad_norm': 0.14741891622543335, 'learning_rate': 0.0001997022688542849, 'epoch': 0.43}\n",
      "{'loss': 0.7278, 'grad_norm': 0.15548810362815857, 'learning_rate': 0.000199672968675387, 'epoch': 0.44}\n",
      "{'loss': 0.9856, 'grad_norm': 0.24955691397190094, 'learning_rate': 0.00019964229597196757, 'epoch': 0.45}\n",
      "{'loss': 1.1647, 'grad_norm': 1.2844798564910889, 'learning_rate': 0.0001996102511663983, 'epoch': 0.46}\n",
      "{'loss': 0.7459, 'grad_norm': 0.1561105102300644, 'learning_rate': 0.00019957683469994507, 'epoch': 0.47}\n",
      "{'loss': 0.8165, 'grad_norm': 0.13467681407928467, 'learning_rate': 0.0001995420470327619, 'epoch': 0.48}\n",
      "{'loss': 0.7046, 'grad_norm': 0.16651834547519684, 'learning_rate': 0.00019950588864388466, 'epoch': 0.49}\n",
      "{'loss': 0.8994, 'grad_norm': 0.21630635857582092, 'learning_rate': 0.00019946836003122443, 'epoch': 0.49}\n",
      "{'loss': 1.2226, 'grad_norm': 0.8380023837089539, 'learning_rate': 0.00019942946171156063, 'epoch': 0.5}\n",
      "{'loss': 0.8096, 'grad_norm': 0.1346685141324997, 'learning_rate': 0.000199389194220534, 'epoch': 0.51}\n",
      "{'loss': 0.9233, 'grad_norm': 0.1593814641237259, 'learning_rate': 0.00019934755811263909, 'epoch': 0.52}\n",
      "{'loss': 0.7814, 'grad_norm': 0.11869017034769058, 'learning_rate': 0.00019930455396121666, 'epoch': 0.53}\n",
      "{'loss': 0.9919, 'grad_norm': 0.21243983507156372, 'learning_rate': 0.00019926018235844585, 'epoch': 0.54}\n",
      "{'loss': 1.2151, 'grad_norm': 1.2885425090789795, 'learning_rate': 0.00019921444391533602, 'epoch': 0.55}\n",
      "{'loss': 0.7887, 'grad_norm': 0.1599774807691574, 'learning_rate': 0.00019916733926171823, 'epoch': 0.56}\n",
      "{'loss': 0.6303, 'grad_norm': 0.11757202446460724, 'learning_rate': 0.00019911886904623667, 'epoch': 0.57}\n",
      "{'loss': 0.8645, 'grad_norm': 0.11994308233261108, 'learning_rate': 0.0001990690339363397, 'epoch': 0.58}\n",
      "{'loss': 0.7805, 'grad_norm': 0.17348818480968475, 'learning_rate': 0.00019901783461827066, 'epoch': 0.59}\n",
      "{'loss': 1.0427, 'grad_norm': 0.3150290846824646, 'learning_rate': 0.00019896527179705841, 'epoch': 0.6}\n",
      "{'loss': 0.9636, 'grad_norm': 0.19836971163749695, 'learning_rate': 0.00019891134619650765, 'epoch': 0.6}\n",
      "{'loss': 0.5644, 'grad_norm': 0.11525871604681015, 'learning_rate': 0.00019885605855918885, 'epoch': 0.61}\n",
      "{'loss': 0.6803, 'grad_norm': 0.12563388049602509, 'learning_rate': 0.00019879940964642823, 'epoch': 0.62}\n",
      "{'loss': 0.889, 'grad_norm': 0.20241566002368927, 'learning_rate': 0.00019874140023829707, 'epoch': 0.63}\n",
      "{'loss': 1.0415, 'grad_norm': 0.5912663340568542, 'learning_rate': 0.00019868203113360103, 'epoch': 0.64}\n",
      "{'loss': 0.764, 'grad_norm': 0.17967723309993744, 'learning_rate': 0.00019862130314986923, 'epoch': 0.65}\n",
      "{'loss': 0.7638, 'grad_norm': 0.10909184068441391, 'learning_rate': 0.00019855921712334294, 'epoch': 0.66}\n",
      "{'loss': 0.6988, 'grad_norm': 0.20420308411121368, 'learning_rate': 0.00019849577390896396, 'epoch': 0.67}\n",
      "{'loss': 0.885, 'grad_norm': 0.1870366781949997, 'learning_rate': 0.00019843097438036308, 'epoch': 0.68}\n",
      "{'loss': 1.1497, 'grad_norm': 0.8228712677955627, 'learning_rate': 0.0001983648194298478, 'epoch': 0.69}\n",
      "{'loss': 0.7046, 'grad_norm': 0.08434689790010452, 'learning_rate': 0.0001982973099683902, 'epoch': 0.7}\n",
      "{'loss': 0.8194, 'grad_norm': 0.1119556650519371, 'learning_rate': 0.00019822844692561438, 'epoch': 0.71}\n",
      "{'loss': 0.8022, 'grad_norm': 0.1279713660478592, 'learning_rate': 0.00019815823124978357, 'epoch': 0.71}\n",
      "{'loss': 0.9209, 'grad_norm': 0.15695765614509583, 'learning_rate': 0.00019808666390778724, 'epoch': 0.72}\n",
      "{'loss': 1.112, 'grad_norm': 0.27812376618385315, 'learning_rate': 0.00019801374588512754, 'epoch': 0.73}\n",
      "{'loss': 0.7028, 'grad_norm': 0.2523203492164612, 'learning_rate': 0.00019793947818590594, 'epoch': 0.74}\n",
      "{'loss': 0.748, 'grad_norm': 0.11184527724981308, 'learning_rate': 0.00019786386183280938, 'epoch': 0.75}\n",
      "{'loss': 0.6813, 'grad_norm': 0.08245179057121277, 'learning_rate': 0.00019778689786709608, 'epoch': 0.76}\n",
      "{'loss': 0.9293, 'grad_norm': 0.14341041445732117, 'learning_rate': 0.00019770858734858126, 'epoch': 0.77}\n",
      "{'loss': 1.114, 'grad_norm': 1.162226676940918, 'learning_rate': 0.0001976289313556225, 'epoch': 0.78}\n",
      "{'loss': 0.8484, 'grad_norm': 0.11363644897937775, 'learning_rate': 0.00019754793098510505, 'epoch': 0.79}\n",
      "{'loss': 0.5932, 'grad_norm': 0.11386804282665253, 'learning_rate': 0.00019746558735242656, 'epoch': 0.8}\n",
      "{'loss': 0.6829, 'grad_norm': 0.11127624660730362, 'learning_rate': 0.00019738190159148178, 'epoch': 0.81}\n",
      "{'loss': 0.8978, 'grad_norm': 0.2226933240890503, 'learning_rate': 0.00019729687485464689, 'epoch': 0.82}\n",
      "{'loss': 1.1036, 'grad_norm': 0.8030156493186951, 'learning_rate': 0.00019721050831276372, 'epoch': 0.82}\n",
      "{'loss': 0.6442, 'grad_norm': 0.15042661130428314, 'learning_rate': 0.0001971228031551237, 'epoch': 0.83}\n",
      "{'loss': 0.6144, 'grad_norm': 0.14081624150276184, 'learning_rate': 0.0001970337605894511, 'epoch': 0.84}\n",
      "{'loss': 0.6926, 'grad_norm': 0.13094210624694824, 'learning_rate': 0.00019694338184188695, 'epoch': 0.85}\n",
      "{'loss': 0.8995, 'grad_norm': 0.18613041937351227, 'learning_rate': 0.0001968516681569717, 'epoch': 0.86}\n",
      "{'loss': 1.1086, 'grad_norm': 0.7637686133384705, 'learning_rate': 0.00019675862079762837, 'epoch': 0.87}\n",
      "{'loss': 0.8762, 'grad_norm': 0.1252686232328415, 'learning_rate': 0.00019666424104514493, 'epoch': 0.88}\n",
      "{'loss': 0.5759, 'grad_norm': 0.10595980286598206, 'learning_rate': 0.0001965685301991569, 'epoch': 0.89}\n",
      "{'loss': 0.6768, 'grad_norm': 0.12354572862386703, 'learning_rate': 0.00019647148957762926, 'epoch': 0.9}\n",
      "{'loss': 0.8457, 'grad_norm': 0.19207923114299774, 'learning_rate': 0.00019637312051683833, 'epoch': 0.91}\n",
      "{'loss': 1.042, 'grad_norm': 0.35490140318870544, 'learning_rate': 0.00019627342437135355, 'epoch': 0.92}\n",
      "{'loss': 0.8292, 'grad_norm': 0.08755843341350555, 'learning_rate': 0.0001961724025140185, 'epoch': 0.93}\n",
      "{'loss': 0.6678, 'grad_norm': 0.13463272154331207, 'learning_rate': 0.0001960700563359323, 'epoch': 0.93}\n",
      "{'loss': 0.5906, 'grad_norm': 0.10484824329614639, 'learning_rate': 0.00019596638724643032, 'epoch': 0.94}\n",
      "{'loss': 0.8299, 'grad_norm': 0.13454625010490417, 'learning_rate': 0.0001958613966730648, 'epoch': 0.95}\n",
      "{'loss': 1.1541, 'grad_norm': 0.572297215461731, 'learning_rate': 0.00019575508606158512, 'epoch': 0.96}\n",
      "{'loss': 0.7241, 'grad_norm': 0.09060929715633392, 'learning_rate': 0.00019564745687591803, 'epoch': 0.97}\n",
      "{'loss': 0.8817, 'grad_norm': 0.1471233367919922, 'learning_rate': 0.00019553851059814732, 'epoch': 0.98}\n",
      "{'loss': 0.8935, 'grad_norm': 0.15986619889736176, 'learning_rate': 0.00019542824872849363, 'epoch': 0.99}\n",
      "{'loss': 1.0337, 'grad_norm': 0.36289915442466736, 'learning_rate': 0.0001953166727852935, 'epoch': 1.0}\n",
      "{'loss': 0.7862, 'grad_norm': 0.09626788645982742, 'learning_rate': 0.0001952037843049788, 'epoch': 1.01}\n",
      "{'loss': 0.6099, 'grad_norm': 0.1646992415189743, 'learning_rate': 0.0001950895848420553, 'epoch': 1.02}\n",
      "{'loss': 0.6774, 'grad_norm': 0.1661912202835083, 'learning_rate': 0.0001949740759690814, 'epoch': 1.03}\n",
      "{'loss': 0.8548, 'grad_norm': 0.17087498307228088, 'learning_rate': 0.00019485725927664643, 'epoch': 1.04}\n",
      "{'loss': 0.9752, 'grad_norm': 0.725864827632904, 'learning_rate': 0.00019473913637334874, 'epoch': 1.04}\n",
      "{'loss': 0.6526, 'grad_norm': 0.13219721615314484, 'learning_rate': 0.0001946197088857736, 'epoch': 1.05}\n",
      "{'loss': 0.6788, 'grad_norm': 0.12262720614671707, 'learning_rate': 0.00019449897845847075, 'epoch': 1.06}\n",
      "{'loss': 0.758, 'grad_norm': 0.16676007211208344, 'learning_rate': 0.0001943769467539318, 'epoch': 1.07}\n",
      "{'loss': 0.9264, 'grad_norm': 0.1637645810842514, 'learning_rate': 0.00019425361545256727, 'epoch': 1.08}\n",
      "{'loss': 1.0119, 'grad_norm': 0.3514573872089386, 'learning_rate': 0.0001941289862526835, 'epoch': 1.09}\n",
      "{'loss': 0.8178, 'grad_norm': 0.11983964592218399, 'learning_rate': 0.0001940030608704593, 'epoch': 1.1}\n",
      "{'loss': 0.8228, 'grad_norm': 0.13729913532733917, 'learning_rate': 0.00019387584103992218, 'epoch': 1.11}\n",
      "{'loss': 0.6864, 'grad_norm': 0.12002410739660263, 'learning_rate': 0.00019374732851292465, 'epoch': 1.12}\n",
      "{'loss': 0.8519, 'grad_norm': 0.1731453686952591, 'learning_rate': 0.00019361752505911997, 'epoch': 1.13}\n",
      "{'loss': 0.7971, 'grad_norm': 0.5055484771728516, 'learning_rate': 0.0001934864324659378, 'epoch': 1.14}\n",
      "{'loss': 0.7295, 'grad_norm': 0.16461922228336334, 'learning_rate': 0.0001933540525385597, 'epoch': 1.15}\n",
      "{'loss': 0.5008, 'grad_norm': 0.0789175033569336, 'learning_rate': 0.00019322038709989405, 'epoch': 1.15}\n",
      "{'loss': 0.764, 'grad_norm': 0.12569674849510193, 'learning_rate': 0.00019308543799055117, 'epoch': 1.16}\n",
      "{'loss': 0.8359, 'grad_norm': 0.20806850492954254, 'learning_rate': 0.00019294920706881786, 'epoch': 1.17}\n",
      "{'loss': 0.987, 'grad_norm': 0.4219251871109009, 'learning_rate': 0.00019281169621063188, 'epoch': 1.18}\n",
      "{'loss': 0.8565, 'grad_norm': 0.1495688408613205, 'learning_rate': 0.00019267290730955595, 'epoch': 1.19}\n",
      "{'loss': 0.5739, 'grad_norm': 0.10138145834207535, 'learning_rate': 0.00019253284227675188, 'epoch': 1.2}\n",
      "{'loss': 0.7009, 'grad_norm': 0.1496867686510086, 'learning_rate': 0.00019239150304095417, 'epoch': 1.21}\n",
      "{'loss': 0.9619, 'grad_norm': 0.20607571303844452, 'learning_rate': 0.00019224889154844342, 'epoch': 1.22}\n",
      "{'loss': 1.0494, 'grad_norm': 0.39655911922454834, 'learning_rate': 0.0001921050097630196, 'epoch': 1.23}\n",
      "{'loss': 0.6316, 'grad_norm': 0.16414746642112732, 'learning_rate': 0.00019195985966597494, 'epoch': 1.24}\n",
      "{'loss': 0.6804, 'grad_norm': 0.13932327926158905, 'learning_rate': 0.00019181344325606666, 'epoch': 1.25}\n",
      "{'loss': 0.6556, 'grad_norm': 0.13880953192710876, 'learning_rate': 0.00019166576254948952, 'epoch': 1.26}\n",
      "{'loss': 0.9115, 'grad_norm': 0.19070227444171906, 'learning_rate': 0.00019151681957984792, 'epoch': 1.26}\n",
      "{'loss': 0.9458, 'grad_norm': 0.4961719214916229, 'learning_rate': 0.00019136661639812798, 'epoch': 1.27}\n",
      "{'loss': 0.6726, 'grad_norm': 0.1347179263830185, 'learning_rate': 0.0001912151550726694, 'epoch': 1.28}\n",
      "{'loss': 0.6484, 'grad_norm': 0.09832090884447098, 'learning_rate': 0.0001910624376891367, 'epoch': 1.29}\n",
      "{'loss': 0.8032, 'grad_norm': 0.16378656029701233, 'learning_rate': 0.00019090846635049085, 'epoch': 1.3}\n",
      "{'loss': 0.8819, 'grad_norm': 0.23054270446300507, 'learning_rate': 0.00019075324317695995, 'epoch': 1.31}\n",
      "{'loss': 0.8801, 'grad_norm': 0.5117153525352478, 'learning_rate': 0.00019059677030601035, 'epoch': 1.32}\n",
      "{'loss': 0.6771, 'grad_norm': 0.1342538595199585, 'learning_rate': 0.00019043904989231701, 'epoch': 1.33}\n",
      "{'loss': 0.7938, 'grad_norm': 0.11082575470209122, 'learning_rate': 0.000190280084107734, 'epoch': 1.34}\n",
      "{'loss': 0.4892, 'grad_norm': 0.12353023886680603, 'learning_rate': 0.00019011987514126432, 'epoch': 1.35}\n",
      "{'loss': 0.7059, 'grad_norm': 0.16103532910346985, 'learning_rate': 0.00018995842519903012, 'epoch': 1.36}\n",
      "{'loss': 1.1017, 'grad_norm': 0.5067449808120728, 'learning_rate': 0.00018979573650424193, 'epoch': 1.37}\n",
      "{'loss': 0.7704, 'grad_norm': 0.14309298992156982, 'learning_rate': 0.0001896318112971685, 'epoch': 1.37}\n",
      "{'loss': 0.6071, 'grad_norm': 0.11551208794116974, 'learning_rate': 0.00018946665183510546, 'epoch': 1.38}\n",
      "{'loss': 0.7573, 'grad_norm': 0.1600361168384552, 'learning_rate': 0.0001893002603923446, 'epoch': 1.39}\n",
      "{'loss': 0.7369, 'grad_norm': 0.19851213693618774, 'learning_rate': 0.00018913263926014238, 'epoch': 1.4}\n",
      "{'loss': 0.9556, 'grad_norm': 0.32583460211753845, 'learning_rate': 0.00018896379074668848, 'epoch': 1.41}\n",
      "{'loss': 0.7744, 'grad_norm': 0.1127820760011673, 'learning_rate': 0.00018879371717707395, 'epoch': 1.42}\n",
      "{'loss': 0.6459, 'grad_norm': 0.1376914083957672, 'learning_rate': 0.0001886224208932591, 'epoch': 1.43}\n",
      "{'loss': 0.6215, 'grad_norm': 0.10363025218248367, 'learning_rate': 0.00018844990425404148, 'epoch': 1.44}\n",
      "{'loss': 0.8075, 'grad_norm': 0.19153228402137756, 'learning_rate': 0.00018827616963502326, 'epoch': 1.45}\n",
      "{'loss': 0.9552, 'grad_norm': 0.3967684805393219, 'learning_rate': 0.00018810121942857845, 'epoch': 1.46}\n",
      "{'loss': 0.893, 'grad_norm': 0.19492191076278687, 'learning_rate': 0.00018792505604382014, 'epoch': 1.47}\n",
      "{'loss': 0.8373, 'grad_norm': 0.1771751046180725, 'learning_rate': 0.00018774768190656712, 'epoch': 1.48}\n",
      "{'loss': 0.6428, 'grad_norm': 0.12347359955310822, 'learning_rate': 0.00018756909945931064, 'epoch': 1.48}\n",
      "{'loss': 0.9001, 'grad_norm': 0.16563807427883148, 'learning_rate': 0.00018738931116118074, 'epoch': 1.49}\n",
      "{'loss': 1.0099, 'grad_norm': 0.6185562014579773, 'learning_rate': 0.00018720831948791232, 'epoch': 1.5}\n",
      "{'loss': 0.6748, 'grad_norm': 0.1491692215204239, 'learning_rate': 0.00018702612693181106, 'epoch': 1.51}\n",
      "{'loss': 0.6114, 'grad_norm': 0.08572675287723541, 'learning_rate': 0.00018684273600171918, 'epoch': 1.52}\n",
      "{'loss': 0.6744, 'grad_norm': 0.15364691615104675, 'learning_rate': 0.00018665814922298087, 'epoch': 1.53}\n",
      "{'loss': 0.8025, 'grad_norm': 0.1770668774843216, 'learning_rate': 0.0001864723691374074, 'epoch': 1.54}\n",
      "{'loss': 0.9995, 'grad_norm': 0.2892688810825348, 'learning_rate': 0.00018628539830324229, 'epoch': 1.55}\n",
      "{'loss': 0.7444, 'grad_norm': 0.1201941967010498, 'learning_rate': 0.00018609723929512598, 'epoch': 1.56}\n",
      "{'loss': 0.7326, 'grad_norm': 0.15446551144123077, 'learning_rate': 0.00018590789470406034, 'epoch': 1.57}\n",
      "{'loss': 0.7324, 'grad_norm': 0.10798589885234833, 'learning_rate': 0.00018571736713737314, 'epoch': 1.58}\n",
      "{'loss': 0.7757, 'grad_norm': 0.20749083161354065, 'learning_rate': 0.00018552565921868194, 'epoch': 1.59}\n",
      "{'loss': 0.9314, 'grad_norm': 0.5908108949661255, 'learning_rate': 0.0001853327735878582, 'epoch': 1.59}\n",
      "{'loss': 0.6509, 'grad_norm': 0.09103362262248993, 'learning_rate': 0.00018513871290099074, 'epoch': 1.6}\n",
      "{'loss': 0.6866, 'grad_norm': 0.12459768354892731, 'learning_rate': 0.00018494347983034922, 'epoch': 1.61}\n",
      "{'loss': 0.6985, 'grad_norm': 0.11872580647468567, 'learning_rate': 0.00018474707706434733, 'epoch': 1.62}\n",
      "{'loss': 0.7942, 'grad_norm': 0.18185074627399445, 'learning_rate': 0.00018454950730750587, 'epoch': 1.63}\n",
      "{'loss': 0.9059, 'grad_norm': 0.49338191747665405, 'learning_rate': 0.00018435077328041538, 'epoch': 1.64}\n",
      "{'loss': 0.7061, 'grad_norm': 0.10394886881113052, 'learning_rate': 0.0001841508777196987, 'epoch': 1.65}\n",
      "{'loss': 0.6512, 'grad_norm': 0.07428690791130066, 'learning_rate': 0.00018394982337797337, 'epoch': 1.66}\n",
      "{'loss': 0.5877, 'grad_norm': 0.09902969747781754, 'learning_rate': 0.0001837476130238136, 'epoch': 1.67}\n",
      "{'loss': 0.7666, 'grad_norm': 0.15097051858901978, 'learning_rate': 0.0001835442494417123, 'epoch': 1.68}\n",
      "{'loss': 0.913, 'grad_norm': 0.4832516014575958, 'learning_rate': 0.00018333973543204255, 'epoch': 1.69}\n",
      "{'loss': 0.7801, 'grad_norm': 0.14916113018989563, 'learning_rate': 0.00018313407381101923, 'epoch': 1.7}\n",
      "{'loss': 0.7982, 'grad_norm': 0.14018374681472778, 'learning_rate': 0.00018292726741066007, 'epoch': 1.7}\n",
      "{'loss': 0.7487, 'grad_norm': 0.1397341638803482, 'learning_rate': 0.00018271931907874677, 'epoch': 1.71}\n",
      "{'loss': 0.8912, 'grad_norm': 0.21250593662261963, 'learning_rate': 0.00018251023167878576, 'epoch': 1.72}\n",
      "{'loss': 0.9918, 'grad_norm': 0.38241514563560486, 'learning_rate': 0.00018230000808996873, 'epoch': 1.73}\n",
      "{'loss': 0.8062, 'grad_norm': 0.11398215591907501, 'learning_rate': 0.000182088651207133, 'epoch': 1.74}\n",
      "{'loss': 0.6764, 'grad_norm': 0.13579395413398743, 'learning_rate': 0.00018187616394072168, 'epoch': 1.75}\n",
      "{'loss': 0.6838, 'grad_norm': 0.1192527562379837, 'learning_rate': 0.00018166254921674359, 'epoch': 1.76}\n",
      "{'loss': 0.6951, 'grad_norm': 0.22842997312545776, 'learning_rate': 0.00018144780997673293, 'epoch': 1.77}\n",
      "{'loss': 1.0206, 'grad_norm': 0.42825186252593994, 'learning_rate': 0.00018123194917770875, 'epoch': 1.78}\n",
      "{'loss': 0.7073, 'grad_norm': 0.1776118129491806, 'learning_rate': 0.00018101496979213441, 'epoch': 1.79}\n",
      "{'loss': 0.6565, 'grad_norm': 0.11402549594640732, 'learning_rate': 0.00018079687480787642, 'epoch': 1.8}\n",
      "{'loss': 0.7782, 'grad_norm': 0.1483936756849289, 'learning_rate': 0.00018057766722816342, 'epoch': 1.81}\n",
      "{'loss': 0.7828, 'grad_norm': 0.18942834436893463, 'learning_rate': 0.00018035735007154475, 'epoch': 1.81}\n",
      "{'loss': 0.9979, 'grad_norm': 0.5870315432548523, 'learning_rate': 0.00018013592637184904, 'epoch': 1.82}\n",
      "{'loss': 0.7693, 'grad_norm': 0.19502517580986023, 'learning_rate': 0.00017991339917814225, 'epoch': 1.83}\n",
      "{'loss': 0.7515, 'grad_norm': 0.1178046390414238, 'learning_rate': 0.00017968977155468575, 'epoch': 1.84}\n",
      "{'loss': 0.5399, 'grad_norm': 0.11511686444282532, 'learning_rate': 0.00017946504658089422, 'epoch': 1.85}\n",
      "{'loss': 0.7395, 'grad_norm': 0.17267750203609467, 'learning_rate': 0.00017923922735129302, 'epoch': 1.86}\n",
      "{'loss': 0.9467, 'grad_norm': 0.707038164138794, 'learning_rate': 0.00017901231697547583, 'epoch': 1.87}\n",
      "{'loss': 0.7001, 'grad_norm': 0.12191541492938995, 'learning_rate': 0.0001787843185780617, 'epoch': 1.88}\n",
      "{'loss': 0.8198, 'grad_norm': 0.15340761840343475, 'learning_rate': 0.00017855523529865198, 'epoch': 1.89}\n",
      "{'loss': 0.5931, 'grad_norm': 0.12135650962591171, 'learning_rate': 0.00017832507029178724, 'epoch': 1.9}\n",
      "{'loss': 0.7875, 'grad_norm': 0.26190316677093506, 'learning_rate': 0.00017809382672690367, 'epoch': 1.91}\n",
      "{'loss': 0.9206, 'grad_norm': 4.23806095123291, 'learning_rate': 0.00017786150778828952, 'epoch': 1.92}\n",
      "{'loss': 0.7272, 'grad_norm': 0.1370495706796646, 'learning_rate': 0.00017762811667504122, 'epoch': 1.92}\n",
      "{'loss': 0.6751, 'grad_norm': 0.15797464549541473, 'learning_rate': 0.0001773936566010194, 'epoch': 1.93}\n",
      "{'loss': 0.7108, 'grad_norm': 0.09409843385219574, 'learning_rate': 0.00017715813079480453, 'epoch': 1.94}\n",
      "{'loss': 0.937, 'grad_norm': 0.20049436390399933, 'learning_rate': 0.00017692154249965248, 'epoch': 1.95}\n",
      "{'loss': 0.9315, 'grad_norm': 0.6007035970687866, 'learning_rate': 0.00017668389497344997, 'epoch': 1.96}\n",
      "{'loss': 0.7235, 'grad_norm': 0.13160249590873718, 'learning_rate': 0.00017644519148866955, 'epoch': 1.97}\n",
      "{'loss': 0.7984, 'grad_norm': 0.12678571045398712, 'learning_rate': 0.00017620543533232468, 'epoch': 1.98}\n",
      "{'loss': 0.7983, 'grad_norm': 0.17211885750293732, 'learning_rate': 0.00017596462980592432, 'epoch': 1.99}\n",
      "{'loss': 0.9146, 'grad_norm': 0.3618796467781067, 'learning_rate': 0.00017572277822542763, 'epoch': 2.0}\n",
      "{'loss': 0.6579, 'grad_norm': 0.1422632336616516, 'learning_rate': 0.00017547988392119818, 'epoch': 2.01}\n",
      "{'loss': 0.6813, 'grad_norm': 0.13374458253383636, 'learning_rate': 0.00017523595023795813, 'epoch': 2.02}\n",
      "{'loss': 0.8171, 'grad_norm': 0.1385837197303772, 'learning_rate': 0.00017499098053474224, 'epoch': 2.03}\n",
      "{'loss': 0.7516, 'grad_norm': 0.1544596403837204, 'learning_rate': 0.00017474497818485146, 'epoch': 2.03}\n",
      "{'loss': 0.7787, 'grad_norm': 0.30894017219543457, 'learning_rate': 0.00017449794657580664, 'epoch': 2.04}\n",
      "{'loss': 0.6436, 'grad_norm': 0.1267388015985489, 'learning_rate': 0.0001742498891093018, 'epoch': 2.05}\n",
      "{'loss': 0.5172, 'grad_norm': 0.122282974421978, 'learning_rate': 0.0001740008092011573, 'epoch': 2.06}\n",
      "{'loss': 0.6793, 'grad_norm': 0.14812147617340088, 'learning_rate': 0.00017375071028127276, 'epoch': 2.07}\n",
      "{'loss': 0.8737, 'grad_norm': 0.1782035082578659, 'learning_rate': 0.00017349959579358003, 'epoch': 2.08}\n",
      "{'loss': 0.9056, 'grad_norm': 0.5237563848495483, 'learning_rate': 0.00017324746919599536, 'epoch': 2.09}\n",
      "{'loss': 0.6132, 'grad_norm': 0.13720466196537018, 'learning_rate': 0.00017299433396037223, 'epoch': 2.1}\n",
      "{'loss': 0.6282, 'grad_norm': 0.1341201215982437, 'learning_rate': 0.00017274019357245334, 'epoch': 2.11}\n",
      "{'loss': 0.5763, 'grad_norm': 0.15404671430587769, 'learning_rate': 0.0001724850515318225, 'epoch': 2.12}\n",
      "{'loss': 0.724, 'grad_norm': 0.20048624277114868, 'learning_rate': 0.0001722289113518567, 'epoch': 2.13}\n",
      "{'loss': 0.8017, 'grad_norm': 0.3807910680770874, 'learning_rate': 0.00017197177655967744, 'epoch': 2.14}\n",
      "{'loss': 0.7877, 'grad_norm': 0.1541931927204132, 'learning_rate': 0.0001717136506961024, 'epoch': 2.14}\n",
      "{'loss': 0.5893, 'grad_norm': 0.09817639738321304, 'learning_rate': 0.00017145453731559659, 'epoch': 2.15}\n",
      "{'loss': 0.7597, 'grad_norm': 0.15620207786560059, 'learning_rate': 0.00017119443998622337, 'epoch': 2.16}\n",
      "{'loss': 0.6683, 'grad_norm': 0.18693211674690247, 'learning_rate': 0.00017093336228959536, 'epoch': 2.17}\n",
      "{'loss': 0.8321, 'grad_norm': 0.5867390036582947, 'learning_rate': 0.00017067130782082507, 'epoch': 2.18}\n",
      "{'loss': 0.7035, 'grad_norm': 0.1521805226802826, 'learning_rate': 0.00017040828018847557, 'epoch': 2.19}\n",
      "{'loss': 0.6646, 'grad_norm': 0.16049620509147644, 'learning_rate': 0.00017014428301451046, 'epoch': 2.2}\n",
      "{'loss': 0.4916, 'grad_norm': 0.16878755390644073, 'learning_rate': 0.00016987931993424438, 'epoch': 2.21}\n",
      "{'loss': 0.7534, 'grad_norm': 0.20971161127090454, 'learning_rate': 0.0001696133945962927, 'epoch': 2.22}\n",
      "{'loss': 0.886, 'grad_norm': 0.4733705520629883, 'learning_rate': 0.00016934651066252126, 'epoch': 2.23}\n",
      "{'loss': 0.7236, 'grad_norm': 0.15546764433383942, 'learning_rate': 0.0001690786718079962, 'epoch': 2.24}\n",
      "{'loss': 0.6556, 'grad_norm': 0.12679313123226166, 'learning_rate': 0.00016880988172093302, 'epoch': 2.25}\n",
      "{'loss': 0.6414, 'grad_norm': 0.1413196474313736, 'learning_rate': 0.0001685401441026461, 'epoch': 2.25}\n",
      "{'loss': 0.8216, 'grad_norm': 0.21105116605758667, 'learning_rate': 0.00016826946266749752, 'epoch': 2.26}\n",
      "{'loss': 0.8074, 'grad_norm': 0.3272751271724701, 'learning_rate': 0.00016799784114284594, 'epoch': 2.27}\n",
      "{'loss': 0.6908, 'grad_norm': 0.183528333902359, 'learning_rate': 0.00016772528326899536, 'epoch': 2.28}\n",
      "{'loss': 0.6023, 'grad_norm': 0.18450719118118286, 'learning_rate': 0.0001674517927991436, 'epoch': 2.29}\n",
      "{'loss': 0.659, 'grad_norm': 0.1821373701095581, 'learning_rate': 0.00016717737349933055, 'epoch': 2.3}\n",
      "{'loss': 0.7559, 'grad_norm': 0.18929477035999298, 'learning_rate': 0.00016690202914838636, 'epoch': 2.31}\n",
      "{'loss': 0.7659, 'grad_norm': 0.3527553379535675, 'learning_rate': 0.0001666257635378793, 'epoch': 2.32}\n",
      "{'loss': 0.6719, 'grad_norm': 0.15185880661010742, 'learning_rate': 0.00016634858047206378, 'epoch': 2.33}\n",
      "{'loss': 0.7807, 'grad_norm': 0.14480170607566833, 'learning_rate': 0.00016607048376782784, 'epoch': 2.34}\n",
      "{'loss': 0.6106, 'grad_norm': 0.10445864498615265, 'learning_rate': 0.00016579147725464036, 'epoch': 2.35}\n",
      "{'loss': 0.8021, 'grad_norm': 0.1893794685602188, 'learning_rate': 0.00016551156477449878, 'epoch': 2.36}\n",
      "{'loss': 0.8146, 'grad_norm': 0.38846972584724426, 'learning_rate': 0.00016523075018187586, 'epoch': 2.36}\n",
      "{'loss': 0.6839, 'grad_norm': 0.16918881237506866, 'learning_rate': 0.00016494903734366663, 'epoch': 2.37}\n",
      "{'loss': 0.7767, 'grad_norm': 0.19283759593963623, 'learning_rate': 0.0001646664301391354, 'epoch': 2.38}\n",
      "{'loss': 0.6766, 'grad_norm': 0.1481121927499771, 'learning_rate': 0.00016438293245986193, 'epoch': 2.39}\n",
      "{'loss': 0.8712, 'grad_norm': 0.17060863971710205, 'learning_rate': 0.0001640985482096882, 'epoch': 2.4}\n",
      "{'loss': 0.7727, 'grad_norm': 0.4023973345756531, 'learning_rate': 0.00016381328130466452, 'epoch': 2.41}\n",
      "{'loss': 0.7216, 'grad_norm': 0.1575753390789032, 'learning_rate': 0.00016352713567299552, 'epoch': 2.42}\n",
      "{'loss': 0.683, 'grad_norm': 0.11579372733831406, 'learning_rate': 0.0001632401152549863, 'epoch': 2.43}\n",
      "{'loss': 0.5882, 'grad_norm': 0.11707299202680588, 'learning_rate': 0.0001629522240029878, 'epoch': 2.44}\n",
      "{'loss': 0.7638, 'grad_norm': 0.20371103286743164, 'learning_rate': 0.0001626634658813427, 'epoch': 2.45}\n",
      "{'loss': 0.7982, 'grad_norm': 0.3163855969905853, 'learning_rate': 0.00016237384486633078, 'epoch': 2.46}\n",
      "{'loss': 0.6065, 'grad_norm': 0.15596063435077667, 'learning_rate': 0.00016208336494611392, 'epoch': 2.47}\n",
      "{'loss': 0.5983, 'grad_norm': 0.1485322117805481, 'learning_rate': 0.0001617920301206816, 'epoch': 2.47}\n",
      "{'loss': 0.6403, 'grad_norm': 0.16528302431106567, 'learning_rate': 0.00016149984440179537, 'epoch': 2.48}\n",
      "{'loss': 0.7057, 'grad_norm': 0.18507914245128632, 'learning_rate': 0.0001612068118129339, 'epoch': 2.49}\n",
      "{'loss': 0.8664, 'grad_norm': 0.3313150405883789, 'learning_rate': 0.00016091293638923756, 'epoch': 2.5}\n",
      "{'loss': 0.6756, 'grad_norm': 0.1848055124282837, 'learning_rate': 0.0001606182221774527, 'epoch': 2.51}\n",
      "{'loss': 0.5741, 'grad_norm': 0.163276806473732, 'learning_rate': 0.00016032267323587602, 'epoch': 2.52}\n",
      "{'loss': 0.6392, 'grad_norm': 0.15727970004081726, 'learning_rate': 0.00016002629363429878, 'epoch': 2.53}\n",
      "{'loss': 0.9421, 'grad_norm': 0.21123115718364716, 'learning_rate': 0.00015972908745395052, 'epoch': 2.54}\n",
      "{'loss': 0.7888, 'grad_norm': 0.37929755449295044, 'learning_rate': 0.00015943105878744307, 'epoch': 2.55}\n",
      "{'loss': 0.7174, 'grad_norm': 0.1624019742012024, 'learning_rate': 0.0001591322117387142, 'epoch': 2.56}\n",
      "{'loss': 0.5637, 'grad_norm': 0.21887581050395966, 'learning_rate': 0.0001588325504229708, 'epoch': 2.57}\n",
      "{'loss': 0.6835, 'grad_norm': 0.19926714897155762, 'learning_rate': 0.00015853207896663276, 'epoch': 2.58}\n",
      "{'loss': 0.8163, 'grad_norm': 0.261250376701355, 'learning_rate': 0.00015823080150727557, 'epoch': 2.58}\n",
      "{'loss': 0.9028, 'grad_norm': 0.38179007172584534, 'learning_rate': 0.0001579287221935737, 'epoch': 2.59}\n",
      "{'loss': 0.6291, 'grad_norm': 0.1743483990430832, 'learning_rate': 0.00015762584518524346, 'epoch': 2.6}\n",
      "{'loss': 0.5903, 'grad_norm': 0.13269928097724915, 'learning_rate': 0.00015732217465298546, 'epoch': 2.61}\n",
      "{'loss': 0.6298, 'grad_norm': 0.1710110753774643, 'learning_rate': 0.00015701771477842752, 'epoch': 2.62}\n",
      "{'loss': 0.7118, 'grad_norm': 0.21814113855361938, 'learning_rate': 0.00015671246975406685, 'epoch': 2.63}\n",
      "{'loss': 0.9141, 'grad_norm': 0.3330478072166443, 'learning_rate': 0.00015640644378321235, 'epoch': 2.64}\n",
      "{'loss': 0.6812, 'grad_norm': 0.13603894412517548, 'learning_rate': 0.00015609964107992684, 'epoch': 2.65}\n",
      "{'loss': 0.6807, 'grad_norm': 0.17006409168243408, 'learning_rate': 0.00015579206586896897, 'epoch': 2.66}\n",
      "{'loss': 0.5457, 'grad_norm': 0.11347730457782745, 'learning_rate': 0.00015548372238573496, 'epoch': 2.67}\n",
      "{'loss': 0.7374, 'grad_norm': 0.18557223677635193, 'learning_rate': 0.00015517461487620047, 'epoch': 2.68}\n",
      "{'loss': 0.865, 'grad_norm': 0.4605032801628113, 'learning_rate': 0.00015486474759686183, 'epoch': 2.69}\n",
      "{'loss': 0.7247, 'grad_norm': 0.18549133837223053, 'learning_rate': 0.00015455412481467782, 'epoch': 2.69}\n",
      "{'loss': 0.6262, 'grad_norm': 0.10547151416540146, 'learning_rate': 0.00015424275080701055, 'epoch': 2.7}\n",
      "{'loss': 0.6517, 'grad_norm': 0.1065351590514183, 'learning_rate': 0.00015393062986156683, 'epoch': 2.71}\n",
      "{'loss': 0.7657, 'grad_norm': 0.1687038391828537, 'learning_rate': 0.0001536177662763389, 'epoch': 2.72}\n",
      "{'loss': 0.8509, 'grad_norm': 0.3470120429992676, 'learning_rate': 0.00015330416435954547, 'epoch': 2.73}\n",
      "{'loss': 0.5819, 'grad_norm': 0.2162933498620987, 'learning_rate': 0.00015298982842957214, 'epoch': 2.74}\n",
      "{'loss': 0.8689, 'grad_norm': 0.1474369466304779, 'learning_rate': 0.00015267476281491225, 'epoch': 2.75}\n",
      "{'loss': 0.6084, 'grad_norm': 0.12905849516391754, 'learning_rate': 0.0001523589718541069, 'epoch': 2.76}\n",
      "{'loss': 0.7803, 'grad_norm': 0.2723276913166046, 'learning_rate': 0.00015204245989568565, 'epoch': 2.77}\n",
      "{'loss': 0.9092, 'grad_norm': 0.3847407102584839, 'learning_rate': 0.00015172523129810614, 'epoch': 2.78}\n",
      "{'loss': 0.7307, 'grad_norm': 0.20340491831302643, 'learning_rate': 0.00015140729042969453, 'epoch': 2.79}\n",
      "{'loss': 0.5179, 'grad_norm': 0.07774434983730316, 'learning_rate': 0.00015108864166858506, 'epoch': 2.8}\n",
      "{'loss': 0.5457, 'grad_norm': 0.16635654866695404, 'learning_rate': 0.00015076928940265986, 'epoch': 2.8}\n",
      "{'loss': 0.8231, 'grad_norm': 0.21407219767570496, 'learning_rate': 0.00015044923802948854, 'epoch': 2.81}\n",
      "{'loss': 0.7999, 'grad_norm': 0.37826675176620483, 'learning_rate': 0.0001501284919562675, 'epoch': 2.82}\n",
      "{'loss': 0.6255, 'grad_norm': 0.18049480020999908, 'learning_rate': 0.00014980705559975956, 'epoch': 2.83}\n",
      "{'loss': 0.5841, 'grad_norm': 0.16438964009284973, 'learning_rate': 0.00014948493338623275, 'epoch': 2.84}\n",
      "{'loss': 0.5979, 'grad_norm': 0.11731477826833725, 'learning_rate': 0.00014916212975139964, 'epoch': 2.85}\n",
      "{'loss': 0.688, 'grad_norm': 0.24599403142929077, 'learning_rate': 0.0001488386491403561, 'epoch': 2.86}\n",
      "{'loss': 0.8018, 'grad_norm': 0.44795849919319153, 'learning_rate': 0.00014851449600752025, 'epoch': 2.87}\n",
      "{'loss': 0.7916, 'grad_norm': 0.1860845685005188, 'learning_rate': 0.00014818967481657085, 'epoch': 2.88}\n",
      "{'loss': 0.7523, 'grad_norm': 0.17781038582324982, 'learning_rate': 0.0001478641900403862, 'epoch': 2.89}\n",
      "{'loss': 0.5783, 'grad_norm': 0.1794252097606659, 'learning_rate': 0.00014753804616098225, 'epoch': 2.9}\n",
      "{'loss': 0.8047, 'grad_norm': 0.23281724750995636, 'learning_rate': 0.0001472112476694509, 'epoch': 2.91}\n",
      "{'loss': 0.9037, 'grad_norm': 0.33159536123275757, 'learning_rate': 0.0001468837990658985, 'epoch': 2.91}\n",
      "{'loss': 0.7551, 'grad_norm': 0.1482650190591812, 'learning_rate': 0.0001465557048593833, 'epoch': 2.92}\n",
      "{'loss': 0.7035, 'grad_norm': 0.18239188194274902, 'learning_rate': 0.000146226969567854, 'epoch': 2.93}\n",
      "{'loss': 0.5086, 'grad_norm': 0.18567390739917755, 'learning_rate': 0.0001458975977180869, 'epoch': 2.94}\n",
      "{'loss': 0.8235, 'grad_norm': 0.2241569459438324, 'learning_rate': 0.00014556759384562416, 'epoch': 2.95}\n",
      "{'loss': 0.7913, 'grad_norm': 0.4263581335544586, 'learning_rate': 0.00014523696249471094, 'epoch': 2.96}\n",
      "{'loss': 0.7159, 'grad_norm': 0.1566641926765442, 'learning_rate': 0.00014490570821823297, 'epoch': 2.97}\n",
      "{'loss': 0.4798, 'grad_norm': 0.10393090546131134, 'learning_rate': 0.00014457383557765386, 'epoch': 2.98}\n",
      "{'loss': 0.6745, 'grad_norm': 0.2800411283969879, 'learning_rate': 0.00014424134914295216, 'epoch': 2.99}\n",
      "{'loss': 0.7889, 'grad_norm': 0.4192102253437042, 'learning_rate': 0.0001439082534925587, 'epoch': 3.0}\n",
      "{'loss': 0.7373, 'grad_norm': 0.1178894117474556, 'learning_rate': 0.00014357455321329328, 'epoch': 3.01}\n",
      "{'loss': 0.6797, 'grad_norm': 0.18979166448116302, 'learning_rate': 0.00014324025290030158, 'epoch': 3.02}\n",
      "{'loss': 0.4079, 'grad_norm': 0.14080286026000977, 'learning_rate': 0.000142905357156992, 'epoch': 3.02}\n",
      "{'loss': 0.745, 'grad_norm': 0.2760296165943146, 'learning_rate': 0.0001425698705949722, 'epoch': 3.03}\n",
      "{'loss': 0.6809, 'grad_norm': 0.38505178689956665, 'learning_rate': 0.0001422337978339854, 'epoch': 3.04}\n",
      "{'loss': 0.5473, 'grad_norm': 0.12774775922298431, 'learning_rate': 0.0001418971435018471, 'epoch': 3.05}\n",
      "{'loss': 0.8193, 'grad_norm': 0.1755543053150177, 'learning_rate': 0.00014155991223438122, 'epoch': 3.06}\n",
      "{'loss': 0.6003, 'grad_norm': 0.18460087478160858, 'learning_rate': 0.00014122210867535613, 'epoch': 3.07}\n",
      "{'loss': 0.7006, 'grad_norm': 0.21501092612743378, 'learning_rate': 0.00014088373747642085, 'epoch': 3.08}\n",
      "{'loss': 0.7571, 'grad_norm': 0.4420950412750244, 'learning_rate': 0.000140544803297041, 'epoch': 3.09}\n",
      "{'loss': 0.722, 'grad_norm': 0.18783314526081085, 'learning_rate': 0.00014020531080443453, 'epoch': 3.1}\n",
      "{'loss': 0.5811, 'grad_norm': 0.13922978937625885, 'learning_rate': 0.0001398652646735076, 'epoch': 3.11}\n",
      "{'loss': 0.6054, 'grad_norm': 0.12220755219459534, 'learning_rate': 0.00013952466958679004, 'epoch': 3.12}\n",
      "{'loss': 0.6697, 'grad_norm': 0.2398238629102707, 'learning_rate': 0.00013918353023437103, 'epoch': 3.13}\n",
      "{'loss': 0.6771, 'grad_norm': 0.3413471281528473, 'learning_rate': 0.0001388418513138344, 'epoch': 3.13}\n",
      "{'loss': 0.6536, 'grad_norm': 0.21107245981693268, 'learning_rate': 0.00013849963753019394, 'epoch': 3.14}\n",
      "{'loss': 0.7707, 'grad_norm': 0.1271151602268219, 'learning_rate': 0.0001381568935958288, 'epoch': 3.15}\n",
      "{'loss': 0.5828, 'grad_norm': 0.11952345818281174, 'learning_rate': 0.00013781362423041823, 'epoch': 3.16}\n",
      "{'loss': 0.7288, 'grad_norm': 0.20085090398788452, 'learning_rate': 0.00013746983416087707, 'epoch': 3.17}\n",
      "{'loss': 0.6712, 'grad_norm': 0.27088436484336853, 'learning_rate': 0.00013712552812129015, 'epoch': 3.18}\n",
      "{'loss': 0.5283, 'grad_norm': 0.15936151146888733, 'learning_rate': 0.00013678071085284756, 'epoch': 3.19}\n",
      "{'loss': 0.6282, 'grad_norm': 0.18909649550914764, 'learning_rate': 0.000136435387103779, 'epoch': 3.2}\n",
      "{'loss': 0.6144, 'grad_norm': 0.1778535097837448, 'learning_rate': 0.00013608956162928867, 'epoch': 3.21}\n",
      "{'loss': 0.6837, 'grad_norm': 0.2166128009557724, 'learning_rate': 0.00013574323919148955, 'epoch': 3.22}\n",
      "{'loss': 0.6417, 'grad_norm': 0.4327751398086548, 'learning_rate': 0.00013539642455933802, 'epoch': 3.23}\n",
      "{'loss': 0.5042, 'grad_norm': 0.1648964136838913, 'learning_rate': 0.0001350491225085681, 'epoch': 3.24}\n",
      "{'loss': 0.4836, 'grad_norm': 0.18871866166591644, 'learning_rate': 0.00013470133782162572, 'epoch': 3.24}\n",
      "{'loss': 0.607, 'grad_norm': 0.19838011264801025, 'learning_rate': 0.00013435307528760282, 'epoch': 3.25}\n",
      "{'loss': 0.7014, 'grad_norm': 0.22732611000537872, 'learning_rate': 0.00013400433970217135, 'epoch': 3.26}\n",
      "{'loss': 0.7205, 'grad_norm': 0.47687843441963196, 'learning_rate': 0.00013365513586751753, 'epoch': 3.27}\n",
      "{'loss': 0.579, 'grad_norm': 0.09328503161668777, 'learning_rate': 0.00013330546859227524, 'epoch': 3.28}\n",
      "{'loss': 0.6655, 'grad_norm': 0.21888118982315063, 'learning_rate': 0.00013295534269146023, 'epoch': 3.29}\n",
      "{'loss': 0.7096, 'grad_norm': 0.2242530882358551, 'learning_rate': 0.0001326047629864036, 'epoch': 3.3}\n",
      "{'loss': 0.6733, 'grad_norm': 0.22432108223438263, 'learning_rate': 0.00013225373430468545, 'epoch': 3.31}\n",
      "{'loss': 0.7284, 'grad_norm': 0.5234481692314148, 'learning_rate': 0.0001319022614800685, 'epoch': 3.32}\n",
      "{'loss': 0.5578, 'grad_norm': 0.22818589210510254, 'learning_rate': 0.00013155034935243131, 'epoch': 3.33}\n",
      "{'loss': 0.5835, 'grad_norm': 0.22012656927108765, 'learning_rate': 0.00013119800276770188, 'epoch': 3.34}\n",
      "{'loss': 0.6758, 'grad_norm': 0.16761842370033264, 'learning_rate': 0.00013084522657779067, 'epoch': 3.35}\n",
      "{'loss': 0.6446, 'grad_norm': 0.2622969150543213, 'learning_rate': 0.00013049202564052408, 'epoch': 3.35}\n",
      "{'loss': 0.8296, 'grad_norm': 0.37652522325515747, 'learning_rate': 0.0001301384048195773, 'epoch': 3.36}\n",
      "{'loss': 0.4869, 'grad_norm': 0.13885223865509033, 'learning_rate': 0.00012978436898440746, 'epoch': 3.37}\n",
      "{'loss': 0.497, 'grad_norm': 0.109342060983181, 'learning_rate': 0.00012942992301018656, 'epoch': 3.38}\n",
      "{'loss': 0.5558, 'grad_norm': 0.1949828416109085, 'learning_rate': 0.0001290750717777343, 'epoch': 3.39}\n",
      "{'loss': 0.719, 'grad_norm': 0.23972755670547485, 'learning_rate': 0.00012871982017345098, 'epoch': 3.4}\n",
      "{'loss': 0.8146, 'grad_norm': 0.3895975351333618, 'learning_rate': 0.00012836417308924997, 'epoch': 3.41}\n",
      "{'loss': 0.6076, 'grad_norm': 0.18628130853176117, 'learning_rate': 0.00012800813542249072, 'epoch': 3.42}\n",
      "{'loss': 0.6726, 'grad_norm': 0.2168419063091278, 'learning_rate': 0.0001276517120759109, 'epoch': 3.43}\n",
      "{'loss': 0.3964, 'grad_norm': 0.17671862244606018, 'learning_rate': 0.0001272949079575593, 'epoch': 3.44}\n",
      "{'loss': 0.7017, 'grad_norm': 0.2223624289035797, 'learning_rate': 0.00012693772798072784, 'epoch': 3.45}\n",
      "{'loss': 0.6726, 'grad_norm': 0.30925655364990234, 'learning_rate': 0.0001265801770638843, 'epoch': 3.46}\n",
      "{'loss': 0.6606, 'grad_norm': 0.19548068940639496, 'learning_rate': 0.00012622226013060428, 'epoch': 3.46}\n",
      "{'loss': 0.6165, 'grad_norm': 0.20456090569496155, 'learning_rate': 0.0001258639821095036, 'epoch': 3.47}\n",
      "{'loss': 0.647, 'grad_norm': 0.12310829758644104, 'learning_rate': 0.0001255053479341703, 'epoch': 3.48}\n",
      "{'loss': 0.708, 'grad_norm': 0.21264596283435822, 'learning_rate': 0.0001251463625430968, 'epoch': 3.49}\n",
      "{'loss': 0.7158, 'grad_norm': 0.38313549757003784, 'learning_rate': 0.00012478703087961192, 'epoch': 3.5}\n",
      "{'loss': 0.6705, 'grad_norm': 0.13263578712940216, 'learning_rate': 0.0001244273578918126, 'epoch': 3.51}\n",
      "{'loss': 0.6064, 'grad_norm': 0.1678818166255951, 'learning_rate': 0.00012406734853249605, 'epoch': 3.52}\n",
      "{'loss': 0.6554, 'grad_norm': 0.16040432453155518, 'learning_rate': 0.0001237070077590913, 'epoch': 3.53}\n",
      "{'loss': 0.7232, 'grad_norm': 0.25127777457237244, 'learning_rate': 0.00012334634053359116, 'epoch': 3.54}\n",
      "{'loss': 0.7643, 'grad_norm': 0.414218008518219, 'learning_rate': 0.00012298535182248362, 'epoch': 3.55}\n",
      "{'loss': 0.6776, 'grad_norm': 0.18473219871520996, 'learning_rate': 0.0001226240465966838, 'epoch': 3.56}\n",
      "{'loss': 0.6367, 'grad_norm': 0.12900683283805847, 'learning_rate': 0.0001222624298314652, 'epoch': 3.57}\n",
      "{'loss': 0.7636, 'grad_norm': 0.20867854356765747, 'learning_rate': 0.00012190050650639131, 'epoch': 3.57}\n",
      "{'loss': 0.67, 'grad_norm': 0.3160181939601898, 'learning_rate': 0.00012153828160524707, 'epoch': 3.58}\n",
      "{'loss': 0.6565, 'grad_norm': 0.36258983612060547, 'learning_rate': 0.00012117576011597018, 'epoch': 3.59}\n",
      "{'loss': 0.6635, 'grad_norm': 0.13296420872211456, 'learning_rate': 0.00012081294703058246, 'epoch': 3.6}\n",
      "{'loss': 0.5035, 'grad_norm': 0.1418532282114029, 'learning_rate': 0.00012044984734512106, 'epoch': 3.61}\n",
      "{'loss': 0.4979, 'grad_norm': 0.1559939980506897, 'learning_rate': 0.00012008646605956975, 'epoch': 3.62}\n",
      "{'loss': 0.6429, 'grad_norm': 0.2609446346759796, 'learning_rate': 0.00011972280817778994, 'epoch': 3.63}\n",
      "{'loss': 0.7833, 'grad_norm': 0.4289540946483612, 'learning_rate': 0.0001193588787074519, 'epoch': 3.64}\n",
      "{'loss': 0.5124, 'grad_norm': 0.1153390035033226, 'learning_rate': 0.00011899468265996571, 'epoch': 3.65}\n",
      "{'loss': 0.7649, 'grad_norm': 0.14272554218769073, 'learning_rate': 0.0001186302250504124, 'epoch': 3.66}\n",
      "{'loss': 0.5792, 'grad_norm': 0.23739947378635406, 'learning_rate': 0.00011826551089747455, 'epoch': 3.67}\n",
      "{'loss': 0.7662, 'grad_norm': 0.2576967775821686, 'learning_rate': 0.00011790054522336767, 'epoch': 3.68}\n",
      "{'loss': 0.7296, 'grad_norm': 0.4703570306301117, 'learning_rate': 0.00011753533305377067, 'epoch': 3.68}\n",
      "{'loss': 0.4514, 'grad_norm': 0.07890883088111877, 'learning_rate': 0.0001171698794177567, 'epoch': 3.69}\n",
      "{'loss': 0.6326, 'grad_norm': 0.1896452158689499, 'learning_rate': 0.00011680418934772417, 'epoch': 3.7}\n",
      "{'loss': 0.6635, 'grad_norm': 0.19346825778484344, 'learning_rate': 0.00011643826787932701, 'epoch': 3.71}\n",
      "{'loss': 0.8269, 'grad_norm': 0.2824012041091919, 'learning_rate': 0.00011607212005140576, 'epoch': 3.72}\n",
      "{'loss': 0.8267, 'grad_norm': 0.4918579161167145, 'learning_rate': 0.00011570575090591791, 'epoch': 3.73}\n",
      "{'loss': 0.6717, 'grad_norm': 0.19526009261608124, 'learning_rate': 0.00011533916548786857, 'epoch': 3.74}\n",
      "{'loss': 0.5947, 'grad_norm': 0.20753394067287445, 'learning_rate': 0.00011497236884524094, 'epoch': 3.75}\n",
      "{'loss': 0.506, 'grad_norm': 0.1537184715270996, 'learning_rate': 0.00011460536602892695, 'epoch': 3.76}\n",
      "{'loss': 0.7059, 'grad_norm': 0.25261181592941284, 'learning_rate': 0.00011423816209265749, 'epoch': 3.77}\n",
      "{'loss': 0.7286, 'grad_norm': 0.4431193172931671, 'learning_rate': 0.000113870762092933, 'epoch': 3.78}\n",
      "{'loss': 0.714, 'grad_norm': 0.23772624135017395, 'learning_rate': 0.00011350317108895367, 'epoch': 3.79}\n",
      "{'loss': 0.8332, 'grad_norm': 0.20030753314495087, 'learning_rate': 0.00011313539414255001, 'epoch': 3.79}\n",
      "{'loss': 0.4424, 'grad_norm': 0.16460031270980835, 'learning_rate': 0.00011276743631811295, 'epoch': 3.8}\n",
      "{'loss': 0.7458, 'grad_norm': 0.2716335356235504, 'learning_rate': 0.00011239930268252406, 'epoch': 3.81}\n",
      "{'loss': 0.6612, 'grad_norm': 0.37627750635147095, 'learning_rate': 0.00011203099830508608, 'epoch': 3.82}\n",
      "{'loss': 0.6423, 'grad_norm': 0.17359137535095215, 'learning_rate': 0.00011166252825745269, 'epoch': 3.83}\n",
      "{'loss': 0.7201, 'grad_norm': 0.16934318840503693, 'learning_rate': 0.00011129389761355909, 'epoch': 3.84}\n",
      "{'loss': 0.5814, 'grad_norm': 0.1585892140865326, 'learning_rate': 0.0001109251114495518, 'epoch': 3.85}\n",
      "{'loss': 0.6099, 'grad_norm': 0.18187206983566284, 'learning_rate': 0.00011055617484371899, 'epoch': 3.86}\n",
      "{'loss': 0.6762, 'grad_norm': 0.4625495970249176, 'learning_rate': 0.00011018709287642037, 'epoch': 3.87}\n",
      "{'loss': 0.6569, 'grad_norm': 0.1578705906867981, 'learning_rate': 0.00010981787063001739, 'epoch': 3.88}\n",
      "{'loss': 0.6, 'grad_norm': 0.1479141116142273, 'learning_rate': 0.00010944851318880314, 'epoch': 3.89}\n",
      "{'loss': 0.5918, 'grad_norm': 0.17889462411403656, 'learning_rate': 0.0001090790256389324, 'epoch': 3.9}\n",
      "{'loss': 0.6031, 'grad_norm': 0.2648673355579376, 'learning_rate': 0.00010870941306835154, 'epoch': 3.9}\n",
      "{'loss': 0.7752, 'grad_norm': 0.6050918102264404, 'learning_rate': 0.00010833968056672854, 'epoch': 3.91}\n",
      "{'loss': 0.677, 'grad_norm': 0.2049216479063034, 'learning_rate': 0.00010796983322538295, 'epoch': 3.92}\n",
      "{'loss': 0.6486, 'grad_norm': 0.1729295700788498, 'learning_rate': 0.00010759987613721547, 'epoch': 3.93}\n",
      "{'loss': 0.5334, 'grad_norm': 0.4928719103336334, 'learning_rate': 0.00010722981439663829, 'epoch': 3.94}\n",
      "{'loss': 0.6462, 'grad_norm': 0.23171749711036682, 'learning_rate': 0.00010685965309950448, 'epoch': 3.95}\n",
      "{'loss': 0.6608, 'grad_norm': 0.4965028762817383, 'learning_rate': 0.0001064893973430382, 'epoch': 3.96}\n",
      "{'loss': 0.6185, 'grad_norm': 0.26241275668144226, 'learning_rate': 0.00010611905222576426, 'epoch': 3.97}\n",
      "{'loss': 0.6514, 'grad_norm': 0.14845077693462372, 'learning_rate': 0.00010574862284743798, 'epoch': 3.98}\n",
      "{'loss': 0.6855, 'grad_norm': 0.26045694947242737, 'learning_rate': 0.00010537811430897507, 'epoch': 3.99}\n",
      "{'loss': 0.6879, 'grad_norm': 0.36158487200737, 'learning_rate': 0.00010500753171238116, 'epoch': 4.0}\n",
      "{'loss': 0.6894, 'grad_norm': 0.17102201282978058, 'learning_rate': 0.00010463688016068176, 'epoch': 4.01}\n",
      "{'loss': 0.4309, 'grad_norm': 0.14002031087875366, 'learning_rate': 0.00010426616475785195, 'epoch': 4.01}\n",
      "{'loss': 0.4758, 'grad_norm': 0.1967623084783554, 'learning_rate': 0.00010389539060874598, 'epoch': 4.02}\n",
      "{'loss': 0.7423, 'grad_norm': 0.32500922679901123, 'learning_rate': 0.00010352456281902707, 'epoch': 4.03}\n",
      "{'loss': 0.5081, 'grad_norm': 0.48406508564949036, 'learning_rate': 0.00010315368649509716, 'epoch': 4.04}\n",
      "{'loss': 0.659, 'grad_norm': 0.20868855714797974, 'learning_rate': 0.00010278276674402638, 'epoch': 4.05}\n",
      "{'loss': 0.5505, 'grad_norm': 0.18845035135746002, 'learning_rate': 0.00010241180867348301, 'epoch': 4.06}\n",
      "{'loss': 0.6279, 'grad_norm': 0.17995725572109222, 'learning_rate': 0.00010204081739166286, 'epoch': 4.07}\n",
      "{'loss': 0.6787, 'grad_norm': 0.2596850097179413, 'learning_rate': 0.00010166979800721923, 'epoch': 4.08}\n",
      "{'loss': 0.6077, 'grad_norm': 0.43816059827804565, 'learning_rate': 0.00010129875562919229, 'epoch': 4.09}\n",
      "{'loss': 0.6214, 'grad_norm': 0.15761244297027588, 'learning_rate': 0.0001009276953669388, 'epoch': 4.1}\n",
      "{'loss': 0.5262, 'grad_norm': 0.22662052512168884, 'learning_rate': 0.00010055662233006192, 'epoch': 4.11}\n",
      "{'loss': 0.5999, 'grad_norm': 0.17232853174209595, 'learning_rate': 0.0001001855416283406, 'epoch': 4.12}\n",
      "{'loss': 0.6198, 'grad_norm': 0.22144979238510132, 'learning_rate': 9.981445837165945e-05, 'epoch': 4.12}\n",
      "{'loss': 0.674, 'grad_norm': 0.34339001774787903, 'learning_rate': 9.944337766993812e-05, 'epoch': 4.13}\n",
      "{'loss': 0.6471, 'grad_norm': 0.2546364963054657, 'learning_rate': 9.907230463306122e-05, 'epoch': 4.14}\n",
      "{'loss': 0.5699, 'grad_norm': 0.21716172993183136, 'learning_rate': 9.870124437080773e-05, 'epoch': 4.15}\n",
      "{'loss': 0.4405, 'grad_norm': 0.19187037646770477, 'learning_rate': 9.833020199278075e-05, 'epoch': 4.16}\n",
      "{'loss': 0.6382, 'grad_norm': 0.2375209778547287, 'learning_rate': 9.795918260833714e-05, 'epoch': 4.17}\n",
      "{'loss': 0.6043, 'grad_norm': 0.587422251701355, 'learning_rate': 9.758819132651704e-05, 'epoch': 4.18}\n",
      "{'loss': 0.4632, 'grad_norm': 0.21665719151496887, 'learning_rate': 9.721723325597365e-05, 'epoch': 4.19}\n",
      "{'loss': 0.5867, 'grad_norm': 0.19179049134254456, 'learning_rate': 9.684631350490287e-05, 'epoch': 4.2}\n",
      "{'loss': 0.5111, 'grad_norm': 0.16587506234645844, 'learning_rate': 9.647543718097293e-05, 'epoch': 4.21}\n",
      "{'loss': 0.6509, 'grad_norm': 0.20953136682510376, 'learning_rate': 9.610460939125407e-05, 'epoch': 4.22}\n",
      "{'loss': 0.6484, 'grad_norm': 0.48255619406700134, 'learning_rate': 9.573383524214808e-05, 'epoch': 4.23}\n",
      "{'loss': 0.4822, 'grad_norm': 0.2368803322315216, 'learning_rate': 9.536311983931825e-05, 'epoch': 4.23}\n",
      "{'loss': 0.6735, 'grad_norm': 0.22195245325565338, 'learning_rate': 9.499246828761887e-05, 'epoch': 4.24}\n",
      "{'loss': 0.6941, 'grad_norm': 0.1990823596715927, 'learning_rate': 9.462188569102497e-05, 'epoch': 4.25}\n",
      "{'loss': 0.7739, 'grad_norm': 0.306953489780426, 'learning_rate': 9.4251377152562e-05, 'epoch': 4.26}\n",
      "{'loss': 0.7095, 'grad_norm': 0.42035797238349915, 'learning_rate': 9.388094777423578e-05, 'epoch': 4.27}\n",
      "{'loss': 0.5053, 'grad_norm': 0.20446263253688812, 'learning_rate': 9.351060265696183e-05, 'epoch': 4.28}\n",
      "{'loss': 0.4729, 'grad_norm': 0.20595580339431763, 'learning_rate': 9.314034690049555e-05, 'epoch': 4.29}\n",
      "{'loss': 0.5144, 'grad_norm': 0.13972681760787964, 'learning_rate': 9.277018560336174e-05, 'epoch': 4.3}\n",
      "{'loss': 0.667, 'grad_norm': 0.23125019669532776, 'learning_rate': 9.240012386278454e-05, 'epoch': 4.31}\n",
      "{'loss': 0.6994, 'grad_norm': 0.38192451000213623, 'learning_rate': 9.20301667746171e-05, 'epoch': 4.32}\n",
      "{'loss': 0.5437, 'grad_norm': 0.2523573637008667, 'learning_rate': 9.166031943327147e-05, 'epoch': 4.33}\n",
      "{'loss': 0.6939, 'grad_norm': 0.20299434661865234, 'learning_rate': 9.129058693164848e-05, 'epoch': 4.34}\n",
      "{'loss': 0.4663, 'grad_norm': 0.08918876200914383, 'learning_rate': 9.092097436106764e-05, 'epoch': 4.34}\n",
      "{'loss': 0.546, 'grad_norm': 0.20623798668384552, 'learning_rate': 9.055148681119688e-05, 'epoch': 4.35}\n",
      "{'loss': 0.6152, 'grad_norm': 0.329146146774292, 'learning_rate': 9.018212936998265e-05, 'epoch': 4.36}\n",
      "{'loss': 0.5442, 'grad_norm': 0.20132623612880707, 'learning_rate': 8.981290712357963e-05, 'epoch': 4.37}\n",
      "{'loss': 0.5957, 'grad_norm': 0.17693068087100983, 'learning_rate': 8.944382515628104e-05, 'epoch': 4.38}\n",
      "{'loss': 0.5383, 'grad_norm': 0.2059308886528015, 'learning_rate': 8.90748885504482e-05, 'epoch': 4.39}\n",
      "{'loss': 0.6053, 'grad_norm': 0.2926793098449707, 'learning_rate': 8.870610238644092e-05, 'epoch': 4.4}\n",
      "{'loss': 0.6634, 'grad_norm': 0.28154245018959045, 'learning_rate': 8.833747174254736e-05, 'epoch': 4.41}\n",
      "{'loss': 0.6302, 'grad_norm': 0.18992120027542114, 'learning_rate': 8.796900169491397e-05, 'epoch': 4.42}\n",
      "{'loss': 0.7648, 'grad_norm': 0.22400574386119843, 'learning_rate': 8.760069731747597e-05, 'epoch': 4.43}\n",
      "{'loss': 0.6264, 'grad_norm': 0.1645766794681549, 'learning_rate': 8.723256368188708e-05, 'epoch': 4.44}\n",
      "{'loss': 0.5727, 'grad_norm': 0.29992446303367615, 'learning_rate': 8.686460585744998e-05, 'epoch': 4.45}\n",
      "{'loss': 0.6428, 'grad_norm': 0.5237988233566284, 'learning_rate': 8.649682891104634e-05, 'epoch': 4.45}\n",
      "{'loss': 0.52, 'grad_norm': 0.21826563775539398, 'learning_rate': 8.612923790706707e-05, 'epoch': 4.46}\n",
      "{'loss': 0.6927, 'grad_norm': 0.2335142195224762, 'learning_rate': 8.576183790734253e-05, 'epoch': 4.47}\n",
      "{'loss': 0.6698, 'grad_norm': 0.2387399673461914, 'learning_rate': 8.539463397107308e-05, 'epoch': 4.48}\n",
      "{'loss': 0.4623, 'grad_norm': 0.255428671836853, 'learning_rate': 8.502763115475908e-05, 'epoch': 4.49}\n",
      "{'loss': 0.6356, 'grad_norm': 0.5061883330345154, 'learning_rate': 8.466083451213144e-05, 'epoch': 4.5}\n",
      "{'loss': 0.4959, 'grad_norm': 0.3155367970466614, 'learning_rate': 8.429424909408214e-05, 'epoch': 4.51}\n",
      "{'loss': 0.5081, 'grad_norm': 0.2094240039587021, 'learning_rate': 8.392787994859427e-05, 'epoch': 4.52}\n",
      "{'loss': 0.6041, 'grad_norm': 0.18268728256225586, 'learning_rate': 8.356173212067301e-05, 'epoch': 4.53}\n",
      "{'loss': 0.6169, 'grad_norm': 0.2875094413757324, 'learning_rate': 8.319581065227585e-05, 'epoch': 4.54}\n",
      "{'loss': 0.5852, 'grad_norm': 0.3997384011745453, 'learning_rate': 8.283012058224329e-05, 'epoch': 4.55}\n",
      "{'loss': 0.614, 'grad_norm': 0.2246607542037964, 'learning_rate': 8.246466694622938e-05, 'epoch': 4.56}\n",
      "{'loss': 0.565, 'grad_norm': 0.19673874974250793, 'learning_rate': 8.209945477663236e-05, 'epoch': 4.56}\n",
      "{'loss': 0.5133, 'grad_norm': 0.17400109767913818, 'learning_rate': 8.173448910252548e-05, 'epoch': 4.57}\n",
      "{'loss': 0.5808, 'grad_norm': 0.27988168597221375, 'learning_rate': 8.136977494958764e-05, 'epoch': 4.58}\n",
      "{'loss': 0.6603, 'grad_norm': 0.33321014046669006, 'learning_rate': 8.100531734003428e-05, 'epoch': 4.59}\n",
      "{'loss': 0.5935, 'grad_norm': 0.2400318831205368, 'learning_rate': 8.064112129254814e-05, 'epoch': 4.6}\n",
      "{'loss': 0.6332, 'grad_norm': 0.16116447746753693, 'learning_rate': 8.02771918222101e-05, 'epoch': 4.61}\n",
      "{'loss': 0.6745, 'grad_norm': 0.2194352000951767, 'learning_rate': 7.991353394043027e-05, 'epoch': 4.62}\n",
      "{'loss': 0.5736, 'grad_norm': 0.24987265467643738, 'learning_rate': 7.955015265487895e-05, 'epoch': 4.63}\n",
      "{'loss': 0.5126, 'grad_norm': 0.4753198027610779, 'learning_rate': 7.918705296941757e-05, 'epoch': 4.64}\n",
      "{'loss': 0.5939, 'grad_norm': 0.1981365829706192, 'learning_rate': 7.882423988402983e-05, 'epoch': 4.65}\n",
      "{'loss': 0.4477, 'grad_norm': 0.19876031577587128, 'learning_rate': 7.846171839475295e-05, 'epoch': 4.66}\n",
      "{'loss': 0.7726, 'grad_norm': 0.2596862018108368, 'learning_rate': 7.809949349360872e-05, 'epoch': 4.67}\n",
      "{'loss': 0.6478, 'grad_norm': 0.33922499418258667, 'learning_rate': 7.773757016853483e-05, 'epoch': 4.67}\n",
      "{'loss': 0.6224, 'grad_norm': 0.5005382299423218, 'learning_rate': 7.73759534033162e-05, 'epoch': 4.68}\n",
      "{'loss': 0.6498, 'grad_norm': 0.23996809124946594, 'learning_rate': 7.701464817751639e-05, 'epoch': 4.69}\n",
      "{'loss': 0.5763, 'grad_norm': 0.22290581464767456, 'learning_rate': 7.66536594664089e-05, 'epoch': 4.7}\n",
      "{'loss': 0.5311, 'grad_norm': 0.1797059327363968, 'learning_rate': 7.629299224090873e-05, 'epoch': 4.71}\n",
      "{'loss': 0.663, 'grad_norm': 0.2542630136013031, 'learning_rate': 7.593265146750397e-05, 'epoch': 4.72}\n",
      "{'loss': 0.6163, 'grad_norm': 0.4500494599342346, 'learning_rate': 7.557264210818741e-05, 'epoch': 4.73}\n",
      "{'loss': 0.5236, 'grad_norm': 0.19188863039016724, 'learning_rate': 7.52129691203881e-05, 'epoch': 4.74}\n",
      "{'loss': 0.5664, 'grad_norm': 0.16799810528755188, 'learning_rate': 7.485363745690322e-05, 'epoch': 4.75}\n",
      "{'loss': 0.4894, 'grad_norm': 0.26864078640937805, 'learning_rate': 7.449465206582973e-05, 'epoch': 4.76}\n",
      "{'loss': 0.4148, 'grad_norm': 0.25929540395736694, 'learning_rate': 7.413601789049644e-05, 'epoch': 4.77}\n",
      "{'loss': 0.6871, 'grad_norm': 0.4164469838142395, 'learning_rate': 7.377773986939574e-05, 'epoch': 4.78}\n",
      "{'loss': 0.5794, 'grad_norm': 0.2630780339241028, 'learning_rate': 7.34198229361157e-05, 'epoch': 4.78}\n",
      "{'loss': 0.4413, 'grad_norm': 0.2023559808731079, 'learning_rate': 7.306227201927218e-05, 'epoch': 4.79}\n",
      "{'loss': 0.5151, 'grad_norm': 0.16286475956439972, 'learning_rate': 7.270509204244074e-05, 'epoch': 4.8}\n",
      "{'loss': 0.7408, 'grad_norm': 0.34874704480171204, 'learning_rate': 7.234828792408912e-05, 'epoch': 4.81}\n",
      "{'loss': 0.6792, 'grad_norm': 0.37513893842697144, 'learning_rate': 7.19918645775093e-05, 'epoch': 4.82}\n",
      "{'loss': 0.5896, 'grad_norm': 0.16421453654766083, 'learning_rate': 7.163582691075004e-05, 'epoch': 4.83}\n",
      "{'loss': 0.5874, 'grad_norm': 0.1887603998184204, 'learning_rate': 7.128017982654907e-05, 'epoch': 4.84}\n",
      "{'loss': 0.5614, 'grad_norm': 0.13662807643413544, 'learning_rate': 7.092492822226573e-05, 'epoch': 4.85}\n",
      "{'loss': 0.6165, 'grad_norm': 0.23039336502552032, 'learning_rate': 7.057007698981346e-05, 'epoch': 4.86}\n",
      "{'loss': 0.5772, 'grad_norm': 0.42517656087875366, 'learning_rate': 7.021563101559257e-05, 'epoch': 4.87}\n",
      "{'loss': 0.5591, 'grad_norm': 0.24331124126911163, 'learning_rate': 6.986159518042273e-05, 'epoch': 4.88}\n",
      "{'loss': 0.6059, 'grad_norm': 0.1819923222064972, 'learning_rate': 6.950797435947594e-05, 'epoch': 4.89}\n",
      "{'loss': 0.4957, 'grad_norm': 0.1893680840730667, 'learning_rate': 6.915477342220937e-05, 'epoch': 4.89}\n",
      "{'loss': 0.5218, 'grad_norm': 0.27061325311660767, 'learning_rate': 6.880199723229817e-05, 'epoch': 4.9}\n",
      "{'loss': 0.6938, 'grad_norm': 0.35742560029029846, 'learning_rate': 6.844965064756871e-05, 'epoch': 4.91}\n",
      "{'loss': 0.5891, 'grad_norm': 0.240936741232872, 'learning_rate': 6.80977385199315e-05, 'epoch': 4.92}\n",
      "{'loss': 0.6558, 'grad_norm': 0.22539865970611572, 'learning_rate': 6.774626569531453e-05, 'epoch': 4.93}\n",
      "{'loss': 0.7274, 'grad_norm': 0.2589259743690491, 'learning_rate': 6.739523701359643e-05, 'epoch': 4.94}\n",
      "{'loss': 0.6136, 'grad_norm': 0.34912383556365967, 'learning_rate': 6.704465730853981e-05, 'epoch': 4.95}\n",
      "{'loss': 0.63, 'grad_norm': 0.5224745273590088, 'learning_rate': 6.669453140772477e-05, 'epoch': 4.96}\n",
      "{'loss': 0.6395, 'grad_norm': 0.1936814934015274, 'learning_rate': 6.634486413248249e-05, 'epoch': 4.97}\n",
      "{'loss': 0.4366, 'grad_norm': 0.3271266520023346, 'learning_rate': 6.599566029782863e-05, 'epoch': 4.98}\n",
      "{'loss': 0.557, 'grad_norm': 0.2701995372772217, 'learning_rate': 6.564692471239723e-05, 'epoch': 4.99}\n",
      "{'loss': 0.6725, 'grad_norm': 0.37471508979797363, 'learning_rate': 6.52986621783743e-05, 'epoch': 5.0}\n",
      "{'loss': 0.5877, 'grad_norm': 0.20099815726280212, 'learning_rate': 6.49508774914319e-05, 'epoch': 5.0}\n",
      "{'loss': 0.4716, 'grad_norm': 0.18935240805149078, 'learning_rate': 6.4603575440662e-05, 'epoch': 5.01}\n",
      "{'loss': 0.5141, 'grad_norm': 0.2206757664680481, 'learning_rate': 6.425676080851046e-05, 'epoch': 5.02}\n",
      "{'loss': 0.5287, 'grad_norm': 0.25200310349464417, 'learning_rate': 6.391043837071138e-05, 'epoch': 5.03}\n",
      "{'loss': 0.565, 'grad_norm': 0.3586837649345398, 'learning_rate': 6.356461289622102e-05, 'epoch': 5.04}\n",
      "{'loss': 0.3759, 'grad_norm': 0.17936573922634125, 'learning_rate': 6.321928914715246e-05, 'epoch': 5.05}\n",
      "{'loss': 0.588, 'grad_norm': 0.23362553119659424, 'learning_rate': 6.287447187870985e-05, 'epoch': 5.06}\n",
      "{'loss': 0.5037, 'grad_norm': 0.15559767186641693, 'learning_rate': 6.253016583912295e-05, 'epoch': 5.07}\n",
      "{'loss': 0.5392, 'grad_norm': 0.2548922300338745, 'learning_rate': 6.218637576958176e-05, 'epoch': 5.08}\n",
      "{'loss': 0.5892, 'grad_norm': 0.4370632767677307, 'learning_rate': 6.184310640417125e-05, 'epoch': 5.09}\n",
      "{'loss': 0.4298, 'grad_norm': 0.19217662513256073, 'learning_rate': 6.150036246980609e-05, 'epoch': 5.1}\n",
      "{'loss': 0.6184, 'grad_norm': 0.23553811013698578, 'learning_rate': 6.115814868616563e-05, 'epoch': 5.11}\n",
      "{'loss': 0.5005, 'grad_norm': 0.14307880401611328, 'learning_rate': 6.081646976562899e-05, 'epoch': 5.11}\n",
      "{'loss': 0.6623, 'grad_norm': 0.31307676434516907, 'learning_rate': 6.047533041320998e-05, 'epoch': 5.12}\n",
      "{'loss': 0.6033, 'grad_norm': 0.43684324622154236, 'learning_rate': 6.0134735326492456e-05, 'epoch': 5.13}\n",
      "{'loss': 0.4241, 'grad_norm': 0.26784974336624146, 'learning_rate': 5.97946891955655e-05, 'epoch': 5.14}\n",
      "{'loss': 0.4345, 'grad_norm': 0.2706666886806488, 'learning_rate': 5.9455196702959035e-05, 'epoch': 5.15}\n",
      "{'loss': 0.5108, 'grad_norm': 0.22260521352291107, 'learning_rate': 5.911626252357918e-05, 'epoch': 5.16}\n",
      "{'loss': 0.633, 'grad_norm': 0.2903805077075958, 'learning_rate': 5.877789132464388e-05, 'epoch': 5.17}\n",
      "{'loss': 0.5889, 'grad_norm': 0.4396819472312927, 'learning_rate': 5.84400877656188e-05, 'epoch': 5.18}\n",
      "{'loss': 0.473, 'grad_norm': 0.23834861814975739, 'learning_rate': 5.8102856498152926e-05, 'epoch': 5.19}\n",
      "{'loss': 0.5424, 'grad_norm': 0.23237314820289612, 'learning_rate': 5.776620216601462e-05, 'epoch': 5.2}\n",
      "{'loss': 0.6579, 'grad_norm': 0.22070491313934326, 'learning_rate': 5.7430129405027835e-05, 'epoch': 5.21}\n",
      "{'loss': 0.5271, 'grad_norm': 0.2264925241470337, 'learning_rate': 5.7094642843008e-05, 'epoch': 5.22}\n",
      "{'loss': 0.5243, 'grad_norm': 0.4701060950756073, 'learning_rate': 5.675974709969847e-05, 'epoch': 5.22}\n",
      "{'loss': 0.5724, 'grad_norm': 0.16943641006946564, 'learning_rate': 5.642544678670676e-05, 'epoch': 5.23}\n",
      "{'loss': 0.5408, 'grad_norm': 0.15351635217666626, 'learning_rate': 5.6091746507441334e-05, 'epoch': 5.24}\n",
      "{'loss': 0.4849, 'grad_norm': 0.2411016821861267, 'learning_rate': 5.575865085704785e-05, 'epoch': 5.25}\n",
      "{'loss': 0.7795, 'grad_norm': 0.2528478503227234, 'learning_rate': 5.542616442234618e-05, 'epoch': 5.26}\n",
      "{'loss': 0.6354, 'grad_norm': 0.41886571049690247, 'learning_rate': 5.509429178176704e-05, 'epoch': 5.27}\n",
      "{'loss': 0.5778, 'grad_norm': 0.2035697102546692, 'learning_rate': 5.476303750528906e-05, 'epoch': 5.28}\n",
      "{'loss': 0.4739, 'grad_norm': 0.21510066092014313, 'learning_rate': 5.443240615437586e-05, 'epoch': 5.29}\n",
      "{'loss': 0.5043, 'grad_norm': 0.17295078933238983, 'learning_rate': 5.4102402281913135e-05, 'epoch': 5.3}\n",
      "{'loss': 0.5353, 'grad_norm': 0.25027555227279663, 'learning_rate': 5.3773030432146076e-05, 'epoch': 5.31}\n",
      "{'loss': 0.6201, 'grad_norm': 0.41595658659935, 'learning_rate': 5.3444295140616684e-05, 'epoch': 5.32}\n",
      "{'loss': 0.5233, 'grad_norm': 0.2633334994316101, 'learning_rate': 5.311620093410157e-05, 'epoch': 5.33}\n",
      "{'loss': 0.5301, 'grad_norm': 0.2384870946407318, 'learning_rate': 5.278875233054912e-05, 'epoch': 5.33}\n",
      "{'loss': 0.7127, 'grad_norm': 0.19370630383491516, 'learning_rate': 5.246195383901782e-05, 'epoch': 5.34}\n",
      "{'loss': 0.5321, 'grad_norm': 0.318053662776947, 'learning_rate': 5.2135809959613825e-05, 'epoch': 5.35}\n",
      "{'loss': 0.5822, 'grad_norm': 0.4862412214279175, 'learning_rate': 5.1810325183429135e-05, 'epoch': 5.36}\n",
      "{'loss': 0.4612, 'grad_norm': 0.07944880425930023, 'learning_rate': 5.14855039924798e-05, 'epoch': 5.37}\n",
      "{'loss': 0.532, 'grad_norm': 0.23576797544956207, 'learning_rate': 5.116135085964391e-05, 'epoch': 5.38}\n",
      "{'loss': 0.6905, 'grad_norm': 0.20079857110977173, 'learning_rate': 5.08378702486004e-05, 'epoch': 5.39}\n",
      "{'loss': 0.6334, 'grad_norm': 0.34496504068374634, 'learning_rate': 5.051506661376725e-05, 'epoch': 5.4}\n",
      "{'loss': 0.572, 'grad_norm': 0.4299263656139374, 'learning_rate': 5.019294440024045e-05, 'epoch': 5.41}\n",
      "{'loss': 0.4598, 'grad_norm': 0.2223227471113205, 'learning_rate': 4.987150804373254e-05, 'epoch': 5.42}\n",
      "{'loss': 0.5788, 'grad_norm': 0.30219152569770813, 'learning_rate': 4.955076197051154e-05, 'epoch': 5.43}\n",
      "{'loss': 0.5381, 'grad_norm': 0.2291395366191864, 'learning_rate': 4.923071059734015e-05, 'epoch': 5.44}\n",
      "{'loss': 0.5623, 'grad_norm': 0.3338155746459961, 'learning_rate': 4.891135833141495e-05, 'epoch': 5.44}\n",
      "{'loss': 0.5495, 'grad_norm': 0.6164751052856445, 'learning_rate': 4.859270957030547e-05, 'epoch': 5.45}\n",
      "{'loss': 0.4931, 'grad_norm': 0.22125467658042908, 'learning_rate': 4.827476870189387e-05, 'epoch': 5.46}\n",
      "{'loss': 0.4988, 'grad_norm': 0.22244785726070404, 'learning_rate': 4.795754010431438e-05, 'epoch': 5.47}\n",
      "{'loss': 0.557, 'grad_norm': 0.20673556625843048, 'learning_rate': 4.7641028145893094e-05, 'epoch': 5.48}\n",
      "{'loss': 0.5743, 'grad_norm': 0.286647230386734, 'learning_rate': 4.732523718508779e-05, 'epoch': 5.49}\n",
      "{'loss': 0.586, 'grad_norm': 0.5177326798439026, 'learning_rate': 4.7010171570427874e-05, 'epoch': 5.5}\n",
      "{'loss': 0.3743, 'grad_norm': 0.1996482014656067, 'learning_rate': 4.6695835640454564e-05, 'epoch': 5.51}\n",
      "{'loss': 0.5477, 'grad_norm': 0.13948984444141388, 'learning_rate': 4.638223372366111e-05, 'epoch': 5.52}\n",
      "{'loss': 0.6186, 'grad_norm': 0.24253788590431213, 'learning_rate': 4.606937013843319e-05, 'epoch': 5.53}\n",
      "{'loss': 0.5916, 'grad_norm': 0.21988512575626373, 'learning_rate': 4.575724919298946e-05, 'epoch': 5.54}\n",
      "{'loss': 0.6559, 'grad_norm': 0.427955687046051, 'learning_rate': 4.5445875185322206e-05, 'epoch': 5.55}\n",
      "{'loss': 0.4026, 'grad_norm': 0.2459821105003357, 'learning_rate': 4.513525240313819e-05, 'epoch': 5.55}\n",
      "{'loss': 0.5844, 'grad_norm': 0.12014699727296829, 'learning_rate': 4.4825385123799576e-05, 'epoch': 5.56}\n",
      "{'loss': 0.5384, 'grad_norm': 0.24579766392707825, 'learning_rate': 4.451627761426506e-05, 'epoch': 5.57}\n",
      "{'loss': 0.4255, 'grad_norm': 0.27789318561553955, 'learning_rate': 4.420793413103106e-05, 'epoch': 5.58}\n",
      "{'loss': 0.7059, 'grad_norm': 0.49639657139778137, 'learning_rate': 4.3900358920073184e-05, 'epoch': 5.59}\n",
      "{'loss': 0.5882, 'grad_norm': 0.22769658267498016, 'learning_rate': 4.359355621678764e-05, 'epoch': 5.6}\n",
      "{'loss': 0.5176, 'grad_norm': 0.13532087206840515, 'learning_rate': 4.3287530245933194e-05, 'epoch': 5.61}\n",
      "{'loss': 0.5708, 'grad_norm': 0.2988031208515167, 'learning_rate': 4.2982285221572505e-05, 'epoch': 5.62}\n",
      "{'loss': 0.5584, 'grad_norm': 0.3830651342868805, 'learning_rate': 4.267782534701457e-05, 'epoch': 5.63}\n",
      "{'loss': 0.5997, 'grad_norm': 0.36809274554252625, 'learning_rate': 4.237415481475654e-05, 'epoch': 5.64}\n",
      "{'loss': 0.43, 'grad_norm': 0.2179250419139862, 'learning_rate': 4.207127780642628e-05, 'epoch': 5.65}\n",
      "{'loss': 0.5704, 'grad_norm': 0.2573198676109314, 'learning_rate': 4.1769198492724474e-05, 'epoch': 5.66}\n",
      "{'loss': 0.4375, 'grad_norm': 0.17315760254859924, 'learning_rate': 4.1467921033367285e-05, 'epoch': 5.66}\n",
      "{'loss': 0.5138, 'grad_norm': 0.3243674337863922, 'learning_rate': 4.1167449577029224e-05, 'epoch': 5.67}\n",
      "{'loss': 0.4731, 'grad_norm': 0.4909150004386902, 'learning_rate': 4.086778826128584e-05, 'epoch': 5.68}\n",
      "{'loss': 0.4567, 'grad_norm': 0.23245874047279358, 'learning_rate': 4.056894121255693e-05, 'epoch': 5.69}\n",
      "{'loss': 0.5579, 'grad_norm': 0.1427922546863556, 'learning_rate': 4.02709125460495e-05, 'epoch': 5.7}\n",
      "{'loss': 0.7186, 'grad_norm': 0.26990363001823425, 'learning_rate': 3.997370636570127e-05, 'epoch': 5.71}\n",
      "{'loss': 0.5359, 'grad_norm': 0.33266037702560425, 'learning_rate': 3.9677326764123965e-05, 'epoch': 5.72}\n",
      "{'loss': 0.5529, 'grad_norm': 0.5304198861122131, 'learning_rate': 3.9381777822547305e-05, 'epoch': 5.73}\n",
      "{'loss': 0.505, 'grad_norm': 0.25176820158958435, 'learning_rate': 3.9087063610762444e-05, 'epoch': 5.74}\n",
      "{'loss': 0.6011, 'grad_norm': 0.26470619440078735, 'learning_rate': 3.879318818706609e-05, 'epoch': 5.75}\n",
      "{'loss': 0.5325, 'grad_norm': 0.27012863755226135, 'learning_rate': 3.8500155598204644e-05, 'epoch': 5.76}\n",
      "{'loss': 0.6716, 'grad_norm': 0.35762497782707214, 'learning_rate': 3.820796987931842e-05, 'epoch': 5.77}\n",
      "{'loss': 0.5742, 'grad_norm': 0.39956116676330566, 'learning_rate': 3.7916635053886066e-05, 'epoch': 5.77}\n",
      "{'loss': 0.4361, 'grad_norm': 0.3164328932762146, 'learning_rate': 3.762615513366925e-05, 'epoch': 5.78}\n",
      "{'loss': 0.5538, 'grad_norm': 0.5555834174156189, 'learning_rate': 3.7336534118657305e-05, 'epoch': 5.79}\n",
      "{'loss': 0.6693, 'grad_norm': 0.2344851940870285, 'learning_rate': 3.7047775997012226e-05, 'epoch': 5.8}\n",
      "{'loss': 0.577, 'grad_norm': 0.43988290429115295, 'learning_rate': 3.675988474501373e-05, 'epoch': 5.81}\n",
      "{'loss': 0.5316, 'grad_norm': 0.39204922318458557, 'learning_rate': 3.6472864327004465e-05, 'epoch': 5.82}\n",
      "{'loss': 0.3942, 'grad_norm': 0.09795687347650528, 'learning_rate': 3.61867186953355e-05, 'epoch': 5.83}\n",
      "{'loss': 0.4389, 'grad_norm': 0.2291291505098343, 'learning_rate': 3.590145179031183e-05, 'epoch': 5.84}\n",
      "{'loss': 0.551, 'grad_norm': 0.22656163573265076, 'learning_rate': 3.56170675401381e-05, 'epoch': 5.85}\n",
      "{'loss': 0.5923, 'grad_norm': 0.3535904288291931, 'learning_rate': 3.533356986086465e-05, 'epoch': 5.86}\n",
      "{'loss': 0.507, 'grad_norm': 0.467583566904068, 'learning_rate': 3.5050962656333376e-05, 'epoch': 5.87}\n",
      "{'loss': 0.5806, 'grad_norm': 0.22177602350711823, 'learning_rate': 3.476924981812417e-05, 'epoch': 5.88}\n",
      "{'loss': 0.6946, 'grad_norm': 0.21745553612709045, 'learning_rate': 3.4488435225501207e-05, 'epoch': 5.88}\n",
      "{'loss': 0.4382, 'grad_norm': 0.2193586379289627, 'learning_rate': 3.420852274535963e-05, 'epoch': 5.89}\n",
      "{'loss': 0.5652, 'grad_norm': 0.4002958834171295, 'learning_rate': 3.392951623217221e-05, 'epoch': 5.9}\n",
      "{'loss': 0.5048, 'grad_norm': 0.7609049081802368, 'learning_rate': 3.365141952793622e-05, 'epoch': 5.91}\n",
      "{'loss': 0.4848, 'grad_norm': 0.24916960299015045, 'learning_rate': 3.33742364621207e-05, 'epoch': 5.92}\n",
      "{'loss': 0.5914, 'grad_norm': 0.2800154685974121, 'learning_rate': 3.3097970851613666e-05, 'epoch': 5.93}\n",
      "{'loss': 0.6455, 'grad_norm': 0.29346001148223877, 'learning_rate': 3.282262650066945e-05, 'epoch': 5.94}\n",
      "{'loss': 0.5501, 'grad_norm': 0.33546826243400574, 'learning_rate': 3.254820720085643e-05, 'epoch': 5.95}\n",
      "{'loss': 0.4923, 'grad_norm': 0.3794172704219818, 'learning_rate': 3.227471673100464e-05, 'epoch': 5.96}\n",
      "{'loss': 0.6452, 'grad_norm': 0.2663310766220093, 'learning_rate': 3.200215885715407e-05, 'epoch': 5.97}\n",
      "{'loss': 0.3844, 'grad_norm': 0.10677774250507355, 'learning_rate': 3.17305373325025e-05, 'epoch': 5.98}\n",
      "{'loss': 0.6197, 'grad_norm': 0.30958324670791626, 'learning_rate': 3.14598558973539e-05, 'epoch': 5.99}\n",
      "{'loss': 0.5794, 'grad_norm': 0.47792086005210876, 'learning_rate': 3.119011827906701e-05, 'epoch': 5.99}\n",
      "{'loss': 0.4442, 'grad_norm': 0.1939927190542221, 'learning_rate': 3.092132819200383e-05, 'epoch': 6.0}\n",
      "{'loss': 0.4996, 'grad_norm': 0.18541069328784943, 'learning_rate': 3.065348933747876e-05, 'epoch': 6.01}\n",
      "{'loss': 0.5271, 'grad_norm': 0.2846187949180603, 'learning_rate': 3.0386605403707346e-05, 'epoch': 6.02}\n",
      "{'loss': 0.5428, 'grad_norm': 0.3672785460948944, 'learning_rate': 3.0120680065755635e-05, 'epoch': 6.03}\n",
      "{'loss': 0.4757, 'grad_norm': 0.42796844244003296, 'learning_rate': 2.9855716985489556e-05, 'epoch': 6.04}\n",
      "{'loss': 0.3929, 'grad_norm': 0.22435873746871948, 'learning_rate': 2.9591719811524464e-05, 'epoch': 6.05}\n",
      "{'loss': 0.5249, 'grad_norm': 0.2730151116847992, 'learning_rate': 2.9328692179174933e-05, 'epoch': 6.06}\n",
      "{'loss': 0.4659, 'grad_norm': 0.1359754353761673, 'learning_rate': 2.9066637710404675e-05, 'epoch': 6.07}\n",
      "{'loss': 0.4939, 'grad_norm': 0.3065972924232483, 'learning_rate': 2.8805560013776657e-05, 'epoch': 6.08}\n",
      "{'loss': 0.5482, 'grad_norm': 0.348825603723526, 'learning_rate': 2.854546268440339e-05, 'epoch': 6.09}\n",
      "{'loss': 0.4299, 'grad_norm': 0.2502751648426056, 'learning_rate': 2.8286349303897618e-05, 'epoch': 6.1}\n",
      "{'loss': 0.6471, 'grad_norm': 0.2371729165315628, 'learning_rate': 2.8028223440322586e-05, 'epoch': 6.1}\n",
      "{'loss': 0.604, 'grad_norm': 0.3027206063270569, 'learning_rate': 2.777108864814333e-05, 'epoch': 6.11}\n",
      "{'loss': 0.63, 'grad_norm': 0.36961042881011963, 'learning_rate': 2.7514948468177503e-05, 'epoch': 6.12}\n",
      "{'loss': 0.4639, 'grad_norm': 0.9526433348655701, 'learning_rate': 2.7259806427546652e-05, 'epoch': 6.13}\n",
      "{'loss': 0.4316, 'grad_norm': 0.29763224720954895, 'learning_rate': 2.7005666039627788e-05, 'epoch': 6.14}\n",
      "{'loss': 0.6209, 'grad_norm': 0.2282804548740387, 'learning_rate': 2.6752530804004684e-05, 'epoch': 6.15}\n",
      "{'loss': 0.5192, 'grad_norm': 0.2874715328216553, 'learning_rate': 2.6500404206420027e-05, 'epoch': 6.16}\n",
      "{'loss': 0.5771, 'grad_norm': 0.3254605829715729, 'learning_rate': 2.624928971872722e-05, 'epoch': 6.17}\n",
      "{'loss': 0.4864, 'grad_norm': 0.4737119674682617, 'learning_rate': 2.599919079884271e-05, 'epoch': 6.18}\n",
      "{'loss': 0.3627, 'grad_norm': 0.18187032639980316, 'learning_rate': 2.575011089069823e-05, 'epoch': 6.19}\n",
      "{'loss': 0.5756, 'grad_norm': 0.2215755432844162, 'learning_rate': 2.5502053424193384e-05, 'epoch': 6.2}\n",
      "{'loss': 0.7219, 'grad_norm': 0.2993971109390259, 'learning_rate': 2.525502181514855e-05, 'epoch': 6.21}\n",
      "{'loss': 0.6002, 'grad_norm': 0.24761490523815155, 'learning_rate': 2.5009019465257775e-05, 'epoch': 6.21}\n",
      "{'loss': 0.5234, 'grad_norm': 0.4813014566898346, 'learning_rate': 2.4764049762041874e-05, 'epoch': 6.22}\n",
      "{'loss': 0.3549, 'grad_norm': 0.2358364313840866, 'learning_rate': 2.452011607880187e-05, 'epoch': 6.23}\n",
      "{'loss': 0.5493, 'grad_norm': 0.29316437244415283, 'learning_rate': 2.4277221774572388e-05, 'epoch': 6.24}\n",
      "{'loss': 0.4276, 'grad_norm': 0.2047187089920044, 'learning_rate': 2.40353701940757e-05, 'epoch': 6.25}\n",
      "{'loss': 0.4496, 'grad_norm': 0.4289587736129761, 'learning_rate': 2.3794564667675346e-05, 'epoch': 6.26}\n",
      "{'loss': 0.5358, 'grad_norm': 0.565204918384552, 'learning_rate': 2.355480851133046e-05, 'epoch': 6.27}\n",
      "{'loss': 0.512, 'grad_norm': 0.16993533074855804, 'learning_rate': 2.331610502655005e-05, 'epoch': 6.28}\n",
      "{'loss': 0.4686, 'grad_norm': 0.2825622260570526, 'learning_rate': 2.3078457500347527e-05, 'epoch': 6.29}\n",
      "{'loss': 0.4927, 'grad_norm': 0.16922858357429504, 'learning_rate': 2.2841869205195487e-05, 'epoch': 6.3}\n",
      "{'loss': 0.4425, 'grad_norm': 0.25918516516685486, 'learning_rate': 2.26063433989806e-05, 'epoch': 6.31}\n",
      "{'loss': 0.4756, 'grad_norm': 0.4320264756679535, 'learning_rate': 2.2371883324958775e-05, 'epoch': 6.32}\n",
      "{'loss': 0.4172, 'grad_norm': 0.2681310474872589, 'learning_rate': 2.2138492211710494e-05, 'epoch': 6.32}\n",
      "{'loss': 0.6962, 'grad_norm': 0.2816303074359894, 'learning_rate': 2.190617327309634e-05, 'epoch': 6.33}\n",
      "{'loss': 0.6007, 'grad_norm': 0.23680023849010468, 'learning_rate': 2.1674929708212776e-05, 'epoch': 6.34}\n",
      "{'loss': 0.5049, 'grad_norm': 0.30875036120414734, 'learning_rate': 2.144476470134804e-05, 'epoch': 6.35}\n",
      "{'loss': 0.4391, 'grad_norm': 0.3974156379699707, 'learning_rate': 2.1215681421938338e-05, 'epoch': 6.36}\n",
      "{'loss': 0.5188, 'grad_norm': 0.2557118237018585, 'learning_rate': 2.0987683024524175e-05, 'epoch': 6.37}\n",
      "{'loss': 0.5792, 'grad_norm': 0.2716580331325531, 'learning_rate': 2.0760772648707016e-05, 'epoch': 6.38}\n",
      "{'loss': 0.5358, 'grad_norm': 0.28064537048339844, 'learning_rate': 2.0534953419105828e-05, 'epoch': 6.39}\n",
      "{'loss': 0.635, 'grad_norm': 0.3608897924423218, 'learning_rate': 2.031022844531426e-05, 'epoch': 6.4}\n",
      "{'loss': 0.5197, 'grad_norm': 0.6100409030914307, 'learning_rate': 2.0086600821857747e-05, 'epoch': 6.41}\n",
      "{'loss': 0.4, 'grad_norm': 0.24130305647850037, 'learning_rate': 1.9864073628150958e-05, 'epoch': 6.42}\n",
      "{'loss': 0.6111, 'grad_norm': 0.21861642599105835, 'learning_rate': 1.964264992845527e-05, 'epoch': 6.43}\n",
      "{'loss': 0.6186, 'grad_norm': 0.2546128034591675, 'learning_rate': 1.9422332771836628e-05, 'epoch': 6.43}\n",
      "{'loss': 0.6107, 'grad_norm': 0.3485831022262573, 'learning_rate': 1.9203125192123584e-05, 'epoch': 6.44}\n",
      "{'loss': 0.4797, 'grad_norm': 0.2851535379886627, 'learning_rate': 1.8985030207865582e-05, 'epoch': 6.45}\n",
      "{'loss': 0.3963, 'grad_norm': 0.2816433012485504, 'learning_rate': 1.8768050822291238e-05, 'epoch': 6.46}\n",
      "{'loss': 0.6286, 'grad_norm': 0.26936203241348267, 'learning_rate': 1.8552190023267112e-05, 'epoch': 6.47}\n",
      "{'loss': 0.5073, 'grad_norm': 0.26249122619628906, 'learning_rate': 1.8337450783256437e-05, 'epoch': 6.48}\n",
      "{'loss': 0.4938, 'grad_norm': 0.2963910698890686, 'learning_rate': 1.812383605927832e-05, 'epoch': 6.49}\n",
      "{'loss': 0.561, 'grad_norm': 0.5401706695556641, 'learning_rate': 1.7911348792867e-05, 'epoch': 6.5}\n",
      "{'loss': 0.4442, 'grad_norm': 0.27579444646835327, 'learning_rate': 1.769999191003128e-05, 'epoch': 6.51}\n",
      "{'loss': 0.6282, 'grad_norm': 0.258561909198761, 'learning_rate': 1.748976832121425e-05, 'epoch': 6.52}\n",
      "{'loss': 0.4997, 'grad_norm': 0.22616368532180786, 'learning_rate': 1.7280680921253244e-05, 'epoch': 6.53}\n",
      "{'loss': 0.5176, 'grad_norm': 0.3137586712837219, 'learning_rate': 1.7072732589339955e-05, 'epoch': 6.54}\n",
      "{'loss': 0.5971, 'grad_norm': 0.438211053609848, 'learning_rate': 1.6865926188980808e-05, 'epoch': 6.54}\n",
      "{'loss': 0.4832, 'grad_norm': 0.18444794416427612, 'learning_rate': 1.6660264567957474e-05, 'epoch': 6.55}\n",
      "{'loss': 0.5068, 'grad_norm': 0.2123945951461792, 'learning_rate': 1.645575055828773e-05, 'epoch': 6.56}\n",
      "{'loss': 0.6723, 'grad_norm': 0.2522537112236023, 'learning_rate': 1.625238697618642e-05, 'epoch': 6.57}\n",
      "{'loss': 0.4374, 'grad_norm': 0.2862676680088043, 'learning_rate': 1.605017662202666e-05, 'epoch': 6.58}\n",
      "{'loss': 0.5594, 'grad_norm': 0.5590866208076477, 'learning_rate': 1.584912228030132e-05, 'epoch': 6.59}\n",
      "{'loss': 0.5213, 'grad_norm': 0.27802619338035583, 'learning_rate': 1.5649226719584654e-05, 'epoch': 6.6}\n",
      "{'loss': 0.5217, 'grad_norm': 0.2974499762058258, 'learning_rate': 1.5450492692494146e-05, 'epoch': 6.61}\n",
      "{'loss': 0.608, 'grad_norm': 0.2956256866455078, 'learning_rate': 1.5252922935652691e-05, 'epoch': 6.62}\n",
      "{'loss': 0.52, 'grad_norm': 0.2914142608642578, 'learning_rate': 1.5056520169650811e-05, 'epoch': 6.63}\n",
      "{'loss': 0.5329, 'grad_norm': 0.44018879532814026, 'learning_rate': 1.486128709900928e-05, 'epoch': 6.64}\n",
      "{'loss': 0.4578, 'grad_norm': 0.249013289809227, 'learning_rate': 1.466722641214181e-05, 'epoch': 6.65}\n",
      "{'loss': 0.5996, 'grad_norm': 0.16460974514484406, 'learning_rate': 1.4474340781318052e-05, 'epoch': 6.65}\n",
      "{'loss': 0.5333, 'grad_norm': 0.2541968822479248, 'learning_rate': 1.4282632862626899e-05, 'epoch': 6.66}\n",
      "{'loss': 0.3304, 'grad_norm': 0.266737163066864, 'learning_rate': 1.4092105295939684e-05, 'epoch': 6.67}\n",
      "{'loss': 0.4961, 'grad_norm': 0.4115392863750458, 'learning_rate': 1.3902760704874063e-05, 'epoch': 6.68}\n",
      "{'loss': 0.5391, 'grad_norm': 0.2015586644411087, 'learning_rate': 1.3714601696757712e-05, 'epoch': 6.69}\n",
      "{'loss': 0.4513, 'grad_norm': 0.2390698492527008, 'learning_rate': 1.352763086259261e-05, 'epoch': 6.7}\n",
      "{'loss': 0.4291, 'grad_norm': 0.23930563032627106, 'learning_rate': 1.3341850777019149e-05, 'epoch': 6.71}\n",
      "{'loss': 0.5505, 'grad_norm': 0.33696818351745605, 'learning_rate': 1.3157263998280845e-05, 'epoch': 6.72}\n",
      "{'loss': 0.5867, 'grad_norm': 0.653688371181488, 'learning_rate': 1.2973873068188958e-05, 'epoch': 6.73}\n",
      "{'loss': 0.3667, 'grad_norm': 0.27437251806259155, 'learning_rate': 1.27916805120877e-05, 'epoch': 6.74}\n",
      "{'loss': 0.5481, 'grad_norm': 0.2519664764404297, 'learning_rate': 1.2610688838819262e-05, 'epoch': 6.75}\n",
      "{'loss': 0.5633, 'grad_norm': 0.2604893445968628, 'learning_rate': 1.243090054068936e-05, 'epoch': 6.76}\n",
      "{'loss': 0.5211, 'grad_norm': 0.22295118868350983, 'learning_rate': 1.2252318093432891e-05, 'epoch': 6.76}\n",
      "{'loss': 0.4527, 'grad_norm': 0.48283469676971436, 'learning_rate': 1.2074943956179884e-05, 'epoch': 6.77}\n",
      "{'loss': 0.4747, 'grad_norm': 0.22976063191890717, 'learning_rate': 1.1898780571421552e-05, 'epoch': 6.78}\n",
      "{'loss': 0.406, 'grad_norm': 0.24564442038536072, 'learning_rate': 1.1723830364976751e-05, 'epoch': 6.79}\n",
      "{'loss': 0.5205, 'grad_norm': 0.21152953803539276, 'learning_rate': 1.1550095745958523e-05, 'epoch': 6.8}\n",
      "{'loss': 0.5429, 'grad_norm': 0.32044968008995056, 'learning_rate': 1.137757910674092e-05, 'epoch': 6.81}\n",
      "{'loss': 0.5684, 'grad_norm': 0.42676371335983276, 'learning_rate': 1.1206282822926083e-05, 'epoch': 6.82}\n",
      "{'loss': 0.4938, 'grad_norm': 0.31119009852409363, 'learning_rate': 1.1036209253311524e-05, 'epoch': 6.83}\n",
      "{'loss': 0.5201, 'grad_norm': 0.3195965588092804, 'learning_rate': 1.0867360739857624e-05, 'epoch': 6.84}\n",
      "{'loss': 0.4676, 'grad_norm': 0.25247788429260254, 'learning_rate': 1.0699739607655435e-05, 'epoch': 6.85}\n",
      "{'loss': 0.5078, 'grad_norm': 0.310273677110672, 'learning_rate': 1.0533348164894575e-05, 'epoch': 6.86}\n",
      "{'loss': 0.6001, 'grad_norm': 0.39641669392585754, 'learning_rate': 1.0368188702831528e-05, 'epoch': 6.87}\n",
      "{'loss': 0.4853, 'grad_norm': 0.20308133959770203, 'learning_rate': 1.0204263495758071e-05, 'epoch': 6.87}\n",
      "{'loss': 0.5344, 'grad_norm': 0.2439168244600296, 'learning_rate': 1.0041574800969921e-05, 'epoch': 6.88}\n",
      "{'loss': 0.5387, 'grad_norm': 0.1791093945503235, 'learning_rate': 9.880124858735684e-06, 'epoch': 6.89}\n",
      "{'loss': 0.3981, 'grad_norm': 0.2850487232208252, 'learning_rate': 9.71991589226604e-06, 'epoch': 6.9}\n",
      "{'loss': 0.6069, 'grad_norm': 0.456756055355072, 'learning_rate': 9.560950107682997e-06, 'epoch': 6.91}\n",
      "{'loss': 0.5602, 'grad_norm': 0.28018876910209656, 'learning_rate': 9.403229693989678e-06, 'epoch': 6.92}\n",
      "{'loss': 0.5885, 'grad_norm': 0.2171386331319809, 'learning_rate': 9.24675682304008e-06, 'epoch': 6.93}\n",
      "{'loss': 0.4827, 'grad_norm': 0.2963436245918274, 'learning_rate': 9.091533649509177e-06, 'epoch': 6.94}\n",
      "{'loss': 0.5672, 'grad_norm': 0.2545556128025055, 'learning_rate': 8.9375623108633e-06, 'epoch': 6.95}\n",
      "{'loss': 0.5369, 'grad_norm': 0.40072324872016907, 'learning_rate': 8.784844927330637e-06, 'epoch': 6.96}\n",
      "{'loss': 0.424, 'grad_norm': 0.2054445445537567, 'learning_rate': 8.633383601872035e-06, 'epoch': 6.97}\n",
      "{'loss': 0.6116, 'grad_norm': 0.2654389441013336, 'learning_rate': 8.483180420152093e-06, 'epoch': 6.98}\n",
      "{'loss': 0.457, 'grad_norm': 0.19278934597969055, 'learning_rate': 8.334237450510485e-06, 'epoch': 6.98}\n",
      "{'loss': 0.5358, 'grad_norm': 0.4007129967212677, 'learning_rate': 8.186556743933327e-06, 'epoch': 6.99}\n",
      "{'loss': 0.4472, 'grad_norm': 0.2729578912258148, 'learning_rate': 8.040140334025082e-06, 'epoch': 7.0}\n",
      "{'loss': 0.4155, 'grad_norm': 0.15444859862327576, 'learning_rate': 7.894990236980404e-06, 'epoch': 7.01}\n",
      "{'loss': 0.6426, 'grad_norm': 0.2826949954032898, 'learning_rate': 7.7511084515566e-06, 'epoch': 7.02}\n",
      "{'loss': 0.5014, 'grad_norm': 0.32542428374290466, 'learning_rate': 7.608496959045863e-06, 'epoch': 7.03}\n",
      "{'loss': 0.3871, 'grad_norm': 0.3920625150203705, 'learning_rate': 7.467157723248153e-06, 'epoch': 7.04}\n",
      "{'loss': 0.3568, 'grad_norm': 0.1591615080833435, 'learning_rate': 7.327092690444082e-06, 'epoch': 7.05}\n",
      "{'loss': 0.4517, 'grad_norm': 0.34581616520881653, 'learning_rate': 7.188303789368134e-06, 'epoch': 7.06}\n",
      "{'loss': 0.4031, 'grad_norm': 0.21173584461212158, 'learning_rate': 7.050792931182127e-06, 'epoch': 7.07}\n",
      "{'loss': 0.4649, 'grad_norm': 0.29680806398391724, 'learning_rate': 6.914562009448833e-06, 'epoch': 7.08}\n",
      "{'loss': 0.5456, 'grad_norm': 0.2581002414226532, 'learning_rate': 6.779612900105958e-06, 'epoch': 7.09}\n",
      "{'loss': 0.3844, 'grad_norm': 0.7116900086402893, 'learning_rate': 6.645947461440327e-06, 'epoch': 7.09}\n",
      "{'loss': 0.6254, 'grad_norm': 0.29392141103744507, 'learning_rate': 6.5135675340622035e-06, 'epoch': 7.1}\n",
      "{'loss': 0.4922, 'grad_norm': 0.26343345642089844, 'learning_rate': 6.382474940880057e-06, 'epoch': 7.11}\n",
      "{'loss': 0.5249, 'grad_norm': 0.26783487200737, 'learning_rate': 6.252671487075368e-06, 'epoch': 7.12}\n",
      "{'loss': 0.446, 'grad_norm': 0.4446471631526947, 'learning_rate': 6.12415896007783e-06, 'epoch': 7.13}\n",
      "{'loss': 0.3858, 'grad_norm': 0.1991591900587082, 'learning_rate': 5.996939129540702e-06, 'epoch': 7.14}\n",
      "{'loss': 0.5974, 'grad_norm': 0.17670416831970215, 'learning_rate': 5.871013747316501e-06, 'epoch': 7.15}\n",
      "{'loss': 0.5564, 'grad_norm': 0.2624216675758362, 'learning_rate': 5.746384547432737e-06, 'epoch': 7.16}\n",
      "{'loss': 0.4926, 'grad_norm': 0.21756014227867126, 'learning_rate': 5.62305324606821e-06, 'epoch': 7.17}\n",
      "{'loss': 0.5124, 'grad_norm': 0.3051775097846985, 'learning_rate': 5.5010215415292385e-06, 'epoch': 7.18}\n",
      "{'loss': 0.4188, 'grad_norm': 0.2501889169216156, 'learning_rate': 5.38029111422641e-06, 'epoch': 7.19}\n",
      "{'loss': 0.5254, 'grad_norm': 0.2795218527317047, 'learning_rate': 5.260863626651291e-06, 'epoch': 7.2}\n",
      "{'loss': 0.4736, 'grad_norm': 0.2775251865386963, 'learning_rate': 5.142740723353601e-06, 'epoch': 7.2}\n",
      "{'loss': 0.559, 'grad_norm': 0.21502599120140076, 'learning_rate': 5.025924030918616e-06, 'epoch': 7.21}\n",
      "{'loss': 0.555, 'grad_norm': 0.334901362657547, 'learning_rate': 4.910415157944715e-06, 'epoch': 7.22}\n",
      "{'loss': 0.4896, 'grad_norm': 0.20236290991306305, 'learning_rate': 4.796215695021211e-06, 'epoch': 7.23}\n",
      "{'loss': 0.6287, 'grad_norm': 0.29837000370025635, 'learning_rate': 4.683327214706534e-06, 'epoch': 7.24}\n",
      "{'loss': 0.5666, 'grad_norm': 0.28214240074157715, 'learning_rate': 4.571751271506419e-06, 'epoch': 7.25}\n",
      "{'loss': 0.5311, 'grad_norm': 0.26851123571395874, 'learning_rate': 4.461489401852692e-06, 'epoch': 7.26}\n",
      "{'loss': 0.4243, 'grad_norm': 0.4287591576576233, 'learning_rate': 4.352543124081987e-06, 'epoch': 7.27}\n",
      "{'loss': 0.404, 'grad_norm': 0.29033035039901733, 'learning_rate': 4.244913938414885e-06, 'epoch': 7.28}\n",
      "{'loss': 0.5751, 'grad_norm': 0.29713645577430725, 'learning_rate': 4.13860332693522e-06, 'epoch': 7.29}\n",
      "{'loss': 0.3603, 'grad_norm': 0.15174858272075653, 'learning_rate': 4.033612753569682e-06, 'epoch': 7.3}\n",
      "{'loss': 0.5677, 'grad_norm': 0.3165353536605835, 'learning_rate': 3.929943664067715e-06, 'epoch': 7.31}\n",
      "{'loss': 0.5634, 'grad_norm': 0.3761563003063202, 'learning_rate': 3.827597485981527e-06, 'epoch': 7.31}\n",
      "{'loss': 0.4652, 'grad_norm': 0.22759418189525604, 'learning_rate': 3.726575628646478e-06, 'epoch': 7.32}\n",
      "{'loss': 0.6573, 'grad_norm': 0.2823098599910736, 'learning_rate': 3.6268794831616717e-06, 'epoch': 7.33}\n",
      "{'loss': 0.6004, 'grad_norm': 0.22701291739940643, 'learning_rate': 3.5285104223707566e-06, 'epoch': 7.34}\n",
      "{'loss': 0.6098, 'grad_norm': 0.4412696957588196, 'learning_rate': 3.4314698008431123e-06, 'epoch': 7.35}\n",
      "{'loss': 0.4985, 'grad_norm': 0.44701939821243286, 'learning_rate': 3.335758954855073e-06, 'epoch': 7.36}\n",
      "{'loss': 0.4642, 'grad_norm': 0.31226882338523865, 'learning_rate': 3.241379202371653e-06, 'epoch': 7.37}\n",
      "{'loss': 0.5417, 'grad_norm': 0.2797461748123169, 'learning_rate': 3.148331843028296e-06, 'epoch': 7.38}\n",
      "{'loss': 0.4773, 'grad_norm': 0.10832106322050095, 'learning_rate': 3.056618158113078e-06, 'epoch': 7.39}\n",
      "{'loss': 0.4653, 'grad_norm': 0.2989048659801483, 'learning_rate': 2.96623941054891e-06, 'epoch': 7.4}\n",
      "{'loss': 0.6072, 'grad_norm': 0.42320969700813293, 'learning_rate': 2.8771968448763396e-06, 'epoch': 7.41}\n",
      "{'loss': 0.3462, 'grad_norm': 0.27848950028419495, 'learning_rate': 2.7894916872362677e-06, 'epoch': 7.42}\n",
      "{'loss': 0.5765, 'grad_norm': 0.1993722915649414, 'learning_rate': 2.7031251453531247e-06, 'epoch': 7.42}\n",
      "{'loss': 0.5563, 'grad_norm': 0.296169251203537, 'learning_rate': 2.6180984085182547e-06, 'epoch': 7.43}\n",
      "{'loss': 0.5401, 'grad_norm': 0.24774153530597687, 'learning_rate': 2.5344126475734587e-06, 'epoch': 7.44}\n",
      "{'loss': 0.5467, 'grad_norm': 0.45279359817504883, 'learning_rate': 2.4520690148949642e-06, 'epoch': 7.45}\n",
      "{'loss': 0.4344, 'grad_norm': 0.2895505726337433, 'learning_rate': 2.3710686443775165e-06, 'epoch': 7.46}\n",
      "{'loss': 0.4207, 'grad_norm': 0.252129465341568, 'learning_rate': 2.291412651418778e-06, 'epoch': 7.47}\n",
      "{'loss': 0.5134, 'grad_norm': 0.18871207535266876, 'learning_rate': 2.2131021329039435e-06, 'epoch': 7.48}\n",
      "{'loss': 0.5858, 'grad_norm': 0.2535172700881958, 'learning_rate': 2.1361381671906267e-06, 'epoch': 7.49}\n",
      "{'loss': 0.4821, 'grad_norm': 0.4528355300426483, 'learning_rate': 2.0605218140940517e-06, 'epoch': 7.5}\n",
      "{'loss': 0.4877, 'grad_norm': 0.2673408091068268, 'learning_rate': 1.9862541148724767e-06, 'epoch': 7.51}\n",
      "{'loss': 0.6408, 'grad_norm': 0.27599868178367615, 'learning_rate': 1.9133360922127806e-06, 'epoch': 7.52}\n",
      "{'loss': 0.5729, 'grad_norm': 0.25791069865226746, 'learning_rate': 1.8417687502164438e-06, 'epoch': 7.53}\n",
      "{'loss': 0.4696, 'grad_norm': 0.2909274995326996, 'learning_rate': 1.7715530743856456e-06, 'epoch': 7.53}\n",
      "{'loss': 0.4742, 'grad_norm': 0.5008105635643005, 'learning_rate': 1.7026900316098215e-06, 'epoch': 7.54}\n",
      "{'loss': 0.5051, 'grad_norm': 0.27675753831863403, 'learning_rate': 1.6351805701522282e-06, 'epoch': 7.55}\n",
      "{'loss': 0.5771, 'grad_norm': 0.26603010296821594, 'learning_rate': 1.5690256196369436e-06, 'epoch': 7.56}\n",
      "{'loss': 0.4865, 'grad_norm': 0.22015029191970825, 'learning_rate': 1.504226091036054e-06, 'epoch': 7.57}\n",
      "{'loss': 0.5367, 'grad_norm': 0.3425843417644501, 'learning_rate': 1.4407828766570875e-06, 'epoch': 7.58}\n",
      "{'loss': 0.5016, 'grad_norm': 0.4875033497810364, 'learning_rate': 1.3786968501307783e-06, 'epoch': 7.59}\n",
      "{'loss': 0.3751, 'grad_norm': 0.26257339119911194, 'learning_rate': 1.3179688663989886e-06, 'epoch': 7.6}\n",
      "{'loss': 0.3806, 'grad_norm': 0.14481034874916077, 'learning_rate': 1.2585997617029499e-06, 'epoch': 7.61}\n",
      "{'loss': 0.4979, 'grad_norm': 0.2658715844154358, 'learning_rate': 1.2005903535717733e-06, 'epoch': 7.62}\n",
      "{'loss': 0.513, 'grad_norm': 0.30513519048690796, 'learning_rate': 1.143941440811147e-06, 'epoch': 7.63}\n",
      "{'loss': 0.5227, 'grad_norm': 0.37240052223205566, 'learning_rate': 1.0886538034923676e-06, 'epoch': 7.64}\n",
      "{'loss': 0.4253, 'grad_norm': 0.19723418354988098, 'learning_rate': 1.0347282029415928e-06, 'epoch': 7.64}\n",
      "{'loss': 0.4747, 'grad_norm': 0.18256674706935883, 'learning_rate': 9.821653817293498e-07, 'epoch': 7.65}\n",
      "{'loss': 0.4861, 'grad_norm': 0.22046515345573425, 'learning_rate': 9.309660636603101e-07, 'epoch': 7.66}\n",
      "{'loss': 0.5625, 'grad_norm': 0.3243106007575989, 'learning_rate': 8.811309537633539e-07, 'epoch': 7.67}\n",
      "{'loss': 0.4668, 'grad_norm': 0.3627272844314575, 'learning_rate': 8.326607382817875e-07, 'epoch': 7.68}\n",
      "{'loss': 0.4268, 'grad_norm': 0.1951933056116104, 'learning_rate': 7.855560846639964e-07, 'epoch': 7.69}\n",
      "{'loss': 0.3897, 'grad_norm': 0.2383430153131485, 'learning_rate': 7.398176415541414e-07, 'epoch': 7.7}\n",
      "{'loss': 0.5152, 'grad_norm': 0.25092825293540955, 'learning_rate': 6.954460387833539e-07, 'epoch': 7.71}\n",
      "{'loss': 0.6072, 'grad_norm': 0.3518134355545044, 'learning_rate': 6.524418873609328e-07, 'epoch': 7.72}\n",
      "{'loss': 0.5085, 'grad_norm': 0.5196384191513062, 'learning_rate': 6.10805779466006e-07, 'epoch': 7.73}\n",
      "{'loss': 0.3503, 'grad_norm': 0.09218819439411163, 'learning_rate': 5.705382884393707e-07, 'epoch': 7.74}\n",
      "{'loss': 0.4606, 'grad_norm': 0.17379067838191986, 'learning_rate': 5.316399687755991e-07, 'epoch': 7.75}\n",
      "{'loss': 0.4447, 'grad_norm': 0.1966184824705124, 'learning_rate': 4.941113561153677e-07, 'epoch': 7.75}\n",
      "{'loss': 0.5248, 'grad_norm': 0.32855159044265747, 'learning_rate': 4.5795296723812887e-07, 'epoch': 7.76}\n",
      "{'loss': 0.5154, 'grad_norm': 0.5497889518737793, 'learning_rate': 4.231653000549507e-07, 'epoch': 7.77}\n",
      "{'loss': 0.5638, 'grad_norm': 0.2629426121711731, 'learning_rate': 3.8974883360169966e-07, 'epoch': 7.78}\n",
      "{'loss': 0.7675, 'grad_norm': 0.23314645886421204, 'learning_rate': 3.57704028032424e-07, 'epoch': 7.79}\n",
      "{'loss': 0.5153, 'grad_norm': 0.2670533359050751, 'learning_rate': 3.27031324613003e-07, 'epoch': 7.8}\n",
      "{'loss': 0.5384, 'grad_norm': 0.2683781683444977, 'learning_rate': 2.977311457151188e-07, 'epoch': 7.81}\n",
      "{'loss': 0.5838, 'grad_norm': 0.4588652551174164, 'learning_rate': 2.69803894810372e-07, 'epoch': 7.82}\n",
      "{'loss': 0.384, 'grad_norm': 0.18174374103546143, 'learning_rate': 2.432499564647861e-07, 'epoch': 7.83}\n",
      "{'loss': 0.5952, 'grad_norm': 0.27921345829963684, 'learning_rate': 2.180696963334783e-07, 'epoch': 7.84}\n",
      "{'loss': 0.4194, 'grad_norm': 0.2569669485092163, 'learning_rate': 1.9426346115565263e-07, 'epoch': 7.85}\n",
      "{'loss': 0.6014, 'grad_norm': 0.3526018559932709, 'learning_rate': 1.7183157874979262e-07, 'epoch': 7.86}\n",
      "{'loss': 0.4208, 'grad_norm': 0.5985982418060303, 'learning_rate': 1.5077435800915362e-07, 'epoch': 7.86}\n",
      "{'loss': 0.3805, 'grad_norm': 0.2545718550682068, 'learning_rate': 1.31092088897522e-07, 'epoch': 7.87}\n",
      "{'loss': 0.4825, 'grad_norm': 0.20286211371421814, 'learning_rate': 1.1278504244524035e-07, 'epoch': 7.88}\n",
      "{'loss': 0.4182, 'grad_norm': 0.32053884863853455, 'learning_rate': 9.585347074542173e-08, 'epoch': 7.89}\n",
      "{'loss': 0.5488, 'grad_norm': 0.3601350486278534, 'learning_rate': 8.029760695051902e-08, 'epoch': 7.9}\n",
      "{'loss': 0.5099, 'grad_norm': 0.5978466272354126, 'learning_rate': 6.611766526910534e-08, 'epoch': 7.91}\n",
      "{'loss': 0.3832, 'grad_norm': 0.2113458216190338, 'learning_rate': 5.33138409629319e-08, 'epoch': 7.92}\n",
      "{'loss': 0.7074, 'grad_norm': 0.31132081151008606, 'learning_rate': 4.1886310344219084e-08, 'epoch': 7.93}\n",
      "{'loss': 0.5644, 'grad_norm': 0.1662544161081314, 'learning_rate': 3.183523077324724e-08, 'epoch': 7.94}\n",
      "{'loss': 0.6045, 'grad_norm': 0.3047903776168823, 'learning_rate': 2.316074065618068e-08, 'epoch': 7.95}\n",
      "{'loss': 0.5215, 'grad_norm': 0.49278977513313293, 'learning_rate': 1.5862959443158077e-08, 'epoch': 7.96}\n",
      "{'loss': 0.3757, 'grad_norm': 0.20609311759471893, 'learning_rate': 9.941987626649329e-09, 'epoch': 7.97}\n",
      "{'loss': 0.5368, 'grad_norm': 0.2587381601333618, 'learning_rate': 5.397906740112202e-09, 'epoch': 7.97}\n",
      "{'loss': 0.5613, 'grad_norm': 0.27450960874557495, 'learning_rate': 2.2307793567710733e-09, 'epoch': 7.98}\n",
      "{'loss': 0.5204, 'grad_norm': 0.46385347843170166, 'learning_rate': 4.4064908888419297e-10, 'epoch': 7.99}\n",
      "{'train_runtime': 13911.6914, 'train_samples_per_second': 1.255, 'train_steps_per_second': 0.627, 'train_loss': 0.6514609504958886, 'epoch': 8.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,      # uses the number of epochs earlier\n",
    "    per_device_train_batch_size=1,          # 4 seems reasonable\n",
    "    gradient_accumulation_steps=1,          # 2 is fine, as we're a small batch\n",
    "    optim=\"paged_adamw_32bit\",              # default optimizer\n",
    "    save_steps=0,                           # we're not gonna save\n",
    "    logging_steps=10,                       # same value as used by Meta\n",
    "    learning_rate=2e-4,                     # standard learning rate\n",
    "    weight_decay=0.001,                     # standard weight decay 0.001\n",
    "    fp16=False,                             # set to true for A100\n",
    "    bf16=False,                             # set to true for A100\n",
    "    max_grad_norm=0.3,                      # standard setting\n",
    "    max_steps=-1,                           # needs to be -1, otherwise overrides epochs\n",
    "    warmup_ratio=0.03,                      # standard warmup ratio\n",
    "    group_by_length=True,                   # speeds up the training\n",
    "    lr_scheduler_type=\"cosine\",           # constant seems better than cosine\n",
    "    report_to=\"tensorboard\"\n",
    ")\n",
    "\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,                # use our lora peft config\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=None,                    # no max sequence length\n",
    "    tokenizer=tokenizer,                    # use the llama tokenizer\n",
    "    args=training_arguments,                # use the training arguments\n",
    "    packing=False,                          # don't need packing\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2656b9ed-fada-4f90-a503-0ee8802bd1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ea2c853e5ff402f8c77ad33acb05dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2872eeb971604c8a9722d8e8d2daacc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2033fd3c67174524afd030bc90e2d8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/ayman56/llama2_SAS_finetuned_50_test/commit/c00c4c68988fb8e2a24f12cedf218e711b152541', commit_message='Upload tokenizer', commit_description='', oid='c00c4c68988fb8e2a24f12cedf218e711b152541', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.push_to_hub(\"llama2_SAS_finetuned_50_test\")\n",
    "tokenizer.push_to_hub(\"llama2_SAS_finetuned_50_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
